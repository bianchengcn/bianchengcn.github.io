<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch实现kaggle猫狗识别（超详细） - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch实现kaggle猫狗识别（超详细）" />
<meta property="og:description" content="kaggle是一个为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台，在这上面有非常多的好项目、好资源可供机器学习、深度学习爱好者学习之用。碰巧最近入门了一门非常的深度学习框架：pytorch（如果你对pytorch不甚了解，请点击这里），所以今天我和大家一起用pytorch实现一个图像识别领域的入门项目：猫狗图像识别。
深度学习的基础就是数据，咱们先从数据谈起。此次使用的猫狗分类图像一共25000张，猫狗分别有12500张。下载地址：https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data我们先来简单的看看都是一些什么图片。我们从下载文件里可以看到有两个文件夹：train和test1，分别用于训练和测试。打开train文件夹可以看到有25000 张小猫小狗的图片，图片名字为cat.0.jpg，cat.1.jpg，dog.0.jpg，dog.1.jpg。
仔细看小猫小狗，可以发现它们姿态不一，有的站着，有的眯着眼睛，有的甚至和其他可识别物体比如桶、人混在一起。同时，小猫们的图片尺寸也不一致，有的是竖放的长方形，有的是横放的长方形，但我们最终需要是合理尺寸的图片。所以需要进行图片处理，并把图片转化成Tensor作为模型的输入。代码如下：
data_transform = transforms.Compose([ transforms.Resize(84), transforms.CenterCrop(84), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) train_dataset = datasets.ImageFolder(root=&#39;./data2/train/&#39;, transform=data_transform) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers) 为方便训练过程，需要把训练集进行处理：把猫狗的图片分别放在cat，dog文件夹中，并划分出一部分图片作为测试集（与下载的测试集不同）。代码如下：
# kaggle原始数据集地址 original_dataset_dir = &#39;E:\python ese\c_d\data\\train\\train&#39; total_num = int(len(os.listdir(original_dataset_dir)) / 2) random_idx = np.array(range(total_num)) np.random.shuffle(random_idx) # 待处理的数据集地址 base_dir = &#39;E:\python ese\c_d\data2&#39; if not os.path.exists(base_dir): os.mkdir(base_dir) # 训练集、测试集的划分 sub_dirs = [&#39;train&#39;, &#39;test&#39;] animals = [&#39;cats&#39;, &#39;dogs&#39;] train_idx = random_idx[:int(total_num * 0.9)] test_idx = random_idx[int(total_num * 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d4a95f8811dd1343ddf370901c111c2d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-31T16:28:45+08:00" />
<meta property="article:modified_time" content="2019-05-31T16:28:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch实现kaggle猫狗识别（超详细）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>kaggle是一个为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台，在这上面有非常多的好项目、好资源可供机器学习、深度学习爱好者学习之用。碰巧最近入门了一门非常的深度学习框架：pytorch（如果你对pytorch不甚了解，<a href="http://http//pytorch.org/" rel="nofollow">请点击这里</a>），所以今天我和大家一起用pytorch实现一个图像识别领域的入门项目：猫狗图像识别。<br> 深度学习的基础就是数据，咱们先从数据谈起。此次使用的猫狗分类图像一共25000张，猫狗分别有12500张。下载地址：<a href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data%E6%88%91%E4%BB%AC%E5%85%88%E6%9D%A5%E7%AE%80%E5%8D%95%E7%9A%84%E7%9C%8B%E7%9C%8B%E9%83%BD%E6%98%AF%E4%B8%80%E4%BA%9B%E4%BB%80%E4%B9%88%E5%9B%BE%E7%89%87%E3%80%82%E6%88%91%E4%BB%AC%E4%BB%8E%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E9%87%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%9C%89%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%EF%BC%9Atrain%E5%92%8Ctest1%EF%BC%8C%E5%88%86%E5%88%AB%E7%94%A8%E4%BA%8E%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E3%80%82%E6%89%93%E5%BC%80train%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%9C%8925000" rel="nofollow">https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data我们先来简单的看看都是一些什么图片。我们从下载文件里可以看到有两个文件夹：train和test1，分别用于训练和测试。打开train文件夹可以看到有25000</a> 张小猫小狗的图片，图片名字为cat.0.jpg，cat.1.jpg，dog.0.jpg，dog.1.jpg。<br> <img src="https://images2.imgbox.com/28/5e/9sJClWg0_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/44/cc/FW5AebaS_o.png" alt="在这里插入图片描述"><br> 仔细看小猫小狗，可以发现它们姿态不一，有的站着，有的眯着眼睛，有的甚至和其他可识别物体比如桶、人混在一起。同时，小猫们的图片尺寸也不一致，有的是竖放的长方形，有的是横放的长方形，但我们最终需要是合理尺寸的图片。所以需要进行图片处理，并把图片转化成Tensor作为模型的输入。代码如下：</p> 
<pre><code>data_transform = transforms.Compose([
    transforms.Resize(84),
    transforms.CenterCrop(84),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder(root='./data2/train/', 
                                     transform=data_transform)
train_loader = torch.utils.data.DataLoader(train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True,
                                           num_workers=num_workers)

</code></pre> 
<p>为方便训练过程，需要把训练集进行处理：把猫狗的图片分别放在cat，dog文件夹中，并划分出一部分图片作为测试集（与下载的测试集不同）。代码如下：</p> 
<pre><code>
# kaggle原始数据集地址
original_dataset_dir = 'E:\python ese\c_d\data\\train\\train'
total_num = int(len(os.listdir(original_dataset_dir)) / 2)
random_idx = np.array(range(total_num))
np.random.shuffle(random_idx)

# 待处理的数据集地址
base_dir = 'E:\python ese\c_d\data2'
if not os.path.exists(base_dir):
    os.mkdir(base_dir)

# 训练集、测试集的划分
sub_dirs = ['train', 'test']
animals = ['cats', 'dogs']
train_idx = random_idx[:int(total_num * 0.9)]
test_idx = random_idx[int(total_num * 0.9):]
numbers = [train_idx, test_idx]
for idx, sub_dir in enumerate(sub_dirs):
    dir = os.path.join(base_dir, sub_dir)
    if not os.path.exists(dir):
        os.mkdir(dir)
    for animal in animals:
        animal_dir = os.path.join(dir, animal)  #
        if not os.path.exists(animal_dir):
            os.mkdir(animal_dir)
        fnames = [animal[:-1] + '.{}.jpg'.format(i) for i in numbers[idx]]
        for fname in fnames:
            src = os.path.join(original_dataset_dir, fname)
            dst = os.path.join(animal_dir, fname)
            shutil.copyfile(src, dst)

        # 验证训练集、验证集、测试集的划分的照片数目
        print(animal_dir + ' total images : %d' % (len(os.listdir(animal_dir))))

</code></pre> 
<p>紧接着我们了解一下特别适用于图像识别领域的神经网络：卷积神经网络。学习过神经网络的同学可能或多或少地听说过卷积神经网络。这是一种典型的多层神经网络，擅长处理图像特别是大图像的相关机器学习问题。卷积神经网络通过一系列的方法，成功地将大数据量的图像识别问题不断降维，最终使其能够被训练。CNN最早由Yann LeCun提出并应用在手写体识别上。一个典型的CNN网络架构如下：<br> <img src="https://images2.imgbox.com/38/ac/PXh3W8nR_o.jpg" alt="在这里插入图片描述"><br> 这是一个典型的CNN架构，由卷基层、池化层、全连接层组合而成。其中卷基层与池化层配合，组成多个卷积组，逐层提取特征，最终完成分类。听到上述一连串的术语如果你有点蒙了，也别怕，因为这些复杂、抽象的技术都已经在pytorch中一一实现，我们要做的不过是正确的调用相关函数。</p> 
<pre><code># 创建模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.maxpool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 18 * 18, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 2)

    def forward(self, x):
        x = self.maxpool(F.relu(self.conv1(x)))
        x = self.maxpool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 18 * 18)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x


net = Net()

</code></pre> 
<p>我们从conv1说起。conv1实际上就是定义一个卷积层，3,6,5分别是什么意思？3代表的是输入图像的像素数组的层数，一般来说就是你输入的图像的通道数，比如这里使用的小猫图像都是彩色图像，由R、G、B三个通道组成，所以数值为3；6代表的是我们希望进行6次卷积，每一次卷积都能生成不同的特征映射数组，用于提取小猫和小狗的6种特征。每一个特征映射结果最终都会被堆叠在一起形成一个图像输出，再作为下一步的输入；5就是过滤框架的尺寸，表示我们希望用一个5 * 5的矩阵去和图像中相同尺寸的矩阵进行点乘再相加，形成一个值。定义好了卷基层，我们接着定义池化层。池化层所做的事说来简单，其实就是因为大图片生成的像素矩阵实在太大了，我们需要用一个合理的方法在降维的同时又不失去物体特征，所以深度学习学者们想出了一个称为池化的技术，说白了就是从左上角开始，每四个元素(2 * 2)合并成一个元素，用这一个元素去代表四个元素的值，所以图像体积一下子降为原来的四分之一。再往下一行，我们又一次碰见了一个卷积层：conv2,和conv1一样，它的输入也是一个多层像素数组，输出也是一个多层像素数组，不同的是这一次完成的计算量更大了，我们看这里面的参数分别是6，16，5。之所以为6是因为conv1的输出层数为6，所以这里输入的层数就是6；16代表conv2的输出层数，和conv1一样，16代表着这一次卷积操作将会学习小猫小狗的16种映射特征，特征越多理论上能学习的效果就越好，大家可以尝试一下别的值，看看效果是否真的编变好。conv2使用的过滤框尺寸和conv1一样，所以不再重复。最后三行代码都是用于定义全连接网络的，接触过神经网络的应该就不再陌生了，主要是需要解释一下fc1。之前在学习的时候比较不理解的也是这一行，为什么是16 * 18 * 18呢？16很好理解，因为最后一次卷积生成的图像矩阵的高度就是16层，那18 * 18是怎么来的呢？我们回过头去看一行代码</p> 
<p>transforms.CenterCrop(84)<br> 在这行代码里我们把训练图像裁剪成一个84 * 84的正方形尺寸，所以图像最早输入就是一个3 * 84 * 84的数组。经过第一次5 * 5的卷积之后，我们可以得出卷积的结果是一个6 * 80 * 80的矩阵，这里的80就是因为我们使用了一个5 * 5的过滤框，当它从左上角第一个元素开始卷积后，过滤框的中心是从2到78，并不是从0到79，所以结果就是一个80 * 80的图像了。经过一个池化层之后，图像尺寸的宽和高都分别缩小到原来的1/2，所以变成40 * 40。紧接着又进行了一次卷积，和上一次一样，长宽都减掉4，变成36 * 36，然后应用了最后一层的池化，最终尺寸就是18 * 18。所以第一层全连接层的输入数据的尺寸是16 * 18 * 18。三个全连接层所做的事很类似，就是不断训练，最后输出一个二分类数值。net类的forward函数表示前向计算的整个过程。forward接受一个input，返回一个网络输出值，中间的过程就是一个调用init函数中定义的层的过程。F.relu是一个激活函数，把所有的非零值转化成零值。此次图像识别的最后关键一步就是真正的循环训练操作。</p> 
<p>下面就可以开始训练了！</p> 
<pre><code>
# 定义loss和optimizer
cirterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)

def train():

    for epoch in range(epochs):
        running_loss = 0.0
        train_correct = 0
        train_total = 0
        for i, data in enumerate(train_loader, 0):
            inputs, train_labels = data
            if use_gpu:
                inputs, labels = Variable(inputs.cuda()), Variable(train_labels.cuda())
            else:
                inputs, labels = Variable(inputs), Variable(train_labels)
            optimizer.zero_grad()
            outputs = net(inputs)
            _, train_predicted = torch.max(outputs.data, 1)
            train_correct += (train_predicted == labels.data).sum()
            loss = cirterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_total += train_labels.size(0)

        print('train %d epoch loss: %.3f  acc: %.3f ' % (
            epoch + 1, running_loss / train_total, 100 * train_correct / train_total))
        # 模型测试
        correct = 0
        test_loss = 0.0
        test_total = 0
        test_total = 0
        net.eval()
        for data in test_loader:
            images, labels = data
            if use_gpu:
                images, labels = Variable(images.cuda()), Variable(labels.cuda())
            else:
                images, labels = Variable(images), Variable(labels)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            loss = cirterion(outputs, labels)
            test_loss += loss.item()
            test_total += labels.size(0)
            correct += (predicted == labels.data).sum()

        print('test  %d epoch loss: %.3f  acc: %.3f ' % (epoch + 1, test_loss / test_total, 100 * correct / test_total))

    torch.save(net, 'model.pt')


train()
</code></pre> 
<p>完整代码：</p> 
<pre><code># coding=utf-8
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data import Dataset
from torchvision import transforms, datasets, models

# 随机种子设置
random_state = 42
np.random.seed(random_state)

# kaggle原始数据集地址
original_dataset_dir = 'E:\python ese\c_d\data\\train\\train'
total_num = int(len(os.listdir(original_dataset_dir)) / 2)
random_idx = np.array(range(total_num))
np.random.shuffle(random_idx)

# 待处理的数据集地址
base_dir = 'E:\python ese\c_d\data2'
if not os.path.exists(base_dir):
    os.mkdir(base_dir)

# 训练集、测试集的划分
sub_dirs = ['train', 'test']
animals = ['cats', 'dogs']
train_idx = random_idx[:int(total_num * 0.9)]
test_idx = random_idx[int(total_num * 0.9):]
numbers = [train_idx, test_idx]
for idx, sub_dir in enumerate(sub_dirs):
    dir = os.path.join(base_dir, sub_dir)
    if not os.path.exists(dir):
        os.mkdir(dir)
    for animal in animals:
        animal_dir = os.path.join(dir, animal)  #
        if not os.path.exists(animal_dir):
            os.mkdir(animal_dir)
        fnames = [animal[:-1] + '.{}.jpg'.format(i) for i in numbers[idx]]
        for fname in fnames:
            src = os.path.join(original_dataset_dir, fname)
            dst = os.path.join(animal_dir, fname)
            shutil.copyfile(src, dst)

        # 验证训练集、验证集、测试集的划分的照片数目
        print(animal_dir + ' total images : %d' % (len(os.listdir(animal_dir))))
    # coding=utf-8

# 配置参数
random_state = 1
torch.manual_seed(random_state)  # 设置随机数种子，确保结果可重复
torch.cuda.manual_seed(random_state)
torch.cuda.manual_seed_all(random_state)
np.random.seed(random_state)
# random.seed(random_state)

epochs = 10 # 训练次数
batch_size = 4  # 批处理大小
num_workers = 0  # 多线程的数目
use_gpu = torch.cuda.is_available()
PATH='E:\python ese\c_d\model.pt'
# 对加载的图像作归一化处理， 并裁剪为[224x224x3]大小的图像
data_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder(root='./data2/train/',
                                     transform=data_transform)
train_loader = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True,
                                           num_workers=num_workers)

test_dataset = datasets.ImageFolder(root='./data2/test/', transform=data_transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)


# 创建模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.maxpool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 53 * 53, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 2)

    def forward(self, x):
        x = self.maxpool(F.relu(self.conv1(x)))
        x = self.maxpool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 53 * 53)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)

        return x


net = Net()
if(os.path.exists('model.pt')):
    net=torch.load('model.pt')

if use_gpu:
    net = net.cuda()
print(net)

# 定义loss和optimizer
cirterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)

def train():

    for epoch in range(epochs):
        running_loss = 0.0
        train_correct = 0
        train_total = 0
        for i, data in enumerate(train_loader, 0):
            inputs, train_labels = data
            if use_gpu:
                inputs, labels = Variable(inputs.cuda()), Variable(train_labels.cuda())
            else:
                inputs, labels = Variable(inputs), Variable(train_labels)
            optimizer.zero_grad()
            outputs = net(inputs)
            _, train_predicted = torch.max(outputs.data, 1)
            train_correct += (train_predicted == labels.data).sum()
            loss = cirterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_total += train_labels.size(0)

        print('train %d epoch loss: %.3f  acc: %.3f ' % (
            epoch + 1, running_loss / train_total, 100 * train_correct / train_total))
        # 模型测试
        correct = 0
        test_loss = 0.0
        test_total = 0
        test_total = 0
        net.eval()
        for data in test_loader:
            images, labels = data
            if use_gpu:
                images, labels = Variable(images.cuda()), Variable(labels.cuda())
            else:
                images, labels = Variable(images), Variable(labels)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            loss = cirterion(outputs, labels)
            test_loss += loss.item()
            test_total += labels.size(0)
            correct += (predicted == labels.data).sum()

        print('test  %d epoch loss: %.3f  acc: %.3f ' % (epoch + 1, test_loss / test_total, 100 * correct / test_total))

    torch.save(net, 'model.pt')


train()
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/59e2728dc730962142ce3039181e02fd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">地图服务 纬度、经度对应坐标轴x,y</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/32802b1c4d83e1b0be37c078264b671c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【H5】  svg画贝塞尔曲线方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>