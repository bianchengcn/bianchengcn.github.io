<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>BEV感知（1）--BEV感知算法 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="BEV感知（1）--BEV感知算法" />
<meta property="og:description" content="目录
一、BEV感知算法
1、BEV感知
2、BEV算法数据形式 二、BEV开源数据集 1、KITTI
2、nuScenes
三、BEV感知方法
1、BEV LiDAR
2、BEV Camera
3、BEV Fusion 四、BEV感知算法优劣
一、BEV感知算法 BEV（Bird&#39;s Eye View）即鸟瞰图，通过使用摄像头，雷达，激光雷达等收集数据，通过计算机视觉、深度学习、机器学习等技术对数据进行处理和分析，从而实现对交通、障碍物、道路条件等信息的感知和识别，主要应用于自动驾驶领域。
1、BEV感知 BEV感知是一个建立在众多子任务上的一个概念，包括分类、检测、分割、跟踪、预测、规划等，通过使用鸟瞰图来进行各项计算机视觉相关任务。
BEV感知输入：毫米波雷达（Radar）、激光雷达点云（LiDAR）、相机图像等，依据输入的不同，BEV感知算法有进一步的划分。
对于BEV感知任务中一般有BEV Camera（图像），BEV Fusion（图像和点云融合），BEV LiDAR（点云）三种方式。
2、BEV算法数据形式 BEV算法数据形式一般有纯图像、点云、图像点云融合三种形式。
（1）纯图像
纯图像的输入一般就是BEVCamera感知模型，是完全基于车载摄像机的图像进行提取特征，感知当前场景的车辆、行人等任务的。其中介绍一个最为典型的BEVCamera——BEVFormer。
BEVFormer利用了基于transformer的Encoder，通过网格形式的BEV queries来利用空间和时间进行交互，从而设计可学习的BEV和注意力模块，在nuScenes测试集上对3D目标检测和地图分割任务中实现最优性能。
下图为BEVFormer的完整网络结构，输入多视角图像，经过backbone（一般为Resnet）之后，经过提取网络（前馈网络&#43;时空注意力机制模块）得到BEV特征，最后接一个图像分割或检测的头组成完整的网络输出。
（2）点云
点云就是场景中若干点的组成集合，具有稀疏性、无序性，是一种3D表征，一般来说，点云是通过激光雷达对场景扫描得到的，下图为一个场景的点云图。
对于点云问题，由于点过于稀疏，数量巨大，一般有两种处理方法（聚合方法），分别是Point-based和Voxel-based。
Point-based处理点云数据，可以处理高密度的点云数据，更加灵活，但计算复杂度高，不规则性高。
Voxel-based处理体素数据，使数据结构更加规则，更好的表示体积信息，但收到网格限制，会丢失部分信息。 （3）图像和点云融合
下图为纯图像提取特征和Fusion形式的提取特征的比较，BEVFusion的特征是将Camera格式和LiDAR格式分别提取得到BEV特征后再进行融合。
二、BEV开源数据集 1、KITTI KITTI数据集通过车载相机、激光雷达等传感器进行采集，采集自德国卡尔斯鲁厄街道，数据规模为14999张图像及其对应点云，其中7481张训练集，7518张测试集，KITTI数据集标注了车、行人、骑车的人三类，共计80256个标注对象，下图为标注平台。
在官方论文中可以了解到，标注平台的传感器并不是统一坐标系的，存在R、T关系，另外对于摄像机的外参数做了统一。
KITTI数据表示法：
（1）第1字节 Pedestrian代表行人
（2）第2字节 “0.00” 表示是否被截断，处于0~1范围内，越大被截断遮挡的程度越大
（3）第3字节 “0” 表示行人不存在遮挡，离散值0（不存在遮挡）,1（部分遮挡）,2（严重遮挡）,3（不确定）
（4）第4字节 “-0.20” 角度信息
（4）第5-8字节 “712.40, 143.00” 2D平面左上角坐标，“810.73 307.92”2D平面右下角坐标
（5）第9-11字节 “1.89 0.48 1.20” 3D平面上的高宽长（h,w,l），单位m
（6）第12-14字节 “1.84 1.47 8." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/86d5b11fb2c07de3305df9a7b4c34220/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-31T15:02:58+08:00" />
<meta property="article:modified_time" content="2024-01-31T15:02:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">BEV感知（1）--BEV感知算法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95" rel="nofollow">一、BEV感知算法</a></p> 
<p id="1%E3%80%81BEV%E6%84%9F%E7%9F%A5-toc" style="margin-left:80px;"><a href="#1%E3%80%81BEV%E6%84%9F%E7%9F%A5" rel="nofollow">1、BEV感知</a></p> 
<p id="2%E3%80%81BEV%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E5%BD%A2%E5%BC%8F%C2%A0-toc" style="margin-left:80px;"><a href="#2%E3%80%81BEV%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E5%BD%A2%E5%BC%8F%C2%A0" rel="nofollow">2、BEV算法数据形式 </a></p> 
<p id="%E4%BA%8C%E3%80%81BEV%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%E3%80%81BEV%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0" rel="nofollow">二、BEV开源数据集 </a></p> 
<p id="1%E3%80%81KITTI-toc" style="margin-left:80px;"><a href="#1%E3%80%81KITTI" rel="nofollow">1、KITTI</a></p> 
<p id="2%E3%80%81nuScenes-toc" style="margin-left:80px;"><a href="#2%E3%80%81nuScenes" rel="nofollow">2、nuScenes</a></p> 
<p id="%E4%B8%89%E3%80%81BEV%E6%84%9F%E7%9F%A5%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E4%B8%89%E3%80%81BEV%E6%84%9F%E7%9F%A5%E6%96%B9%E6%B3%95" rel="nofollow">三、BEV感知方法</a></p> 
<p id="1%E3%80%81BEV%20LiDAR-toc" style="margin-left:80px;"><a href="#1%E3%80%81BEV%20LiDAR" rel="nofollow">1、BEV LiDAR</a></p> 
<p id="2%E3%80%81BEV%20Camera-toc" style="margin-left:80px;"><a href="#2%E3%80%81BEV%20Camera" rel="nofollow">2、BEV Camera</a></p> 
<p id="3%E3%80%81BEV%20Fusion%C2%A0-toc" style="margin-left:80px;"><a href="#3%E3%80%81BEV%20Fusion%C2%A0" rel="nofollow">3、BEV Fusion </a></p> 
<p id="%E5%9B%9B%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95%E4%BC%98%E5%8A%A3-toc" style="margin-left:40px;"><a href="#%E5%9B%9B%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95%E4%BC%98%E5%8A%A3" rel="nofollow">四、BEV感知算法优劣</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h3 id="%E4%B8%80%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95">一、BEV感知算法</h3> 
<p>        BEV（Bird's Eye View）即鸟瞰图，通过使用摄像头，雷达，激光雷达等收集数据，通过计算机视觉、深度学习、机器学习等技术对数据进行处理和分析，从而实现对交通、障碍物、道路条件等信息的感知和识别，主要应用于自动驾驶领域。</p> 
<h4 id="1%E3%80%81BEV%E6%84%9F%E7%9F%A5">1、BEV感知</h4> 
<p>        BEV感知是一个建立在众多子任务上的一个概念，包括分类、检测、分割、跟踪、预测、规划等，通过使用鸟瞰图来进行各项计算机视觉相关任务。</p> 
<p>        BEV感知输入：毫米波雷达（Radar）、激光雷达点云（LiDAR）、相机图像等，依据输入的不同，BEV感知算法有进一步的划分。</p> 
<p>        对于BEV感知任务中一般有BEV Camera（图像），BEV Fusion（图像和点云融合），BEV LiDAR（点云）三种方式。</p> 
<p class="img-center"><img alt="" height="160" src="https://images2.imgbox.com/65/29/1LOztj0L_o.png" width="520"></p> 
<h4 id="2%E3%80%81BEV%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E5%BD%A2%E5%BC%8F%C2%A0">2、BEV算法数据形式 </h4> 
<p>        BEV算法数据形式一般有纯图像、点云、图像点云融合三种形式。</p> 
<p>（1）纯图像</p> 
<p>        纯图像的输入一般就是BEVCamera感知模型，是完全基于车载摄像机的图像进行提取特征，感知当前场景的车辆、行人等任务的。其中介绍一个最为典型的BEVCamera——BEVFormer。</p> 
<p>        BEVFormer利用了基于transformer的Encoder，通过网格形式的BEV queries来利用空间和时间进行交互，从而设计可学习的BEV和注意力模块，在nuScenes测试集上对3D目标检测和地图分割任务中实现最优性能。</p> 
<p>        下图为BEVFormer的完整网络结构，输入多视角图像，经过backbone（一般为Resnet）之后，经过提取网络（前馈网络+时空注意力机制模块）得到BEV特征，最后接一个图像分割或检测的头组成完整的网络输出。</p> 
<p class="img-center"><img alt="" height="284" src="https://images2.imgbox.com/da/18/6Ldjwhe8_o.png" width="550"></p> 
<p>（2）点云</p> 
<p>        点云就是场景中若干点的组成集合，具有稀疏性、无序性，是一种3D表征，一般来说，点云是通过激光雷达对场景扫描得到的，下图为一个场景的点云图。</p> 
<p class="img-center"><img alt="" height="144" src="https://images2.imgbox.com/53/ed/rCMWI5dp_o.png" width="250"></p> 
<p>        对于点云问题，由于点过于稀疏，数量巨大，一般有两种处理方法（聚合方法），分别是Point-based和Voxel-based。</p> 
<p>        Point-based处理点云数据，可以处理高密度的点云数据，更加灵活，但计算复杂度高，不规则性高。</p> 
<p>        Voxel-based处理体素数据，使数据结构更加规则，更好的表示体积信息，但收到网格限制，会丢失部分信息。   </p> 
<p>                                 <img alt="" height="142" src="https://images2.imgbox.com/30/86/PPmDnfTT_o.png" width="150">             <img alt="" height="146" src="https://images2.imgbox.com/a2/5e/SmBKdHlD_o.png" width="150">    </p> 
<p>（3）图像和点云融合</p> 
<p>        下图为纯图像提取特征和Fusion形式的提取特征的比较，BEVFusion的特征是将Camera格式和LiDAR格式分别提取得到BEV特征后再进行融合。</p> 
<p class="img-center"><img alt="" height="226" src="https://images2.imgbox.com/3a/93/2asfR9m3_o.png" width="560"></p> 
<h3 id="%E4%BA%8C%E3%80%81BEV%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0">二、BEV开源数据集 </h3> 
<h4 id="1%E3%80%81KITTI">1、KITTI</h4> 
<p>         KITTI数据集通过车载相机、激光雷达等传感器进行采集，采集自德国卡尔斯鲁厄街道，数据规模为14999张图像及其对应点云，其中7481张训练集，7518张测试集，KITTI数据集标注了车、行人、骑车的人三类，共计80256个标注对象，下图为标注平台。</p> 
<p class="img-center"><img alt="" height="349" src="https://images2.imgbox.com/9d/fa/Hgdcf3ML_o.png" width="250"></p> 
<p>        在官方论文中可以了解到，标注平台的传感器并不是统一坐标系的，存在R、T关系，另外对于摄像机的外参数做了统一。</p> 
<p class="img-center"><img alt="" height="202" src="https://images2.imgbox.com/df/a4/8qs6HG28_o.png" width="650"></p> 
<p>        KITTI数据表示法：</p> 
<p>（1）第1字节 Pedestrian代表行人</p> 
<p>（2）第2字节 “0.00” 表示是否被截断，处于0~1范围内，越大被截断遮挡的程度越大</p> 
<p>（3）第3字节 “0” 表示行人不存在遮挡，离散值0（不存在遮挡）,1（部分遮挡）,2（严重遮挡）,3（不确定）</p> 
<p>（4）第4字节 “-0.20” 角度信息</p> 
<p>（4）第5-8字节 “712.40, 143.00” 2D平面左上角坐标，“810.73 307.92”2D平面右下角坐标</p> 
<p>（5）第9-11字节 “1.89 0.48 1.20” 3D平面上的高宽长（h,w,l），单位m</p> 
<p>（6）第12-14字节 “1.84 1.47 8.41” 3D平面的坐标</p> 
<p>（7）第15字节 “0.01” 置信度</p> 
<p class="img-center"><img alt="" height="256" src="https://images2.imgbox.com/0b/4b/WtcRJCeL_o.png" width="650"></p> 
<h4 id="2%E3%80%81nuScenes">2、nuScenes</h4> 
<p class="img-center"><img alt="" height="215" src="https://images2.imgbox.com/87/5c/nLCmpekD_o.png" width="420"></p> 
<p>        nuScenes要比KITTI数据集更加丰富一些，nuScenes采集了不同城市中的1000个场景，传感器系统包括6个摄像机、5个毫米波雷达、1个激光雷达、六轴传感器IMU和GPS。</p> 
<p>        nuScenes数据包含140万个相机图像、39万个激光雷达扫描结果、140万个毫米波雷达扫描结果，标注了32类共计140万个标注对象。</p> 
<blockquote> 
 <p>详细的介绍请看：<a href="https://blog.csdn.net/qq_47233366/article/details/123450282?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170668202516800186545230%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=170668202516800186545230&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-123450282-null-null.142%5Ev99%5Econtrol&amp;utm_term=nuScenes&amp;spm=1018.2226.3001.4187" title="对Nuscenes数据集一无所知，手把手带你玩转Nuscenes数据集_nuscenes数据集token作用">对Nuscenes数据集一无所知，手把手带你玩转Nuscenes数据集_nuscenes数据集token作用</a></p> 
</blockquote> 
<p class="img-center"><img alt="" height="270" src="https://images2.imgbox.com/55/da/VUj6jWR4_o.png" width="520"></p> 
<p><strong>nuScenes数据集格式</strong>：maps、samples、sweeps、v1.0-*。</p> 
<p><strong>        maps</strong>：所有地图文件的文件夹，光栅化的png图像和矢量化的json文件用于后续决策，不用于检测和分割。</p> 
<p><strong>        samples</strong>：关键帧样本的传感器数据，已标注图像</p> 
<p><strong>        sweeps</strong>：中间帧传感器数据，未标注数据</p> 
<p><strong>        v1.0-*</strong>：其余json表</p> 
<p class="img-center"><img alt="" height="251" src="https://images2.imgbox.com/cc/b8/0ND7zeDR_o.png" width="250"></p> 
<h3 id="%E4%B8%89%E3%80%81BEV%E6%84%9F%E7%9F%A5%E6%96%B9%E6%B3%95">三、BEV感知方法</h3> 
<h4 id="1%E3%80%81BEV%20LiDAR">1、BEV LiDAR</h4> 
<p>         BEV LiDAR模式分为Pre-BEV（先提取特征，再生成BEV特征，代表算法PV-RCNN），Post-BEV（先转换为BEV特征，再提取特征，代表算法PointPillar）。下图为两种模式。</p> 
<p class="img-center"><img alt="" height="151" src="https://images2.imgbox.com/4e/13/9gbVymkH_o.png" width="520"></p> 
<p>        <strong>PV-RCNN网络：</strong></p> 
<p>        以点云输入，提取BEV特征，应用于分割与检测。点云经过通过3D稀疏网络提取体素特征，通过关键点采样提取点特征，并将体素特征和点特征融合得到BEV特征，再PV-RCNN网络中得到BEV特征是简单的将3D点云向2D方向做投影得到BEV特征。</p> 
<p class="img-center"><img alt="" height="214" src="https://images2.imgbox.com/3c/88/DED3Ag1X_o.png" width="520"></p> 
<h4 id="2%E3%80%81BEV%20Camera">2、BEV Camera</h4> 
<p>         BEV Camera模型输入相机图像，通过2D特征提取网络（特征共享），2D-3D视角转换网络（转换到3D可以看到俯视图），3Ddecoder检测模块，可以对照上面的BEV Former来看这三个模块。</p> 
<p class="img-center"><img alt="" height="157" src="https://images2.imgbox.com/55/25/Rc2ftLVp_o.png" width="550"></p> 
<h4 id="3%E3%80%81BEV%20Fusion%C2%A0">3、BEV Fusion </h4> 
<p>         BEV主体模块分为2D图像处理流程，3D点云处理流程，BEV融合感知流程。BEV Fusion的重点在于如何进行融合，融合于两者提取BEV特征后，得到融合的BEV特征。</p> 
<h3 id="%E5%9B%9B%E3%80%81BEV%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95%E4%BC%98%E5%8A%A3">四、BEV感知算法优劣</h3> 
<p>        对比通用3D检测结构和BEV感知结构，3D检测将2D转换到3D与3D点云相融合进行提取，而BEV感知结构将2D和3D转换为BEV结构进行融合。</p> 
<p class="img-center"><img alt="" height="298" src="https://images2.imgbox.com/b3/27/sNTZmm6Y_o.png" width="520"></p> 
<p>        BEV感知算法可以对于2D图像的尺度变化和遮挡问题影响小，有利于利用视觉图像远距离识别物体，可以通过多使用Camera减少LiDAR的使用来降低成本，但在3D检测任务中仍然比现有的点云方案有一定差距。</p> 
<p>        下图为Tesla、地平线、毫末对BEV感知的网络结构搭建。</p> 
<p class="img-center"><img alt="" height="277" src="https://images2.imgbox.com/b8/40/WH74hkJU_o.png" width="520"></p> 
<p> </p> 
<blockquote> 
 <p> 参考视频：自动驾驶之心的BEV相关课程</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fef1bc457dedaca9dd1b1c48de95d303/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Windows11通过Hyper-V创建VM，然后通过vscode连接vm进行开发</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/522a610c44257ce0cf0d5910732604bd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MySQL之DML操作</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>