<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用新版FLIR (FLIR_ADAS_v2) 红外数据集训练基于pytorch的YOLOv7模型 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用新版FLIR (FLIR_ADAS_v2) 红外数据集训练基于pytorch的YOLOv7模型" />
<meta property="og:description" content="简介 今年7月份YOLOv7发布，其识别速度和准确度在5 FPS 到 160 FPS范围内远超目前已知的目标检测器FLIR在2022.1.19发布了新版的FLIR_ADAS_v2，相较于上一代的FLIR_1_3，新版有着更多的类别和数量更丰富的图像。现有的博客中关于新版FLIR的使用教学少只有少，加上暑假期间曾使用FLIR_ADAS_v2来训练模型以提高其对红外热图像的识别能力，便决定记录分享一下。本文章主要介绍如何使用FLIR_ADAS_v2中的thermal image来训练基于pytorch的YOLOv7模型若有不足，也欢迎大家指正批评 FLIR_ADAS_v2数据集下载 官方下载链接​​​​​ 如果官方下载失败可以使用笔者上传的夸克网盘 我用夸克网盘分享了「FLIR_ADAS_v2.zip」，点击链接即可保存。打开「夸克APP」，无需下载在线播放视频，畅享原画5倍速，支持电视投屏。
链接：https://pan.quark.cn/s/6ce060c06196
YOLOv7模型下载 在此使用的YOLOv7模型链接 数据集的预处理 将单个json文件转换为多个xml文件 如何将单个annotation json文件转换为多个xml文件，可以参考这篇博客将json文件转换为多个xml文件https://blog.csdn.net/Jiuyee/article/details/127332489 将多个xml文件转换为YOLO所需的txt文件并分类 如何将多个annotation xml文件转换为YOLO所需的txt文件，并依据train和val进行分类，可以参考这篇博客将多个annotation xml文件转换为多个annotation txt文件https://blog.csdn.net/Jiuyee/article/details/127334453
查看标注情况 可以根据以下代码查看数据集的标注情况 根据YOLO标注文件 生成标注图像https://blog.csdn.net/Jiuyee/article/details/131495008
如果转换有问题或者转换失败可以参考我转换的数据集 xml_share文件夹存储了所有转换好的xml文件dataPreProcess压缩包中存的是相关的txt标签以及所有用到的转换代码 我用夸克网盘分享了「FLIR_ADAS_v2」，点击链接即可保存。打开「夸克APP」，无需下载在线播放视频，畅享原画5倍速，支持电视投屏。
链接：https://pan.quark.cn/s/d0b14ace3bfd
提取码：uqar
设置YOLOv7 数据集导入YOLOv7 在YOLOv7项目文件夹中新建文件夹并命名（笔者以data4为例）
将预处理完后的images文件夹和labels文件夹复制到新建文件夹下
获得list文件 相较于YOLOv5，YOLOv7需要在数据集中提供单独的train_list.txt文件和val_list.txt文件，以提供图片的路径内容如所示 大家可写一个小代码，使用os库从文件夹中读取图片名称并写入到txt文件中在这里提供笔者所写的 import os train_path = r&#34;data4/images/train/&#34; val_path = r&#34;data4/images/val/&#34; out = r&#34;data4/&#34; train = os.listdir(train_path) val = os.listdir(val_path) for i in train: with open(out&#43;&#39;train_list.txt&#39;, &#39;a&#43;&#39;) as f: f.write(&#34;data4/images/train/&#34;&#43; i &#43; &#39;\n&#39;) for i in val: with open(out&#43;&#39;val_list." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/4609130902568fd69e34714065e897e5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-02T16:05:43+08:00" />
<meta property="article:modified_time" content="2023-07-02T16:05:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用新版FLIR (FLIR_ADAS_v2) 红外数据集训练基于pytorch的YOLOv7模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>简介</h2> 
<ul><li>今年7月份YOLOv7发布，其识别速度和准确度在5 FPS 到 160 FPS范围内远超目前已知的目标检测器</li><li>FLIR在2022.1.19发布了新版的FLIR_ADAS_v2，相较于上一代的FLIR_1_3，新版有着更多的类别和数量更丰富的图像。</li><li>现有的博客中关于新版FLIR的使用教学少只有少，加上暑假期间曾使用FLIR_ADAS_v2来训练模型以提高其对红外热图像的识别能力，便决定记录分享一下。</li><li>本文章主要介绍如何使用<strong>FLIR_ADAS_v2</strong>中的<strong>thermal image</strong>来训练基于<strong>pytorch</strong>的<strong>YOLOv7</strong>模型</li><li><strong>若有不足，也欢迎大家指正批评</strong></li></ul> 
<h3>FLIR_ADAS_v2数据集下载</h3> 
<ul><li><a href="https://www.flir.com/oem/adas/adas-dataset-form/#anchor29" rel="nofollow" title="官方下载链接​​​​​">官方下载链接​​​​​</a></li><li> 如果官方下载失败可以使用笔者上传的夸克网盘</li></ul> 
<blockquote> 
 <p>我用夸克网盘分享了「FLIR_ADAS_v2.zip」，点击链接即可保存。打开「夸克APP」，无需下载在线播放视频，畅享原画5倍速，支持电视投屏。<br> 链接：https://pan.quark.cn/s/6ce060c06196</p> 
</blockquote> 
<h2>YOLOv7模型下载</h2> 
<ul><li><a href="https://github.com/WongKinYiu/yolov7" title="在此使用的YOLOv7模型链接">在此使用的YOLOv7模型链接</a></li></ul> 
<h2>数据集的预处理</h2> 
<h4>将单个json文件转换为多个xml文件</h4> 
<ul><li>如何将单个annotation json文件转换为多个xml文件，可以参考这篇博客<a class="link-info has-card" href="https://blog.csdn.net/Jiuyee/article/details/127332489" title="将json文件转换为多个xml文件"><span class="link-card-box"><span class="link-title">将json文件转换为多个xml文件</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/9d/94/TeqbIGTK_o.png">https://blog.csdn.net/Jiuyee/article/details/127332489</span></span></a></li></ul> 
<h4> 将多个xml文件转换为YOLO所需的txt文件并分类</h4> 
<ul><li> <p>如何将多个annotation xml文件转换为YOLO所需的txt文件，并依据train和val进行分类，可以参考这篇博客<a class="link-info has-card" href="https://blog.csdn.net/Jiuyee/article/details/127334453" title="将多个annotation xml文件转换为多个annotation txt文件"><span class="link-card-box"><span class="link-title">将多个annotation xml文件转换为多个annotation txt文件</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/4d/85/NULFpw75_o.png">https://blog.csdn.net/Jiuyee/article/details/127334453</span></span></a></p> </li></ul> 
<h4> 查看标注情况</h4> 
<ul><li>可以根据以下代码查看数据集的标注情况</li></ul> 
<p><a class="has-card" href="https://blog.csdn.net/Jiuyee/article/details/131495008" title="根据YOLO标注文件 生成标注图像"><span class="link-card-box"><span class="link-title">根据YOLO标注文件 生成标注图像</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/35/6a/B1B5xpFN_o.png" alt="icon-default.png?t=N5K3">https://blog.csdn.net/Jiuyee/article/details/131495008</span></span></a></p> 
<h4>如果转换有问题或者转换失败可以参考我转换的数据集 </h4> 
<ul><li>xml_share文件夹存储了所有转换好的xml文件</li><li>dataPreProcess压缩包中存的是相关的txt标签以及所有用到的转换代码</li></ul> 
<blockquote> 
 <p>我用夸克网盘分享了「FLIR_ADAS_v2」，点击链接即可保存。打开「夸克APP」，无需下载在线播放视频，畅享原画5倍速，支持电视投屏。<br> 链接：https://pan.quark.cn/s/d0b14ace3bfd<br> 提取码：uqar</p> 
</blockquote> 
<h2>设置YOLOv7</h2> 
<h4>数据集导入YOLOv7</h4> 
<ul><li> <p>在YOLOv7项目文件夹中新建文件夹并命名（笔者以data4为例）</p> </li><li> <p> 将预处理完后的<strong>images文件夹</strong>和<strong>labels文件夹</strong>复制到新建文件夹下</p> </li></ul> 
<p><img alt="" height="148" src="https://images2.imgbox.com/78/9d/bAqCrgxj_o.png" width="473"></p> 
<h4>获得list文件 </h4> 
<ul><li>相较于YOLOv5，YOLOv7需要在数据集中提供单独的<strong>train_list.txt文件</strong>和<strong>val_list.txt文件</strong>，以提供图片的路径</li><li>内容如所示</li></ul> 
<p><img alt="" height="537" src="https://images2.imgbox.com/57/d5/3r0MEQWd_o.png" width="764"></p> 
<ul><li> 大家可写一个小代码，使用os库从文件夹中读取图片名称并写入到txt文件中</li><li>在这里提供笔者所写的 <pre><code class="language-python">import os

train_path = r"data4/images/train/"
val_path = r"data4/images/val/"

out = r"data4/"

train = os.listdir(train_path)
val = os.listdir(val_path)

for i in train:
    with open(out+'train_list.txt', 'a+') as f:
        f.write("data4/images/train/"+ i + '\n')

for i in val:
    with open(out+'val_list.txt', 'a+') as f:
        f.write("data4/images/val/"+ i + '\n')</code></pre> </li><li>将<strong>txt</strong>文件放到<strong>新建文件夹</strong>下</li></ul> 
<p><img alt="" height="262" src="https://images2.imgbox.com/5c/a8/lLaLHEpQ_o.png" width="479"></p> 
<ul><li>注：cache文件为训练时生成，图中所示不用理会 </li></ul> 
<h4>设置类文件</h4> 
<ul><li> <p>在<strong>data文件夹</strong>下复制<strong>coco.yaml</strong>，并命名为<strong>flir.yaml</strong></p> </li><li> <p> 将<strong>train</strong>、<strong>val</strong>的<strong>路径</strong>设置为<strong>对应txt文件</strong>的<strong>路径</strong></p> </li><li> <p>根据自己需求修改<strong>类的数量和名称</strong></p> </li></ul> 
<p><img alt="" height="484" src="https://images2.imgbox.com/8e/bc/RMa7bJba_o.png" width="1200"></p> 
<h4>更改train.py参数</h4> 
<ul><li> <p> 更改<strong>yaml</strong>路径，将其设置为创建的<strong>flir.yaml</strong>文件位置</p> </li><li> <p>根据自己需求和电脑性能设置<strong>epochs</strong>、<strong>workers</strong>、<strong>cuda</strong>、<strong>batch_size</strong>等参数</p> </li></ul> 
<p><img alt="" height="920" src="https://images2.imgbox.com/0b/46/0I4fTo8X_o.png" width="1200"></p> 
<h2>开始训练</h2> 
<h4>运行train.py</h4> 
<p><img alt="" height="514" src="https://images2.imgbox.com/3a/6b/qBvfZJfl_o.png" width="1200"></p> 
<h4> 结果分析</h4> 
<ul><li>开始训练后，在<strong>runs-&gt;train-&gt;exp</strong>文件夹中可查看各种训练结果</li></ul> 
<p><img alt="" height="824" src="https://images2.imgbox.com/89/d7/5Bkr6pDg_o.png" width="1200"></p> 
<h4><img alt="" height="1200" src="https://images2.imgbox.com/89/16/D0cROBJi_o.png" width="1200"></h4> 
<p> <img alt="" height="1038" src="https://images2.imgbox.com/26/3c/tzra5BaV_o.png" width="1200"></p> 
<p></p> 
<h2>使用训练好的权重进行图像识别</h2> 
<ul><li>打开<strong>detect.py</strong></li><li> <p>将需要进行图像识别的图像放入<strong>inference-&gt;images</strong>中</p> </li><li> <p>在<strong>runs-&gt;train-&gt;exp-&gt;weights</strong>中选择权重并设置路径</p> </li></ul> 
<p><img alt="" height="747" src="https://images2.imgbox.com/e2/4f/T5cxY0B7_o.png" width="1200"></p> 
<ul><li> 运行<strong>detect.py</strong></li></ul> 
<p><img alt="" height="581" src="https://images2.imgbox.com/e6/93/Q4yEPuMg_o.png" width="931"></p> 
<h2>识别结果</h2> 
<p><img alt="" height="512" src="https://images2.imgbox.com/45/14/VxFvpn2t_o.png" width="640"></p> 
<p> <img alt="" height="512" src="https://images2.imgbox.com/0b/2b/AuXk39jN_o.jpg" width="640"></p> 
<p><img alt="" height="512" src="https://images2.imgbox.com/f7/14/PQQEi3JR_o.jpg" width="640"></p> 
<p><img alt="" height="512" src="https://images2.imgbox.com/ad/59/SgaQTSvh_o.jpg" width="640"></p> 
<h2>总结</h2> 
<ul><li>相较于Faster RCNN、Efficientdet、YOLOv5等模型，YOLOv7展现出了强大的识别精确度和识别速度，并且有着较短的训练时间和更低的loss</li><li>只能说AB大佬NB！</li></ul> 
<h2>相关推荐</h2> 
<p><a class="link-info has-card" href="https://blog.csdn.net/Jiuyee/article/details/127316297" title="使用新版FLIR (FLIR_ADAS_v2) 训练Faster RCNN模型"><span class="link-card-box"><span class="link-title">使用新版FLIR (FLIR_ADAS_v2) 训练Faster RCNN模型</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/08/a1/NGyIXzf5_o.png">https://blog.csdn.net/Jiuyee/article/details/127316297</span></span></a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9b83fe3c93ae009c3f595fb170debcbc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ivx低代码开发平台</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b84e8ffe04f9948b445dde1806d2cb59/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">抓取猫眼电影排行上</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>