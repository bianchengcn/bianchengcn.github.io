<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Redis常用知识笔记 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Redis常用知识笔记" />
<meta property="og:description" content="目录 0 配置文件内容0.1 ###Units单位###0.2. ###INCLUDES包含###0.3 ######### NETWORK #####（网络配置*重点）0.4 ###GENERAL通用###0.5 ###SECURITY安全###0.6 ###### CLIENTS######### 1 数据类型1.1 Key1.2 String（字符串）数据结构常用命令 1.3List（列表）数据结构常用命令 1.4 Set（集合）数据结构常用命令 1.5 Zset(sorted set) 有序集合数据结构常用命令 1.6 Hash（哈希）数据结构常用命令 1.7 Bitmaps数据结构常用命令 1.8 HyperLogLog常用命令 1.9 Geospatial作用常用命令 2 Redis事务与锁机制2.1 Redis事务的三特性2.1 Redis事务的开启与执行2.2 Redis的锁机制Redis锁的开启与关闭解决乐观锁可能导致的库存遗留问题 3 Redis持久化3.1 RDB（Redis Data Base）生成文件 3.2 AOF（Append Of File）生成文件AOF启动/修复/恢复同步频率设置 3.3 两种方法优劣对比 4 主从复制4.1 如何开启主从复制4.2 常用主从复制策略一主二仆薪火相传反客为主哨兵模式(sentinel)-反客为主自动版本 4.3 复制原理 5 集群5.1 集群启动方式5.2 集群数据分配与查询逻辑常用命令故障恢复 5.3 集群的不足 6 Redis常见应用问题6.1 缓存穿透6.2 缓存击穿6.3 缓存雪崩 TCP端口6379，默认16个库，从0开始
所有库密码相同
Redis是单线程&#43;多路IO复用技术
启动命令
[root@xgms_VM-8-13-centos ~]# redis-server /etc/redis." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/169106a185d40d20d8f9c0978a242c09/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-15T14:03:31+08:00" />
<meta property="article:modified_time" content="2023-04-15T14:03:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Redis常用知识笔记</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#0__22" rel="nofollow">0 配置文件内容</a></li><li><ul><li><a href="#01%09Units_25" rel="nofollow">0.1 ###Units单位###</a></li><li><a href="#02%09INCLUDES_49" rel="nofollow">0.2. ###INCLUDES包含###</a></li><li><a href="#03__NETWORK__72" rel="nofollow">0.3 ######### NETWORK #####（网络配置*重点）</a></li><li><a href="#04_%09GENERAL_176" rel="nofollow">0.4 ###GENERAL通用###</a></li><li><a href="#05_%09SECURITY_295" rel="nofollow">0.5 ###SECURITY安全###</a></li><li><a href="#06__CLIENTS_330" rel="nofollow">0.6 ###### CLIENTS#########</a></li></ul> 
  </li><li><a href="#1__356" rel="nofollow">1 数据类型</a></li><li><ul><li><a href="#11_Key_358" rel="nofollow">1.1 Key</a></li><li><a href="#12_String_373" rel="nofollow">1.2 String（字符串）</a></li><li><ul><li><a href="#_379" rel="nofollow">数据结构</a></li><li><a href="#_388" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#13List_413" rel="nofollow">1.3List（列表）</a></li><li><ul><li><a href="#_417" rel="nofollow">数据结构</a></li><li><a href="#_422" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#14_Set_436" rel="nofollow">1.4 Set（集合）</a></li><li><ul><li><a href="#_440" rel="nofollow">数据结构</a></li><li><a href="#_445" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#15_Zsetsorted_set__459" rel="nofollow">1.5 Zset(sorted set) 有序集合</a></li><li><ul><li><a href="#_460" rel="nofollow">数据结构</a></li><li><a href="#_464" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#16_Hash_474" rel="nofollow">1.6 Hash（哈希）</a></li><li><ul><li><a href="#_475" rel="nofollow">数据结构</a></li><li><a href="#_480" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#17_Bitmaps_490" rel="nofollow">1.7 Bitmaps</a></li><li><ul><li><a href="#_491" rel="nofollow">数据结构</a></li><li><a href="#_494" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#18_HyperLogLog_507" rel="nofollow">1.8 HyperLogLog</a></li><li><ul><li><a href="#_513" rel="nofollow">常用命令</a></li></ul> 
   </li><li><a href="#19_Geospatial_517" rel="nofollow">1.9 Geospatial</a></li><li><ul><li><a href="#_520" rel="nofollow">作用</a></li><li><a href="#_523" rel="nofollow">常用命令</a></li></ul> 
  </li></ul> 
  </li><li><a href="#2_Redis_528" rel="nofollow">2 Redis事务与锁机制</a></li><li><ul><li><a href="#21_Redis_530" rel="nofollow">2.1 Redis事务的三特性</a></li><li><a href="#21_Redis_541" rel="nofollow">2.1 Redis事务的开启与执行</a></li><li><a href="#22_Redis_621" rel="nofollow">2.2 Redis的锁机制</a></li><li><ul><li><a href="#Redis_630" rel="nofollow">Redis锁的开启与关闭</a></li><li><a href="#_662" rel="nofollow">解决乐观锁可能导致的库存遗留问题</a></li></ul> 
  </li></ul> 
  </li><li><a href="#3_Redis_668" rel="nofollow">3 Redis持久化</a></li><li><ul><li><a href="#31_RDBRedis_Data_Base_676" rel="nofollow">3.1 RDB（Redis Data Base）</a></li><li><ul><li><a href="#_690" rel="nofollow">生成文件</a></li></ul> 
   </li><li><a href="#32_AOFAppend_Of_File_753" rel="nofollow">3.2 AOF（Append Of File）</a></li><li><ul><li><a href="#_765" rel="nofollow">生成文件</a></li><li><a href="#AOF_826" rel="nofollow">AOF启动/修复/恢复</a></li><li><a href="#_837" rel="nofollow">同步频率设置</a></li></ul> 
   </li><li><a href="#33__843" rel="nofollow">3.3 两种方法优劣对比</a></li></ul> 
  </li><li><a href="#4__852" rel="nofollow">4 主从复制</a></li><li><ul><li><a href="#41__858" rel="nofollow">4.1 如何开启主从复制</a></li><li><a href="#42__903" rel="nofollow">4.2 常用主从复制策略</a></li><li><ul><li><a href="#_905" rel="nofollow">一主二仆</a></li><li><a href="#_908" rel="nofollow">薪火相传</a></li><li><a href="#_915" rel="nofollow">反客为主</a></li><li><a href="#sentinel_920" rel="nofollow">哨兵模式(sentinel)-反客为主自动版本</a></li></ul> 
   </li><li><a href="#43__940" rel="nofollow">4.3 复制原理</a></li></ul> 
  </li><li><a href="#5__949" rel="nofollow">5 集群</a></li><li><ul><li><a href="#51__958" rel="nofollow">5.1 集群启动方式</a></li><li><a href="#52__1021" rel="nofollow">5.2 集群数据分配与查询逻辑</a></li><li><ul><li><a href="#_1043" rel="nofollow">常用命令</a></li><li><a href="#_1075" rel="nofollow">故障恢复</a></li></ul> 
   </li><li><a href="#53__1083" rel="nofollow">5.3 集群的不足</a></li></ul> 
  </li><li><a href="#6_Redis_1090" rel="nofollow">6 Redis常见应用问题</a></li><li><ul><li><a href="#61__1092" rel="nofollow">6.1 缓存穿透</a></li><li><a href="#62__1111" rel="nofollow">6.2 缓存击穿</a></li><li><a href="#63__1127" rel="nofollow">6.3 缓存雪崩</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<p>TCP端口6379，默认16个库，从0开始<br> 所有库密码相同<br> Redis是单线程+多路IO复用技术<br> 启动命令</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>root@xgms_VM-8-13-centos ~<span class="token punctuation">]</span><span class="token comment"># redis-server /etc/redis.conf</span>
<span class="token punctuation">[</span>root@xgms_VM-8-13-centos ~<span class="token punctuation">]</span><span class="token comment"># ps -ef|grep redis</span>
root      <span class="token number">3201</span>     <span class="token number">1</span>  <span class="token number">0</span> <span class="token number">12</span>:30 ?        00:00:00 redis-server *:6379
root      <span class="token number">3250</span>  <span class="token number">2421</span>  <span class="token number">0</span> <span class="token number">12</span>:30 pts/9    00:00:00 <span class="token function">grep</span> --color<span class="token operator">=</span>auto redis
root     <span class="token number">26370</span> <span class="token number">26127</span>  <span class="token number">0</span> <span class="token number">11</span>:59 pts/9    00:00:00 <span class="token function">sudo</span> <span class="token function">vim</span> /etc/redis.conf
root     <span class="token number">26372</span> <span class="token number">26370</span>  <span class="token number">0</span> <span class="token number">11</span>:59 pts/9    00:00:00 <span class="token function">vim</span> /etc/redis.conf

关闭命令

先切换root
再执行 redis-cli
输入 <span class="token function">shutdown</span>
</code></pre> 
<h2><a id="0__22"></a>0 配置文件内容</h2> 
<p>定义在目录：/etc/redis.conf</p> 
<h3><a id="01%09Units_25"></a>0.1 ###Units单位###</h3> 
<p>配置大小单位,开头定义了一些基本的度量单位，只支持bytes，不支持bit，大小写不敏感</p> 
<pre><code class="prism language-vim"># Redis configuration file example.
#
# Note that in order to read the configuration file, Redis must be
# started with the file path as first argument:
#
# ./redis-server /path/to/redis.conf

# Note on units: when memory size is needed, it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth:
#
# 1k =&gt; 1000 bytes
# 1kb =&gt; 1024 bytes
# 1m =&gt; 1000000 bytes
# 1mb =&gt; 1024*1024 bytes
# 1g =&gt; 1000000000 bytes
# 1gb =&gt; 1024*1024*1024 bytes
#
# units are case insensitive so 1GB 1Gb 1gB are all the same.
</code></pre> 
<h3><a id="02%09INCLUDES_49"></a>0.2. ###INCLUDES包含###</h3> 
<p>类似jsp中的include，多实例的情况可以把公用的配置文件提取出来</p> 
<pre><code class="prism language-vim">################################## INCLUDES ###################################

# Include one or more other config files here.  This is useful if you
# have a standard template that goes to all Redis servers but also need
# to customize a few per-server settings.  Include files can include
# other files, so use this wisely.
#
# Note that option "include" won't be rewritten by command "CONFIG REWRITE"
# from admin or Redis Sentinel. Since Redis always uses the last processed
# line as value of a configuration directive, you'd better put includes
# at the beginning of this file to avoid overwriting config change at runtime.
#
# If instead you are interested in using includes to override configuration
# options, it is better to use include as the last line.
#
# include /path/to/local.conf
# include /path/to/other.conf
</code></pre> 
<h3><a id="03__NETWORK__72"></a>0.3 ######### NETWORK #####（网络配置*重点）</h3> 
<p>需要操作的点</p> 
<ul><li>默认情况bind=127.0.0.1只能接受本机的访问请求，所以需要将其注释掉，无限制接受其他ip访问</li><li>开启了protected-mode，那么在没有设定bind ip且没有设密码的情况下，Redis<strong>只允许接受本机的响应</strong></li><li>port 端口号，默认6379</li><li>tcp-backlog：tcp的backlog数，backlog是一个连接队列，队列总和=为完成三四握手队列+已完成三次握手队列 
  <ul><li>搞并发环境需要一个高backlog值来避免慢客户端连接问题。</li></ul> </li><li>timeout：一个空闲的客户端维持多少秒会关闭，0表示关闭该功能。即永不关闭</li><li>tcp-keepalive：对访问客户端的一种心跳检测，每个n秒检测一次。单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60</li></ul> 
<pre><code class="prism language-vim">################################## NETWORK #####################################

# By default, if no "bind" configuration directive is specified, Redis listens
# for connections from all available network interfaces on the host machine.
# It is possible to listen to just one or multiple selected interfaces using
# the "bind" configuration directive, followed by one or more IP addresses.
# Each address can be prefixed by "-", which means that redis will not fail to
# start if the address is not available. Being not available only refers to
# addresses that does not correspond to any network interfece. Addresses that
# are already in use will always fail, and unsupported protocols will always BE
# silently skipped.
#
# Examples:
#
# bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses
# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6
# bind * -::*                     # like the default, all available interfaces
#
# ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the
# internet, binding to all the interfaces is dangerous and will expose the
# instance to everybody on the internet. So by default we uncomment the
# following bind directive, that will force Redis to listen only on the
# IPv4 and IPv6 (if available) loopback interface addresses (this means Redis
# will only be able to accept client connections from the same host that it is
# running on).
#
# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES
# JUST COMMENT OUT THE FOLLOWING LINE.
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
bind 127.0.0.1 -::1

# Protected mode is a layer of security protection, in order to avoid that
# Redis instances left open on the internet are accessed and exploited.
#
# When protected mode is on and if:
#
# 1) The server is not binding explicitly to a set of addresses using the
#    "bind" directive.
# 2) No password is configured.
#
# The server only accepts connections from clients connecting from the
# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain
# sockets.
#
# By default protected mode is enabled. You should disable it only if
# you are sure you want clients from other hosts to connect to Redis
# even if no authentication is configured, nor a specific set of interfaces
# are explicitly listed using the "bind" directive.
protected-mode yes

# Accept connections on the specified port, default is 6379 (IANA #815344).
# If port 0 is specified Redis will not listen on a TCP socket.
port 6379

# TCP listen() backlog.
#
# In high requests-per-second environments you need a high backlog in order
# to avoid slow clients connection issues. Note that the Linux kernel
# will silently truncate it to the value of /proc/sys/net/core/somaxconn so
# make sure to raise both the value of somaxconn and tcp_max_syn_backlog
# in order to get the desired effect.
tcp-backlog 511

# Unix socket.
#
# Specify the path for the Unix socket that will be used to listen for
# incoming connections. There is no default, so Redis will not listen
# on a unix socket when not specified.
#
# unixsocket /run/redis.sock
# unixsocketperm 700

# Close the connection after a client is idle for N seconds (0 to disable)
timeout 0
# TCP keepalive.
#
# If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence
# of communication. This is useful for two reasons:
#
# 1) Detect dead peers.
# 2) Force network equipment in the middle to consider the connection to be
#    alive.
#
# On Linux, the specified value (in seconds) is the period used to send ACKs.
# Note that to close the connection the double of the time is needed.
# On other kernels the period depends on the kernel configuration.
#
# A reasonable value for this option is 300 seconds, which is the new
# Redis default starting with Redis 3.2.1.
tcp-keepalive 300
</code></pre> 
<h3><a id="04_%09GENERAL_176"></a>0.4 ###GENERAL通用###</h3> 
<ul><li>daemonize ：是否为后台进程，设置为yes</li><li>pidfile：存放pid的位置，每个实例会产生不同的pid文件</li><li>loglevel：指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为notice，生产环境选notice或warming</li><li>logfile：日志文件名称</li><li>databases：设定库的数量 默认16，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id</li></ul> 
<pre><code class="prism language-vim">################################# GENERAL #####################################

# By default Redis does not run as a daemon. Use 'yes' if you need it.
# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.
# When Redis is supervised by upstart or systemd, this parameter has no impact.
daemonize yes

# If you run Redis from upstart or systemd, Redis can interact with your
# supervision tree. Options:
#   supervised no      - no supervision interaction
#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode
#                        requires "expect stop" in your upstart job config
#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET
#                        on startup, and updating Redis status on a regular
#                        basis.
#   supervised auto    - detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# Note: these supervision methods only signal "process is ready."
#       They do not enable continuous pings back to your supervisor.
#
# The default is "no". To run under upstart/systemd, you can simply uncomment
# the line below:
#
# supervised auto

# If a pid file is specified, Redis writes it where specified at startup
# and removes it at exit.
#
# When the server runs non daemonized, no pid file is created if none is
# specified in the configuration. When the server is daemonized, the pid file
# is used even if not specified, defaulting to "/var/run/redis.pid".
#
# Creating a pid file is best effort: if Redis is not able to create it
# nothing bad happens, the server will start and run normally.
#
# Note that on modern Linux systems "/run/redis.pid" is more conforming
# and should be used instead.
pidfile /var/run/redis_6379.pid

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice

# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile ""
# To enable logging to the system logger, just set 'syslog-enabled' to yes,
# and optionally update the other syslog parameters to suit your needs.
# syslog-enabled no

# Specify the syslog identity.
# syslog-ident redis

# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.
# syslog-facility local0

# To disable the built in crash log, which will possibly produce cleaner core
# dumps when they are needed, uncomment the following:
#
# crash-log-enabled no

# To disable the fast memory check that's run as part of the crash log, which
# will possibly let redis terminate sooner, uncomment the following:
#
# crash-memcheck-enabled no
# a different one on a per-connection basis using SELECT &lt;dbid&gt; where
# dbid is a number between 0 and 'databases'-1
databases 16

# By default Redis shows an ASCII art logo only when started to log to the
# standard output and if the standard output is a TTY and syslog logging is
# disabled. Basically this means that normally a logo is displayed only in
# interactive sessions.
#
# However it is possible to force the pre-4.0 behavior and always show a
# ASCII art logo in startup logs by setting the following option to yes.
always-show-logo no

# By default, Redis modifies the process title (as seen in 'top' and 'ps') to
# provide some runtime information. It is possible to disable this and leave
# the process name as executed by setting the following to no.
set-proc-title yes

# When changing the process title, Redis uses the following template to construct
# the modified title.
#
# When changing the process title, Redis uses the following template to construct
# the modified title.
#
# Template variables are specified in curly brackets. The following variables are
# supported:
#
# {title}           Name of process as executed if parent, or type of child process.
# {listen-addr}     Bind address or '*' followed by TCP or TLS port listening on, or
#                   Unix socket if only that's available.
# {server-mode}     Special mode, i.e. "[sentinel]" or "[cluster]".
# {port}            TCP port listening on, or 0.
# {tls-port}        TLS port listening on, or 0.
# {unixsocket}      Unix domain socket listening on, or "".
# {config-file}     Name of configuration file used.
#
proc-title-template "{title} {listen-addr} {server-mode}"
                
</code></pre> 
<h3><a id="05_%09SECURITY_295"></a>0.5 ###SECURITY安全###</h3> 
<p>密码设置</p> 
<ul><li>临时密码设置：</li></ul> 
<pre><code class="prism language-shell">
<span class="token punctuation">[</span>root@xgms_VM-8-13-centos ~<span class="token punctuation">]</span><span class="token comment"># redis-cli</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> config get requirepass
<span class="token punctuation">(</span>error<span class="token punctuation">)</span> NOAUTH Authentication required.  <span class="token comment"># 这里需要密码是因为我之前在配置文件配置了</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> auth <span class="token number">123456</span>
OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> config get requirepass
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"requirepass"</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"123456"</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> config <span class="token builtin class-name">set</span> requirepass <span class="token string">"456789"</span>
OK

</code></pre> 
<ul><li>永久密码设置</li></ul> 
<pre><code class="prism language-vim"># IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility
# layer on top of the new ACL system. The option effect will be just setting
# the password for the default user. Clients will still authenticate using
# AUTH &lt;password&gt; as usually, or more explicitly with AUTH default &lt;password&gt;
# if they follow the new protocol: both will work.
#
# The requirepass is not compatable with aclfile option and the ACL LOAD
# command, these will cause requirepass to be ignored.
#
requirepass 123456
</code></pre> 
<h3><a id="06__CLIENTS_330"></a>0.6 ###### CLIENTS#########</h3> 
<ul><li>maxclients：设置redis同时可以与多少个客户端进行连接，默认10000。达到限制会拒绝新连接，并发送“max number of clients reached”</li><li>maxmermory：最高可用内存。达到上限，redis将会试图移除内部数据，移除规则可以通过maxmemory-policy来指定。</li></ul> 
<pre><code class="prism language-vim">################################### CLIENTS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error 'max number of clients reached'.
#
# IMPORTANT: When Redis Cluster is used, the max number of connections is also
# shared with the cluster bus: every node in the cluster will use two
# connections, one incoming and another outgoing. It is important to size the
# limit accordingly in case of very large clusters.
#
# maxclients 10000
</code></pre> 
<h2><a id="1__356"></a>1 数据类型</h2> 
<h3><a id="11_Key_358"></a>1.1 Key</h3> 
<p>keys *查看当前库所有key (匹配：keys *1)<br> exists key判断某个key是否存在<br> type key 查看你的key是什么类型<br> del key 删除指定的key数据<br> unlink key 根据value选择非阻塞删除<br> 仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。<br> expire key 10 10秒钟：为给定的key设置过期时间<br> ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期</p> 
<p>后续都是Value的可能数据类型</p> 
<h3><a id="12_String_373"></a>1.2 String（字符串）</h3> 
<p>特点：</p> 
<ol><li>二进制安全</li><li>最多512M</li></ol> 
<h4><a id="_379"></a>数据结构</h4> 
<ul><li>简单动态字符串</li><li>内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配</li><li>分配方式 
  <ul><li>长度&lt;1M:扩容加倍</li><li>长度&gt;1M:每次加1M</li></ul> </li></ul> 
<h4><a id="_388"></a>常用命令</h4> 
<ul><li> <p>set key value ：添加键值对</p> 
  <ul><li>NX：当数据库中key不存在时，可以将key-value添加数据库</li><li>XX：当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥</li><li>EX：key的超时秒数</li><li>PX：key的超时毫秒数，与EX互斥</li></ul> </li><li> <p>get key：查询对应键值</p> </li><li> <p>append key value将给定的 追加到原值的末尾</p> </li><li> <p>strlen key 获得值的长度</p> </li><li> <p>setnx key value 只有在 key 不存在时 设置 key 的值</p> </li><li> <p>只对字符串数字值操作</p> </li><li> <p>incr key ：将 key 中储存的数字值增1。如果为空，新增值为1</p> </li><li> <p>decr key ：将 key 中储存的数字值减1。为空则为-1</p> </li><li> <p>incrby / decrby key 步长 ：将 key 中储存的数字值增减。自定义步长。</p> </li><li> <p>以下操作遵循原子性，有一个失败则全失败</p> </li><li> <p>mset key1 value1 key2 value2 … 同时设置一个或多个 key-value对</p> </li><li> <p>mget key1 key2 key3 … 同时获取一个或多个 value</p> </li><li> <p>msetnx key1 value1 key2 value2 … 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。</p> </li><li> <p>setex key 过期时间 value：设置键值的同时，设置过期时间，单位秒。</p> </li><li> <p>getset key value：以新换旧，设置了新值同时获得旧值。</p> </li></ul> 
<h3><a id="13List_413"></a>1.3List（列表）</h3> 
<h4><a id="_417"></a>数据结构</h4> 
<ul><li>双向链表</li><li>数据较少会连续存储，类似ziplist</li><li>数据量多则类似quickList</li><li>Redis将链表与ziplist结合，底层是多个ziplist用头尾节点连接</li></ul> 
<h4><a id="_422"></a>常用命令</h4> 
<ul><li>lpush/rpush key value1 value2 value3 … ：从左边/右边插入一个或多个值。</li><li>lpop/rpop key：从左边/右边吐出一个值。值在键在，值光键亡。</li><li>rpoplpush key1 key2 ：从列表右边吐出一个值，插到列表左边。</li><li>lrange key start stop：按照索引下标获得元素(从左到右)</li><li>lrange mylist 0 -1 0左边第一个，-1右边第一个，（0-1表示获取所有）</li><li>lindex key index ：按照索引下标获得元素(从左到右)</li><li>llen key ：获得列表长度</li><li>linsert key before value newvalue ：在 value 的后面插入 newvalue 插入值</li><li>lrem key n value ：从左边删除n个value(从左到右)</li><li>lset key index value ：将列表key下标为index的值替换成value</li></ul> 
<h3><a id="14_Set_436"></a>1.4 Set（集合）</h3> 
<h4><a id="_440"></a>数据结构</h4> 
<ul><li>无序String list</li><li>自动去重</li><li>底层为idct字典，即vaule为null的hash，因此操作复杂度为O（1）</li></ul> 
<h4><a id="_445"></a>常用命令</h4> 
<ul><li>sadd key value1 value2 … 将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略</li><li>smembers key 取出该集合的所有值</li><li>sismember key value 判断集合 key 是否为含有该 value 值，有1，没有0</li><li>scard key 返回该集合的元素个数。</li><li>srem key value1 value2 … 删除集合中的某个元素。</li><li>spop key <code>随机从该集合中吐出一个值。</code></li><li>srandmember key n 随机从该集合中取出n个值。不会从集合中删除 。</li><li>smove source destination value把集合中一个值从一个集合移动到另一个集合</li><li>sinter key1 key2 返回两个集合的<code>交集</code>元素。</li><li>sunion key1 key2 返回两个集合的<code>并集</code>元素。</li><li>sdiff key1 key2 返回两个集合的<code>差集</code>元素(key1中的，不包含key2中的)</li></ul> 
<h3><a id="15_Zsetsorted_set__459"></a>1.5 Zset(sorted set) 有序集合</h3> 
<h4><a id="_460"></a>数据结构</h4> 
<ul><li>与set类似</li><li>成员关联评分，依据评分排序</li></ul> 
<h4><a id="_464"></a>常用命令</h4> 
<ul><li>zadd key score1 value1 score2 value2 …：将一个或多个 member 元素及其 score 值加入到有序集 key 当中。</li><li>zrange key start stop [WITHSCORES] ：返回有序集 key 中，下标在 start stop 之间的元素带WITHSCORES，可以让分数一起和值返回到结果集。</li><li>zrangebyscore key minmax [withscores] [limit offset count]：返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。</li><li>zrevrangebyscore key maxmin [withscores] [limit offset count] ： 同上，改为从大到小排列。</li><li>zincrby key increment value 为元素的score加上增量</li><li>zrem key value 删除该集合下，指定值的元素</li><li>zcount key min max 统计该集合，分数区间内的元素个数</li><li>zrank key value 返回该值在集合中的排名，从0开始。</li></ul> 
<h3><a id="16_Hash_474"></a>1.6 Hash（哈希）</h3> 
<h4><a id="_475"></a>数据结构</h4> 
<ul><li>类似Map&lt;String,Object&gt; 适合存储对象</li><li>通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题</li><li>Hash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。</li><li>当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。</li></ul> 
<h4><a id="_480"></a>常用命令</h4> 
<ul><li>hset key field value 给 key 集合中的 field 键赋值 value</li><li>hget key1 field 从 key1 集合 field 取出 value</li><li>hmset key1 field1 value1 field2 value2 … 批量设置hash的值</li><li>hexists key1 field 查看哈希表 key 中，给定域 field 是否存在。</li><li>hkeys key 列出该hash集合的所有field</li><li>hvals key 列出该hash集合的所有value</li><li>hincrby key field increment 为哈希表 key 中的域 field 的值加上增量 1 -1</li><li>hsetnx key field value 将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在 .</li></ul> 
<h3><a id="17_Bitmaps_490"></a>1.7 Bitmaps</h3> 
<h4><a id="_491"></a>数据结构</h4> 
<p>特别之处：value是一个二进制数组</p> 
<h4><a id="_494"></a>常用命令</h4> 
<ul><li>setbit key offset value 设置Bitmaps中某个偏移量的值（0或1） 
  <ul><li>offset的数字为具体序号，范围[0,2^32 -1]。第一次初始化不宜太大，执行会较慢</li><li>例子setbit unique:users:20201106 1 1代表2020-11-06这天的独立访问用户的Bitmaps，序号为1的用户访问一次</li></ul> </li><li>getbit key offset：获取Bitmaps中某个偏移量的值</li><li>bitcount: 统计字符串被设置为1的bit数 
  <ul><li>bitcount key start end:</li></ul> </li><li>bitop and(or/not/xor) destkey [key…] 做各类集合操作</li></ul> 
<h3><a id="18_HyperLogLog_507"></a>1.8 HyperLogLog</h3> 
<p>Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。</p> 
<p>在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p> 
<p>基数：就是去重之后的非重复元素</p> 
<h4><a id="_513"></a>常用命令</h4> 
<ul><li>pfadd key element [element …] 添加指定元素到 HyperLogLog 中</li><li>pfcount key [key …] 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可</li><li>pfmerge destkey sourcekey [sourcekey …] 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得</li></ul> 
<h3><a id="19_Geospatial_517"></a>1.9 Geospatial</h3> 
<h4><a id="_520"></a>作用</h4> 
<p>Redis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。</p> 
<h4><a id="_523"></a>常用命令</h4> 
<ul><li>geoadd key longitude latitude member [longitude latitude member…] 添加地理位置（经度，纬度，名称）</li><li>geopos key member [member…] 获得指定地区的坐标值</li><li>geodist key member1 member2 [m|km|ft|mi ] 获取两个位置之间的直线距离</li><li>georadius key longitude latituderadius m|km|ft|mi 以给定的经纬度为中心，找出某一半径内的元素</li></ul> 
<h2><a id="2_Redis_528"></a>2 Redis事务与锁机制</h2> 
<h3><a id="21_Redis_530"></a>2.1 Redis事务的三特性</h3> 
<ul><li>单独的隔离操作 
  <ul><li>事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li></ul> </li><li>没有隔离级别概念 
  <ul><li>队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行</li></ul> </li><li>不保证事务的原子性 
  <ul><li>事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚</li></ul> </li></ul> 
<h3><a id="21_Redis_541"></a>2.1 Redis事务的开启与执行</h3> 
<p>事务中包含多条语句，语句组成一队，组队完成后再决定是否一起执行</p> 
<p>事务主要分为</p> 
<ul><li>multi 组队阶段 过程中任何一条出现问题，整个队伍无法执行</li><li>exec 执行阶段 过程中某一条出现问题不影响其他命令执行</li><li>discard 放弃本次组队</li></ul> 
<pre><code class="prism language-shell">-------------这是正常执行的情况--------
<span class="token punctuation">[</span>root@xgms_VM-8-13-centos ~<span class="token punctuation">]</span><span class="token comment"># redis-cli</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> keys *
<span class="token punctuation">(</span>empty array<span class="token punctuation">)</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> multi
OK
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a1 b1
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a2 b2 
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a3 b3
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">exec</span>
<span class="token number">1</span><span class="token punctuation">)</span> OK
<span class="token number">2</span><span class="token punctuation">)</span> OK
<span class="token number">3</span><span class="token punctuation">)</span> OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> keys *
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"a3"</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"a1"</span>
<span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"a2"</span>


-------------------------执行阶段出错---------------------------
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> multi
OK
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a4 b4
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> incr a4
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a5 b5
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">exec</span>
<span class="token number">1</span><span class="token punctuation">)</span> OK
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>error<span class="token punctuation">)</span> ERR value is not an integer or out of range
<span class="token number">3</span><span class="token punctuation">)</span> OK

-----------------------组队阶段出错，全队无法执行----------------------------
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> multi
OK
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a6 b6
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a7
<span class="token punctuation">(</span>error<span class="token punctuation">)</span> ERR wrong number of arguments <span class="token keyword">for</span> <span class="token string">'set'</span> <span class="token builtin class-name">command</span>
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a8 b8
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">exec</span>
<span class="token punctuation">(</span>error<span class="token punctuation">)</span> EXECABORT Transaction discarded because of previous errors.

---------------------取消组队-------
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> multi
OK
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a9 b9 
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">set</span> a10 b10 
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> discard
OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> keys *
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"a1"</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"a2"</span>
<span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"a4"</span>
<span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">"a5"</span>
<span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">"a3"</span>


</code></pre> 
<h3><a id="22_Redis_621"></a>2.2 Redis的锁机制</h3> 
<p>常见锁种根据对执行前景的预测可分悲观锁与乐观锁。Redis比较注重并发性，用的主要是乐观锁</p> 
<p>悲观锁(Pessimistic Lock), 就是很悲观，<code>每次去拿数据的时候都认为别人会修改</code>，所以每次在<code>拿数据的时候都会上锁</code>，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。</p> 
<p>乐观锁(Optimistic Lock), 就是很乐观，<code>每次去拿数据的时候都认为别人不会修改</code>，所以<code>不会上锁</code>，但是在更新的时候<code>会判断一下在此期间别人有没有去更新</code>这个数据，可以使用<strong>版本号等机制</strong>。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。</p> 
<h4><a id="Redis_630"></a>Redis锁的开启与关闭</h4> 
<p>watch key[key…]<br> 一种乐观锁，可以监视一个或多个key，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断</p> 
<pre><code class="prism language-shell">

<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> <span class="token builtin class-name">set</span> a7 <span class="token number">345</span>
OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> <span class="token function">watch</span> a7
OK
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> multi
OK
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> incr a7
QUEUED
<span class="token number">127.0</span>.0.1:6379<span class="token punctuation">(</span>TX<span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token builtin class-name">exec</span>
<span class="token punctuation">(</span>nil<span class="token punctuation">)</span>


----------与此同时，在执行exec之前------------------
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> <span class="token builtin class-name">set</span> a7 <span class="token number">335</span>
OK

</code></pre> 
<p>unwatch</p> 
<ul><li>取消watch命令对所有key的监视</li><li>如果在执行 WATCH 命令之后，EXEC 命令或DISCARD 命令先被执行了的话，那么就不需要再执行UNWATCH 了。</li></ul> 
<h4><a id="_662"></a>解决乐观锁可能导致的库存遗留问题</h4> 
<p>面对秒杀这类高并发的需求，乐观锁可以解决超卖的问题(即库存已经没了，但是仍然卖出，导致库存为负)，但是因为每次卖出都会驱动乐观锁检查数据版本，可能导致大量的并发请求失败，最终虽然请求执行了多次，但有不少库存遗留。</p> 
<h2><a id="3_Redis_668"></a>3 Redis持久化</h2> 
<p>Redis提供了两种方法</p> 
<ul><li><code>RDB(物理持久化)</code> 指定时间间隔讲内存数据集快照写入磁盘，恢复时将快照读到内存</li><li><code>AOF(逻辑持久化)</code> 以日志形式记录每个写操作(增量保存)，只许追加文件但不可以改写文件</li></ul> 
<blockquote> 
 <p>注意：AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失）</p> 
</blockquote> 
<h3><a id="31_RDBRedis_Data_Base_676"></a>3.1 RDB（Redis Data Base）</h3> 
<p>具体执行过程</p> 
<p>Redis会单独创建（fork）一个子进程来进行持久化，会<code>先</code>将数据<code>写</code>入到 一个临时文件中，待持久化过程都结束了，再用这个<code>临时文件替换上次持久化好的文件</code>。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能</p> 
<p>如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。</p> 
<p>RDB的缺点：最后一次持久化后的数据可能丢失。</p> 
<p><img src="https://images2.imgbox.com/d2/2b/HIqJDuGI_o.png" alt="在这里插入图片描述"></p> 
<ul><li>fork</li></ul> 
<h4><a id="_690"></a>生成文件</h4> 
<p>在redis.conf中配置文件名称，默认为dump.rdb</p> 
<pre><code class="prism language-shell">配置文件中标识如下

dbfilename dump.rdb

</code></pre> 
<p>配置位置：默认为Redis启动时命令行所在的目录下<br> 配置保持策略:save 秒 写操作次数</p> 
<pre><code class="prism language-shell"><span class="token comment"># Enables or disables full sanitation checks for ziplist and listpack etc when</span>
<span class="token comment"># loading an RDB or RESTORE payload. This reduces the chances of a assertion or</span>
<span class="token comment"># crash later on while processing commands.</span>
<span class="token comment"># Options:</span>
<span class="token comment">#   no         - Never perform full sanitation</span>
<span class="token comment">#   yes        - Always perform full sanitation</span>
<span class="token comment">#   clients    - Perform full sanitation only for user connections.</span>
<span class="token comment">#                Excludes: RDB files, RESTORE commands received from the master</span>
<span class="token comment">#                connection, and client connections which have the</span>
<span class="token comment">#                skip-sanitize-payload ACL flag.</span>
<span class="token comment"># The default should be 'clients' but since it currently affects cluster</span>
<span class="token comment"># resharding via MIGRATE, it is temporarily set to 'no' by default.</span>
<span class="token comment">#</span>
<span class="token comment"># sanitize-dump-payload no</span>

<span class="token comment"># The filename where to dump the DB</span>
dbfilename dump.rdb
<span class="token builtin class-name">.</span>
<span class="token builtin class-name">.</span>
<span class="token builtin class-name">.</span>
<span class="token comment"># The working directory.</span>
<span class="token comment">#</span>
<span class="token comment"># The DB will be written inside this directory, with the filename specified</span>
<span class="token comment"># above using the 'dbfilename' configuration directive.</span>
<span class="token comment">#</span>
<span class="token comment"># The Append Only File will also be created inside this directory.</span>
<span class="token comment">#</span>
<span class="token comment"># Note that you must specify a directory here, not a file name.</span>
<span class="token function">dir</span> ./
<span class="token builtin class-name">.</span>
<span class="token builtin class-name">.</span>
<span class="token builtin class-name">.</span>
<span class="token builtin class-name">.</span>
<span class="token comment"># Unless specified otherwise, by default Redis will save the DB:</span>
<span class="token comment">#   * After 3600 seconds (an hour) if at least 1 key changed</span>
<span class="token comment">#   * After 300 seconds (5 minutes) if at least 100 keys changed</span>
<span class="token comment">#   * After 60 seconds if at least 10000 keys changed</span>
<span class="token comment">#</span>
<span class="token comment"># You can set these explicitly by uncommenting the three following lines.</span>
<span class="token comment">#</span>
save <span class="token number">3600</span> <span class="token number">1</span>
save <span class="token number">300</span> <span class="token number">100</span>
save <span class="token number">60</span> <span class="token number">10000</span>



</code></pre> 
<h3><a id="32_AOFAppend_Of_File_753"></a>3.2 AOF（Append Of File）</h3> 
<p>过程<br> <img src="https://images2.imgbox.com/79/6b/rTJ6qPSM_o.png" alt="在这里插入图片描述"><br> （1）客户端的请求写命令会被append追加到AOF缓冲区内；<br> （2）AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；<br> （3）AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；<br> （4）Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；</p> 
<h4><a id="_765"></a>生成文件</h4> 
<p>可以在redis.conf中自行定义文件名称，默认为appendonly.aof<br> AOF文件的保存路径，同RDB的路径一致。</p> 
<pre><code class="prism language-shell"><span class="token comment">############################## APPEND ONLY MODE ###############################</span>

<span class="token comment"># By default Redis asynchronously dumps the dataset on disk. This mode is</span>
<span class="token comment"># good enough in many applications, but an issue with the Redis process or</span>
<span class="token comment"># a power outage may result into a few minutes of writes lost (depending on</span>
<span class="token comment"># the configured save points).</span>
<span class="token comment">#</span>
<span class="token comment"># The Append Only File is an alternative persistence mode that provides</span>
<span class="token comment"># much better durability. For instance using the default data fsync policy</span>
<span class="token comment"># (see later in the config file) Redis can lose just one second of writes in a</span>
<span class="token comment"># dramatic event like a server power outage, or a single write if something</span>
<span class="token comment"># wrong with the Redis process itself happens, but the operating system is</span>
<span class="token comment"># still running correctly.</span>
<span class="token comment">#</span>
<span class="token comment"># AOF and RDB persistence can be enabled at the same time without problems.</span>
<span class="token comment"># If the AOF is enabled on startup Redis will load the AOF, that is the file</span>
<span class="token comment"># with the better durability guarantees.</span>
<span class="token comment">#</span>
<span class="token comment"># Please check http://redis.io/topics/persistence for more information.</span>

appendonly no

<span class="token comment"># The name of the append only file (default: "appendonly.aof")</span>

appendfilename <span class="token string">"appendonly.aof"</span>

<span class="token comment"># The fsync() call tells the Operating System to actually write data on disk</span>
<span class="token comment"># instead of waiting for more data in the output buffer. Some OS will really flush</span>
<span class="token comment"># data on disk, some other OS will just try to do it ASAP.</span>
<span class="token comment">#</span>
<span class="token comment"># Redis supports three different modes:</span>
<span class="token comment">#</span>
<span class="token comment"># no: don't fsync, just let the OS flush the data when it wants. Faster.</span>
<span class="token comment"># always: fsync after every write to the append only log. Slow, Safest.</span>
<span class="token comment"># everysec: fsync only one time every second. Compromise.</span>
<span class="token comment">#</span>
<span class="token comment"># The default is "everysec", as that's usually the right compromise between</span>
<span class="token comment"># speed and data safety. It's up to you to understand if you can relax this to</span>
<span class="token comment"># "no" that will let the operating system flush the output buffer when</span>
<span class="token comment"># it wants, for better performances (but if you can live with the idea of</span>
<span class="token comment"># some data loss consider the default persistence mode that's snapshotting),</span>
<span class="token comment"># or on the contrary, use "always" that's very slow but a bit safer than</span>
<span class="token comment"># everysec.</span>
<span class="token comment">#</span>
<span class="token comment"># More details please check the following article:</span>
<span class="token comment"># http://antirez.com/post/redis-persistence-demystified.html</span>
<span class="token comment">#</span>
<span class="token comment"># If unsure, use "everysec".</span>

<span class="token comment"># appendfsync always</span>
appendfsync everysec
<span class="token comment"># appendfsync no</span>
</code></pre> 
<h4><a id="AOF_826"></a>AOF启动/修复/恢复</h4> 
<ul><li>正常恢复 
  <ul><li>修改默认的appendonly no，改为yes</li><li>将有数据的aof文件复制一份保存到对应目录(查看目录：config get dir)</li><li>恢复：重启redis然后重新加载</li></ul> </li><li>异常恢复 
  <ul><li>修改默认的appendonly no，改为yes</li><li>如遇到AOF文件损坏，通过/usr/local/bin/redis-check-aof–fix appendonly.aof进行恢复</li><li>备份被写坏的AOF文件</li><li>恢复：重启redis，然后重新加载</li></ul> </li></ul> 
<h4><a id="_837"></a>同步频率设置</h4> 
<ul><li>appendfsync always：始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好</li><li>appendfsync everysec：每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。</li><li>appendfsync no：redis不主动进行同步，把同步时机交给操作系统</li></ul> 
<h3><a id="33__843"></a>3.3 两种方法优劣对比</h3> 
<table><thead><tr><th>方式</th><th>优势</th><th>劣势</th><th>文件名</th></tr></thead><tbody><tr><td>RDB</td><td>1.<code>节省磁盘空间</code><br>2.<code>恢复速度快</code><br>3.适合大规模的数据恢复<br>4.对数据完整性和一致性要求不高更适合使用</td><td>1.Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑<br>2.虽然Redis在fork时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能。<br>3. 在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</td><td>dump.rdb</td></tr><tr><td>AOF</td><td>1.备份机制更稳健，丢失数据概率更低<br>2.可读的日志文本，通过操作AOF稳健，可以处理误操作</td><td>1.比起RDB占用更多的磁盘空间<br>2.恢复备份速度要慢<br>3.每次读写都同步的话，有一定的性能压力<br>存在个别Bug，造成恢复不能</td><td>appendonly.aof</td></tr></tbody></table> 
<h2><a id="4__852"></a>4 主从复制</h2> 
<p>主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主</p> 
<p>作用：</p> 
<ol><li>读写分离，性能扩展</li><li>容灾快速恢复</li></ol> 
<h3><a id="41__858"></a>4.1 如何开启主从复制</h3> 
<ol><li>创建/myredis文件夹：mkdir /myredis</li><li>复制redis.conf到文件夹<br> 需要在公共配置里修改如下内容</li></ol> 
<pre><code class="prism language-shell">开启daemonize <span class="token function">yes</span>

<span class="token comment"># 如下需要在各自配置文件里修改</span>
Pid文件名字pidfile
指定端口port
Log文件名字
dump.rdb名字dbfilename
Appendonly 关掉或者换名字

</code></pre> 
<ol start="3"><li>配置一主两从，创建三个配置文件 
  <ul><li>redis6379.conf</li><li>redis6380.conf</li><li>redis6381.conf</li></ul> </li><li>在三个配置文件中写入内容</li></ol> 
<pre><code class="prism language-shell"><span class="token comment"># 三个都要创建，端口号替换成自己的</span>
include /myredis/redis.conf  <span class="token comment"># 这里的include会引入redis.conf的公共部分到这三个配置文件中</span>
pidfile /var/run/redis_6379.pid
port <span class="token number">6379</span>
dbfilename dump6379.rdb

<span class="token comment"># slave-priority 10</span>
<span class="token comment"># 设置从机的优先级，值越小，优先级越高，用于选举主机时使用。默认100</span>
<span class="token comment"># 根据需求看是否配置</span>
</code></pre> 
<ol start="5"><li>启动三个redis服务：redis-sever redis6379.conf（三个各自执行一次） 
  <ul><li>redis-cli -p 6379 进入相应服务器</li><li>info replication 查看相关运行情况与主从信息</li></ul> </li></ol> 
<p>主从复制特点：</p> 
<ol><li>配主不配从：开启服务后，进入从服务器执行slaveof 127.0.0.1 6379配主服务器</li><li>重启后自动变为主服务器，需要重新配置才会作为从服务器运行</li><li>挂掉后重新配置后会从头复制数据</li><li>主服务器挂掉后，从服务器不会主动成为主服务器</li></ol> 
<h3><a id="42__903"></a>4.2 常用主从复制策略</h3> 
<h4><a id="_905"></a>一主二仆</h4> 
<ul><li>主服务器挂掉，从服务器不会主动上位</li><li>从服务器只能读不能写</li></ul> 
<h4><a id="_908"></a>薪火相传</h4> 
<p>上一个Slave可以是下一个slave的Master<br> Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。</p> 
<ul><li>中途变更转向：会清除之前数据，拷贝最新</li><li>某个从机宕机，后续从机无法备份</li></ul> 
<h4><a id="_915"></a>反客为主</h4> 
<ul><li>slaveof no one 命令可以将从机变为主机</li><li>slave-priority 10 可以决定哪个从机优先选为主机</li></ul> 
<h4><a id="sentinel_920"></a>哨兵模式(sentinel)-反客为主自动版本</h4> 
<ul><li>主机故障，从机投票将从机变为主机</li></ul> 
<p>配置方式</p> 
<ol><li>依据一主二仆模式先配置好</li><li>在自定义的/myredis目录下新建sentinel.conf文件：vi sentinel.conf</li><li>配置哨兵，填写内容</li></ol> 
<pre><code class="prism language-python">sentinel monitor mymaster <span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span> <span class="token number">6379</span> <span class="token number">1</span>
<span class="token comment"># 其中mymaster为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量。</span>
</code></pre> 
<ol start="4"><li>启动哨兵：执行redis-sentinel /myredis/sentinel.conf</li><li>主机宕机，从机选举中产生新的主机： 
  <ul><li>选择新主机的主要条件 
    <ol><li>slave-priority (值越小优先级越高)</li><li>偏移量最大（指对原主机数据最全）</li><li>选择runid最小的（每个redis实例启动后生成40位的唯一runid）</li></ol> </li><li>哨兵会向原主机发送slaveof 命令，复制新主机</li><li>原主机重新上线会变为从机</li></ul> </li></ol> 
<h3><a id="43__940"></a>4.3 复制原理</h3> 
<ul><li>Slave启动成功连接到master后会发送一个sync命令</li><li>Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步</li><li>全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。</li><li>增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步</li><li>但是只要是重新连接master,一次完全同步（全量复制)将被自动执行</li></ul> 
<h2><a id="5__949"></a>5 集群</h2> 
<p>作用：扩容、提升并发、减去配置ip与端口的操作</p> 
<p>从redis3.0开始进行无中心化集群配置</p> 
<p>集群实现对Redis水平扩容，数据库分布存储在各节点，从集群的任意一个端口和ip都可以进入集群<br> 集群中也有主从概念，每个集群<code>至少三个主机</code></p> 
<h3><a id="51__958"></a>5.1 集群启动方式</h3> 
<p><code>先将rdb,aof文件都删除掉</code></p> 
<p>步骤：</p> 
<ol><li>配置基本信息：在需要include的redis文件里修改</li></ol> 
<pre><code class="prism language-python">开启daemonize yes
Pid文件名字
指定端口
Log文件名字
Dump<span class="token punctuation">.</span>rdb名字
Appendonly 关掉或者换名字

</code></pre> 
<ol start="2"><li>集群配置修改 redis6369.conf</li></ol> 
<pre><code class="prism language-python">include <span class="token operator">/</span>home<span class="token operator">/</span>bigdata<span class="token operator">/</span>redis<span class="token punctuation">.</span>conf
port <span class="token number">6379</span>
pidfile <span class="token string">"/var/run/redis_6379.pid"</span>
dbfilename <span class="token string">"dump6379.rdb"</span>
<span class="token builtin">dir</span> <span class="token string">"/home/bigdata/redis_cluster"</span>
logfile <span class="token string">"/home/bigdata/redis_cluster/redis_err_6379.log"</span>
cluster<span class="token operator">-</span>enabled yes
<span class="token comment"># 设置节点配置文件名</span>
cluster<span class="token operator">-</span>config<span class="token operator">-</span><span class="token builtin">file</span> nodes<span class="token operator">-</span><span class="token number">6379</span><span class="token punctuation">.</span>conf
<span class="token comment"># 设定节点失联时间，超过该时间（毫秒），集群自动进行主从切换。</span>
cluster<span class="token operator">-</span>node<span class="token operator">-</span>timeout <span class="token number">15000</span>

</code></pre> 
<ol start="3"><li>修改好conf文件并复制，拷贝并依据对应端口修改文件名</li><li>查找替换另外5个文件： 
  <ul><li>vim redis6380.conf 再用:%s/6379/6380 替换端口内容</li></ul> </li><li>启动6个服务： 
  <ul><li>redis-sever redis6379.conf 修改对应端口启动6次</li><li>使用ll查看相应文件下的nodes-6379.conf等系列文件是否生成成功</li></ul> </li><li>将6个节点合成一个集群 
  <ul><li>cd /opt/redis-6.2.1/src</li><li>执行如下命令</li></ul> </li></ol> 
<pre><code class="prism language-shell">redis-cli --cluster create --cluster-replicas <span class="token number">1</span> <span class="token number">192.168</span>.11.101:6379 <span class="token number">192.168</span>.11.101:6380 <span class="token number">192.168</span>.11.101:6381 <span class="token number">192.168</span>.11.101:6389 <span class="token number">192.168</span>.11.101:6390 <span class="token number">192.168</span>.11.101:6391

<span class="token comment"># 此处不要用127.0.0.1， 请用真实IP地址</span>
<span class="token comment"># --replicas 1 采用最简单的方式配置集群，一台主机，一台从机，正好三组。</span>

执行后会返回最后一行
<span class="token punctuation">[</span>OK<span class="token punctuation">]</span> ALL <span class="token number">16384</span> slots covered
这里的slots是用于分布式存储的一个重要依据
</code></pre> 
<ol start="7"><li>-c 采用集群策略连接，设置数据会自动切换到相应的写主机 
  <ul><li>执行如上方式后，如果用redis-cli -p 6379 连接，可能会直接进入读主机，存储数据会出现MOVED重定向操作</li><li>所以需要用集群方式登录：redis-cli -c -p 6379</li></ul> </li><li>连接后可以通过 cluster nodes 命令查看集群信息</li></ol> 
<blockquote> 
 <p>一个集群至少要有三个主节点。<br> 选项 --cluster-replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。<br> 分配原则尽量保证每个主数据库运行在不同的IP地址，每个从库和主库不在一个IP地址上。</p> 
</blockquote> 
<h3><a id="52__1021"></a>5.2 集群数据分配与查询逻辑</h3> 
<p>刚刚启动命令中提到，会返回一行</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>OK<span class="token punctuation">]</span> All nodes agree about slots configuration.
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> Check <span class="token keyword">for</span> <span class="token function">open</span> slots<span class="token punctuation">..</span>.
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> Check slots coverage<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>OK<span class="token punctuation">]</span> All <span class="token number">16384</span> slots covered.

</code></pre> 
<p>一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库会根据<code>键</code>计算<code>插槽值</code>(CRC16(key) % 16384)，值会在[0,16383]内</p> 
<p>然后集群会将插槽（slot）均分给主节点，实现分布式存储</p> 
<ul><li>比如：</li><li>节点 A 负责处理 0 号至 5460 号插槽。</li><li>节点 B 负责处理 5461 号至 10922 号插槽。</li><li>节点 C 负责处理 10923 号至 16383 号插槽。</li></ul> 
<p>总结来说，一个键会对应一个固定的插槽值，然后会根据具体值决定该键值对分配到哪个主节点，<code>键值与插槽值相互对应且唯一</code></p> 
<h4><a id="_1043"></a>常用命令</h4> 
<ul><li>插入命令</li></ul> 
<pre><code class="prism language-shell">常用
<span class="token builtin class-name">set</span> key1 value1

插入后会自动计算插值，然后转到对应主节点进行后续操作

注意：不能使用mget、mset等多键插入操作，因为插入需要单独计算插值
如mset k1 v1 k2 v2  这种操作无法执行

但是mset可以将多个值组合为组，此时就可以存入多个值到一个slot
比如：
mset k1<span class="token punctuation">{<!-- --></span>user<span class="token punctuation">}</span> v1 k2<span class="token punctuation">{<!-- --></span>user<span class="token punctuation">}</span> v2 

此时k1和k2 就都被存储到user组对应的插值下，该插值也可以一次性读出这两个

</code></pre> 
<ul><li>查询命令</li></ul> 
<pre><code class="prism language-python">cluster keyslot key1
cluster countkeysinslot <span class="token number">12345</span>
<span class="token comment"># 只能查询自己slot范围内的值</span>
cluster getkeysinslot <span class="token number">12345</span> <span class="token number">3</span>
<span class="token comment"># 查询具体插槽中的内容，即返回插值为12345的三个键(组存储情况)</span>

</code></pre> 
<h4><a id="_1075"></a>故障恢复</h4> 
<ul><li>主节点下线，从节点在其超时15秒后升为主节点</li><li>主节点重新上线变为从节点</li><li>某个插槽段的主从全部下线，集群运行情况需要看 cluster-require-full-coverage这一参数的配置情况 
  <ul><li>为yes，则整个集群一起下线</li><li>为no，则该插槽段的数据全部无法使用，也无法存储</li></ul> </li></ul> 
<h3><a id="53__1083"></a>5.3 集群的不足</h3> 
<ul><li>多键操作是不被支持的</li><li><code>多键的Redis事务是不被支持的。lua脚本不被支持</code></li><li>由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。</li></ul> 
<h2><a id="6_Redis_1090"></a>6 Redis常见应用问题</h2> 
<h3><a id="61__1092"></a>6.1 缓存穿透</h3> 
<p>情况概述：key对应的数据不存在，但是仍然一直请求该key</p> 
<p>出现情况：</p> 
<ol><li>应用服务器压力变大</li><li>redis命中率很低</li><li>一直查询数据库</li></ol> 
<p>可能原因：</p> 
<ol><li>redis查询不到数据库</li><li>出现很多非正常url访问（可能是黑客攻击）</li></ol> 
<p>解决方案：</p> 
<ol><li><strong>对空值缓存</strong>：查询返回的数据为空也进行缓存，杜绝因为缓存不存在而多次请求数据源的情况</li><li><strong>设置可访问的名单（白名单）</strong>：使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较</li><li><strong>采用布隆过滤器</strong>：布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被 这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。</li><li><strong>进行实时监控</strong>：当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务</li></ol> 
<h3><a id="62__1111"></a>6.2 缓存击穿</h3> 
<p>情况概述：在一个存在的key缓存过期期间，大量并发请求同时向数据库请求</p> 
<p>出现情况：</p> 
<ol><li>数据库访问压力瞬时增加</li><li>redis里面没有出现大量key过期</li><li>redis正常运行</li></ol> 
<p>可能原因：Redis某个key过期了，但是又需要大量访问这个key</p> 
<p>解决方案：</p> 
<ol><li><strong>预先设置热门数据</strong>：在redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长</li><li><strong>实时调整</strong>：现场监控哪些数据热门，实时调整key的过期时长</li><li><strong>使用锁</strong>：<br> <img src="https://images2.imgbox.com/65/d0/ECb3QKln_o.png" alt="在这里插入图片描述"></li></ol> 
<h3><a id="63__1127"></a>6.3 缓存雪崩</h3> 
<p>情况描述：请求多个过期key导致的数据库访问超载。缓存雪崩与缓存击穿的区别在于这里针对很多key缓存，前者则是某一个key</p> 
<p>出现情况：数据库压力变大</p> 
<p>可能原因：极少时间内出现大量key集中过期</p> 
<p>解决方案</p> 
<ol><li><strong>构建多级缓存架构</strong>：nginx缓存 + redis缓存 +其他缓存（ehcache等）</li><li><strong>使用锁或队列</strong>：用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况</li><li><strong>设置过期标志更新缓存</strong>：记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。</li><li><strong>将缓存失效时间分散开</strong>：比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7e045bf26389770c307cea086eac7291/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">VueUse文档个人翻译——核心方法一览</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a21aac46c9e5a6eaf0e6a0bfc0d6fd54/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;多态之四种实现形式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>