<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>模型预测结果校准——Isotonic regression - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="模型预测结果校准——Isotonic regression" />
<meta property="og:description" content="模型预测结果校准——Isotonic regression 方法简介： Isotonic Regression: the method used by Zadrozny and Elkan (2002; 2001) to calibrate predictions from boosted naive bayes, SVM, and decision tree models.[1]
Zadrozny and Elkan (2002; 2001) successfully used a more general
method based on Isotonic Regression (Robertson et al.,1988) to calibrate predictions from SVMs, Naive Bayes, boosted Naive Bayes, and decision trees. This method is more general in that the only restriction is that the mapping function be isotonic (monotonically increasing)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/013013b72ca2cb1d3abffa822a64fab1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-16T18:48:13+08:00" />
<meta property="article:modified_time" content="2018-07-16T18:48:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">模型预测结果校准——Isotonic regression</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 style="margin-left:0cm;">模型预测结果校准——Isotonic regression  </h3> 
<h4 style="margin-left:0cm;">方法简介：</h4> 
<p style="margin-left:0cm;">Isotonic Regression: the method used by Zadrozny and Elkan (2002; 2001) to calibrate predictions from boosted naive bayes, SVM, and decision tree models.[1]</p> 
<p style="margin-left:0cm;">Zadrozny and Elkan (2002; 2001) successfully used a more general</p> 
<p style="margin-left:0cm;">method based on Isotonic Regression (Robertson et al.,1988) to calibrate predictions from SVMs, Naive Bayes, boosted Naive Bayes, and decision trees. This method is more general in that the only restriction is that the mapping function be isotonic (monotonically increasing).[1]</p> 
<p style="margin-left:0cm;">Isotonic regression(保序回归) 是一种非参数化方法（The non-parametric approach）；</p> 
<p style="margin-left:0cm;">假设模型的预测结果记为fi，真实目标记为yi,那么Isotonic Regression的基本假设为：</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="47" src="https://images2.imgbox.com/3f/54/CSK2fPQz_o.png" width="460"></p> 
<p style="margin-left:0cm;">其中m是isotonic(单调递增)的函数。</p> 
<p style="margin-left:0cm;">给定数据集<img alt="" class="has" height="24" src="https://images2.imgbox.com/8f/f7/yZ08KPV5_o.png" width="87">，可以通过下式求解m:</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="40" src="https://images2.imgbox.com/a2/42/Ool6VGEF_o.png" width="448"></p> 
<p style="margin-left:0cm;">Isotonic Regression的一种求解算法是pair-adjacent violators  algorithm（简称PAV算法），时间复杂度是O(N)，主要思想是通过不断合并、调整违反单调性的局部区间，使得最终得到的区间满足单调性。PAV算法也是scikit-learn中isotonic regression库的求解算法。该算法的动态效果图可参阅文献[2]。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="450" src="https://images2.imgbox.com/39/25/1sS3MfoQ_o.png" width="600"></p> 
<p style="margin-left:0cm;">One algorithm that finds a stepwise constant solution for the Isotonic Regression problem is pair-adjacent violators (PAV) algorithm (Ayer et al., 1955) presented in Table 1.</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="273" src="https://images2.imgbox.com/24/f1/w0aIgUFb_o.png" width="467"></p> 
<p style="margin-left:0cm;">Isotonic regression 的通俗化解释：</p> 
<pre class="has"><code>问题描述：给定一个无序数字序列，要求不改变每个元素的位置，但可以修改每个元素的值，修改后得到一个非递减序列，问如何使误差（该处取平方差）最小？ 
保序回归法：从该序列的首元素往后观察，一旦出现乱序现象停止该轮观察，从该乱序元素开始逐个吸收元素组成一个序列，直到该序列所有元素的平均值小于或等于下一个待吸收的元素。 
举例： 
原始序列：&lt;9, 10, 14&gt; 
结果序列：&lt;9, 10, 14&gt; 
分析：从9往后观察，到最后的元素14都未发现乱序情况，不用处理。 
原始序列：&lt;9, 14, 10&gt; 
结果序列：&lt;9, 12, 12&gt;</code></pre> 
<h4>应用流程：</h4> 
<p>对于CTR,特征选择的时候，可能会选择很多细粒度的特征，那么直接通过clicks/impressions计算出的点击率会非常不准确。</p> 
<p style="margin-left:0cm;">文献[4]中提出基于下式，提出求解t()的一种近似方法。</p> 
<p style="margin-left:0cm;">The methods by Wang et al. [5] and Meyer [6] find a non-decreasing</p> 
<p style="margin-left:0cm;">mapping function t() that minimizes:</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="60" src="https://images2.imgbox.com/75/75/3WQW31ym_o.png" width="380"></p> 
<p style="margin-left:0cm;">其中，ci表示真实label, pi表示模型输出的预测概率。M是一个表示平滑程度的参数，a和b分别表示输入的预测值的范围，<img alt="" class="has" height="24" src="https://images2.imgbox.com/fd/5c/OJU0G3Z5_o.png" width="28">用于平衡拟合程度（goodness-of-fit,第一项）和转换函数t()的平滑度（smoothness，第二项）。</p> 
<p style="margin-left:0cm;">另外，为了维持该模型的识别能力，必须保证该模型是单调递增的。</p> 
<p style="margin-left:0cm;">算法实现流程如下：Algorithm 1: Smooth Isotonic Regression</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="84" src="https://images2.imgbox.com/4f/d7/lZdj4RIw_o.png" width="451"></p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="58" src="https://images2.imgbox.com/1f/f1/2r9MFz6o_o.png" width="429"></p> 
<p style="margin-left:0cm;">通过Isotonic regression 得到单调且非参数化的函数f(),同时这个函数要使<img alt="" class="has" height="31" src="https://images2.imgbox.com/e9/43/ciSi3mrE_o.png" width="139">有最小值。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="80" src="https://images2.imgbox.com/c2/61/8XE1nWlJ_o.png" width="436"></p> 
<p style="margin-left:0cm;">在经过Isotonic Regression函数映射后的数据中，选择s个典型的点，其预测值和对应的label分别记作集合<img alt="" class="has" height="30" src="https://images2.imgbox.com/2b/3a/NLcVggmE_o.png" width="28">和<img alt="" class="has" height="27" src="https://images2.imgbox.com/5b/c5/X96vRrmg_o.png" width="24">。</p> 
<p style="margin-left:0cm;"><img alt="" class="has" height="114" src="https://images2.imgbox.com/e3/d3/dC6e0BVB_o.png" width="432"></p> 
<p style="margin-left:0cm;">对步骤2中采样的点采用Piecewise Cubic Hermite Interpolating Polynomial (PCHIP)方法进行插值，得到平滑后的单调曲线，并将该曲线作为最终进行校准的映射函数。</p> 
<p style="margin-left:0cm;">理论上讲，该方法比Isotonic regression 更加平滑，比sigmoid regression 更加灵活。</p> 
<h4 style="margin-left:0cm;">适用情况：</h4> 
<p style="margin-left:0cm;">Isotonic Regression is a more powerful calibration method that can correct any monotonic distortion. Unfortunately, this extra power comes at a price. A learning curve analysis shows that Isotonic Regression is more prone to overfitting, and thus performs worse than Platt Scaling, when data is scarce.[1]</p> 
<p style="margin-left:0cm;">Isotonic regression 对模型的输出特征没有要求；</p> 
<p style="margin-left:0cm;">适用于样本量多的情形，样本量少时，使用isotonic regression容易过拟合；</p> 
<p style="margin-left:0cm;">Isotonic Regression通常作为辅助其他方法修复因为数据稀疏性导致的矫正结果不平滑问题；[7]</p> 
<p style="margin-left:0cm;">Microsoft在文献[3]中的CTR预估模型的校准上用到Isotonic Regression。</p> 
<p style="margin-left:0cm;"> </p> 
<p style="margin-left:0cm;">参考文献：</p> 
<p style="margin-left:0cm;">[1] Alexandru Niculescu-Mizil, et al. Predicting Good Probabilities With Supervised Learning. ICML2005.</p> 
<p style="margin-left:0cm;">[2] https://en.wikipedia.org/wiki/Isotonic_regression</p> 
<p style="margin-left:0cm;">[3] Thore graepel, et al. Web-Scale Bayesian Click-Through Rate Prediction for Sponsored Search Advertising in Microsoft’s Bing Search Engine. ICML2010.</p> 
<p style="margin-left:0cm;">[4] Jiang X, Osl M, Kim J, Ohno-Machado L. Smooth Isotonic Regression: A New Method to Calibrate Predictive Models. AMIA Summits on Translational Science Proceedings. 2011;2011:16-20.</p> 
<p style="margin-left:0cm;">[5] X. Wang and F. Li. Isotonic smoothing spline regression. J Comput Graph Stat, 17(1):21–37, 2008.</p> 
<p style="margin-left:0cm;">[6] M. C. Meyer. Inference using shape-restricted regression splines. Annals of Applied Statistics, 2(3):1013–1033, 2008.</p> 
<p style="margin-left:0cm;">[7] &lt;预测模型结果校准&gt;https://sensirly.github.io/prediction-model-calibration/</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b6a6de59aaef4b86d6aadd931d0c57e0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">再看volatile关键字</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ce13fa83529a591c488141fac20a8ab6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue &#43; vuex &#43; element-ui 购物车</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>