<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>个人使用ChatGLM-6B遇到的部分问题汇总 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="个人使用ChatGLM-6B遇到的部分问题汇总" />
<meta property="og:description" content="本文目录 写在最前个人windows电脑部署时遇到KeyError: &#39;chatglm&#39;问题原因：transformers版本有问题解决方法 OSError/AssertionError/Failed to load cpm_kernels问题原因：配置内容没有修改、依赖包不完整解决方法 想要运行web_demo2.py时遇到No matching distribution found for streamlit-chat问题原因：组件必须要在python&gt;3.8的环境才能运行！！！！ 写在最前 项目的github网址（https://github.com/THUDM/ChatGLM-6B）中有解决问题专用的Issues模块
建议遇到问题先将部分报错写在这里进行查询，大概率能找到问题的解决方法
本文章只用于记录个人在使用过程中遇到的问题，供以后回忆之用。
个人windows电脑部署时遇到 以下都是在运行cli_demo.py遇到
KeyError: ‘chatglm’ # 出现异常描述 (ai) Q:\Python\project\ChatGLM\ChatGLM-6B-main&gt;python cli_demo.py Traceback (most recent call last): File &#34;cli_demo.py&#34;, line 7, in &lt;module&gt; tokenizer = AutoTokenizer.from_pretrained(&#34;THUDM/ChatGLM-6B&#34;, trust_remote_code=True) File &#34;Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\tokenization_auto.py&#34;, line 362, in from_pretrained config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs) File &#34;Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\configuration_auto.py&#34;, line 371, in from_pretrained config_class = CONFIG_MAPPING[config_dict[&#34;model_type&#34;]] KeyError: &#39;chatglm&#39; 问题原因：transformers版本有问题 推荐版本是4.27.1 ，但是好像不太行
解决方法 在出现这个问题之前，我先遇到了一个问题提示找不到模型，然后我查了以后有人说是因为transformer版本太低，然后我就把版本提升到4.3以上的一个版本，然后就出现了上所示问题重新去github上找人答疑时，有人说需要版本得是transformers 4.28.1，我就死马当活马医重新pip install，发现解决了，进入下一个问题 OSError/AssertionError/Failed to load cpm_kernels (ai) Q:\Python\project\ChatGLM\ChatGLM-6B-main&gt;python cli_demo." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bb68e9652d0de4e6ffa899b41abc4366/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-19T17:00:05+08:00" />
<meta property="article:modified_time" content="2023-06-19T17:00:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">个人使用ChatGLM-6B遇到的部分问题汇总</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>本文目录</h4> 
 <ul><li><a href="#_2" rel="nofollow">写在最前</a></li><li><a href="#windows_10" rel="nofollow">个人windows电脑部署时遇到</a></li><li><ul><li><a href="#KeyError_chatglm_13" rel="nofollow">KeyError: 'chatglm'</a></li><li><ul><li><a href="#transformers_28" rel="nofollow">问题原因：transformers版本有问题</a></li><li><a href="#_30" rel="nofollow">解决方法</a></li></ul> 
   </li><li><a href="#OSErrorAssertionErrorFailed_to_load_cpm_kernels_36" rel="nofollow">OSError/AssertionError/Failed to load cpm_kernels</a></li><li><ul><li><a href="#_118" rel="nofollow">问题原因：配置内容没有修改、依赖包不完整</a></li><li><a href="#_120" rel="nofollow">解决方法</a></li></ul> 
  </li></ul> 
  </li><li><a href="#web_demo2py_143" rel="nofollow">想要运行web_demo2.py时遇到</a></li><li><ul><li><a href="#No_matching_distribution_found_for_streamlitchat_145" rel="nofollow">No matching distribution found for streamlit-chat</a></li><li><a href="#python38_155" rel="nofollow">问题原因：组件必须要在python&gt;3.8的环境才能运行！！！！</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>写在最前</h2> 
<p>项目的github网址（https://github.com/THUDM/ChatGLM-6B）中有解决问题专用的Issues模块<br> <img src="https://images2.imgbox.com/7b/bc/Ejzz15w9_o.png" alt="在这里插入图片描述"><br> 建议遇到问题先将部分报错写在这里进行查询，大概率能找到问题的解决方法</p> 
<p>本文章只用于记录个人在使用过程中遇到的问题，供以后回忆之用。</p> 
<h2><a id="windows_10"></a>个人windows电脑部署时遇到</h2> 
<p>以下都是在运行cli_demo.py遇到</p> 
<h3><a id="KeyError_chatglm_13"></a>KeyError: ‘chatglm’</h3> 
<pre><code class="prism language-python"><span class="token comment"># 出现异常描述</span>
<span class="token punctuation">(</span>ai<span class="token punctuation">)</span> Q<span class="token punctuation">:</span>\Python\project\ChatGLM\ChatGLM<span class="token operator">-</span>6B<span class="token operator">-</span>main<span class="token operator">&gt;</span>python cli_demo<span class="token punctuation">.</span>py
Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"cli_demo.py"</span><span class="token punctuation">,</span> line <span class="token number">7</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"THUDM/ChatGLM-6B"</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\tokenization_auto.py"</span><span class="token punctuation">,</span> line <span class="token number">362</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    config <span class="token operator">=</span> AutoConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>pretrained_model_name_or_path<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\configuration_auto.py"</span><span class="token punctuation">,</span> line <span class="token number">371</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    config_class <span class="token operator">=</span> CONFIG_MAPPING<span class="token punctuation">[</span>config_dict<span class="token punctuation">[</span><span class="token string">"model_type"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
KeyError<span class="token punctuation">:</span> <span class="token string">'chatglm'</span>

</code></pre> 
<h4><a id="transformers_28"></a>问题原因：transformers版本有问题</h4> 
<p>推荐版本是4.27.1 ，但是好像不太行</p> 
<h4><a id="_30"></a>解决方法</h4> 
<ul><li>在出现这个问题之前，我先遇到了一个问题提示找不到模型，然后我查了以后有人说是因为transformer版本太低，然后我就把版本提升到4.3以上的一个版本，然后就出现了上所示问题</li><li>重新去github上找人答疑时，有人说需要版本得是transformers 4.28.1，我就死马当活马医重新pip install，发现解决了，进入下一个问题</li></ul> 
<h3><a id="OSErrorAssertionErrorFailed_to_load_cpm_kernels_36"></a>OSError/AssertionError/Failed to load cpm_kernels</h3> 
<pre><code class="prism language-python"><span class="token punctuation">(</span>ai<span class="token punctuation">)</span> Q<span class="token punctuation">:</span>\Python\project\ChatGLM\ChatGLM<span class="token operator">-</span>6B<span class="token operator">-</span>main<span class="token operator">&gt;</span>python cli_demo<span class="token punctuation">.</span>py
Explicitly passing a `revision` <span class="token keyword">is</span> encouraged when loading a model <span class="token keyword">with</span> custom code to ensure no malicious code has been contributed <span class="token keyword">in</span> a newer revision<span class="token punctuation">.</span>
Explicitly passing a `revision` <span class="token keyword">is</span> encouraged when loading a configuration <span class="token keyword">with</span> custom code to ensure no malicious code has been contributed <span class="token keyword">in</span> a newer revision<span class="token punctuation">.</span>
Explicitly passing a `revision` <span class="token keyword">is</span> encouraged when loading a model <span class="token keyword">with</span> custom code to ensure no malicious code has been contributed <span class="token keyword">in</span> a newer revision<span class="token punctuation">.</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span> Logging error <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\quantization.py"</span><span class="token punctuation">,</span> line <span class="token number">19</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    <span class="token keyword">from</span> cpm_kernels<span class="token punctuation">.</span>kernels<span class="token punctuation">.</span>base <span class="token keyword">import</span> LazyKernelCModule<span class="token punctuation">,</span> KernelFunction<span class="token punctuation">,</span> round_up
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\cpm_kernels\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    <span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> library
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\cpm_kernels\library\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">2</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    <span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> cuda
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\cpm_kernels\library\cuda.py"</span><span class="token punctuation">,</span> line <span class="token number">7</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    cuda <span class="token operator">=</span> Lib<span class="token punctuation">.</span>from_lib<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">,</span> ctypes<span class="token punctuation">.</span>WinDLL<span class="token punctuation">(</span><span class="token string">"nvcuda.dll"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  File <span class="token string">"q:\ide\python\cpython37\lib\ctypes\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">356</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __init__
    self<span class="token punctuation">.</span>_handle <span class="token operator">=</span> _dlopen<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_name<span class="token punctuation">,</span> mode<span class="token punctuation">)</span>
OSError<span class="token punctuation">:</span> <span class="token punctuation">[</span>WinError <span class="token number">126</span><span class="token punctuation">]</span> 找不到指定的模块。

During handling of the above exception<span class="token punctuation">,</span> another exception occurred<span class="token punctuation">:</span>

Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"q:\ide\python\cpython37\lib\logging\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">1034</span><span class="token punctuation">,</span> <span class="token keyword">in</span> emit
    msg <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
  File <span class="token string">"q:\ide\python\cpython37\lib\logging\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">880</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token builtin">format</span>
    <span class="token keyword">return</span> fmt<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span>
  File <span class="token string">"q:\ide\python\cpython37\lib\logging\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">619</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token builtin">format</span>
    record<span class="token punctuation">.</span>message <span class="token operator">=</span> record<span class="token punctuation">.</span>getMessage<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"q:\ide\python\cpython37\lib\logging\__init__.py"</span><span class="token punctuation">,</span> line <span class="token number">380</span><span class="token punctuation">,</span> <span class="token keyword">in</span> getMessage
    msg <span class="token operator">=</span> msg <span class="token operator">%</span> self<span class="token punctuation">.</span>args
TypeError<span class="token punctuation">:</span> <span class="token keyword">not</span> <span class="token builtin">all</span> arguments converted during string formatting
Call stack<span class="token punctuation">:</span>
  File <span class="token string">"cli_demo.py"</span><span class="token punctuation">,</span> line <span class="token number">8</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"THUDM\ChatGLM-6B"</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>half<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\auto_factory.py"</span><span class="token punctuation">,</span> line <span class="token number">467</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    pretrained_model_name_or_path<span class="token punctuation">,</span> <span class="token operator">*</span>model_args<span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">,</span> <span class="token operator">**</span>hub_kwargs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\modeling_utils.py"</span><span class="token punctuation">,</span> line <span class="token number">2629</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    model <span class="token operator">=</span> cls<span class="token punctuation">(</span>config<span class="token punctuation">,</span> <span class="token operator">*</span>model_args<span class="token punctuation">,</span> <span class="token operator">**</span>model_kwargs<span class="token punctuation">)</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\modeling_chatglm.py"</span><span class="token punctuation">,</span> line <span class="token number">1061</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __init__
    self<span class="token punctuation">.</span>quantize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>quantization_bit<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>quantization_embeddings<span class="token punctuation">,</span> use_quantization_cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> empty_init<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\modeling_chatglm.py"</span><span class="token punctuation">,</span> line <span class="token number">1424</span><span class="token punctuation">,</span> <span class="token keyword">in</span> quantize
    <span class="token keyword">from</span> <span class="token punctuation">.</span>quantization <span class="token keyword">import</span> quantize<span class="token punctuation">,</span> QuantizedEmbedding<span class="token punctuation">,</span> QuantizedLinear<span class="token punctuation">,</span> load_cpu_kernel
  File <span class="token string">"&lt;frozen importlib._bootstrap&gt;"</span><span class="token punctuation">,</span> line <span class="token number">983</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _find_and_load
  File <span class="token string">"&lt;frozen importlib._bootstrap&gt;"</span><span class="token punctuation">,</span> line <span class="token number">967</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _find_and_load_unlocked
  File <span class="token string">"&lt;frozen importlib._bootstrap&gt;"</span><span class="token punctuation">,</span> line <span class="token number">677</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _load_unlocked
  File <span class="token string">"&lt;frozen importlib._bootstrap_external&gt;"</span><span class="token punctuation">,</span> line <span class="token number">728</span><span class="token punctuation">,</span> <span class="token keyword">in</span> exec_module
  File <span class="token string">"&lt;frozen importlib._bootstrap&gt;"</span><span class="token punctuation">,</span> line <span class="token number">219</span><span class="token punctuation">,</span> <span class="token keyword">in</span> _call_with_frames_removed
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\quantization.py"</span><span class="token punctuation">,</span> line <span class="token number">46</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    logger<span class="token punctuation">.</span>warning<span class="token punctuation">(</span><span class="token string">"Failed to load cpm_kernels:"</span><span class="token punctuation">,</span> exception<span class="token punctuation">)</span>
Message<span class="token punctuation">:</span> <span class="token string">'Failed to load cpm_kernels:'</span>
Arguments<span class="token punctuation">:</span> <span class="token punctuation">(</span>OSError<span class="token punctuation">(</span><span class="token number">22</span><span class="token punctuation">,</span> <span class="token string">'找不到指定的模块。'</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">126</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
No compiled kernel found<span class="token punctuation">.</span>
Compiling kernels <span class="token punctuation">:</span> C<span class="token punctuation">:</span>\Users\user\<span class="token punctuation">.</span>cache\huggingface\modules\transformers_modules\ChatGLM<span class="token operator">-</span>6B\quantization_kernels_parallel<span class="token punctuation">.</span>c
Compiling gcc <span class="token operator">-</span>O3 <span class="token operator">-</span>fPIC <span class="token operator">-</span>pthread <span class="token operator">-</span>fopenmp <span class="token operator">-</span>std<span class="token operator">=</span>c99 C<span class="token punctuation">:</span>\Users\user\<span class="token punctuation">.</span>cache\huggingface\modules\transformers_modules\ChatGLM<span class="token operator">-</span>6B\quantization_kernels_parallel<span class="token punctuation">.</span>c <span class="token operator">-</span>shared <span class="token operator">-</span>o C<span class="token punctuation">:</span>\Users\user\<span class="token punctuation">.</span>cache\huggingface\modules\transformers_modules\ChatGLM<span class="token operator">-</span>6B\quant
ization_kernels_parallel<span class="token punctuation">.</span>so
<span class="token string">'gcc'</span> 不是内部或外部命令，也不是可运行的程序
或批处理文件。
Compile default cpu kernel failed<span class="token punctuation">,</span> using default cpu kernel code<span class="token punctuation">.</span>
Compiling gcc <span class="token operator">-</span>O3 <span class="token operator">-</span>fPIC <span class="token operator">-</span>std<span class="token operator">=</span>c99 C<span class="token punctuation">:</span>\Users\user\<span class="token punctuation">.</span>cache\huggingface\modules\transformers_modules\ChatGLM<span class="token operator">-</span>6B\quantization_kernels<span class="token punctuation">.</span>c <span class="token operator">-</span>shared <span class="token operator">-</span>o C<span class="token punctuation">:</span>\Users\user\<span class="token punctuation">.</span>cache\huggingface\modules\transformers_modules\ChatGLM<span class="token operator">-</span>6B\quantization_kernels<span class="token punctuation">.</span>so
<span class="token string">'gcc'</span> 不是内部或外部命令，也不是可运行的程序
或批处理文件。
Compile default cpu kernel failed<span class="token punctuation">.</span>
Failed to load kernel<span class="token punctuation">.</span>
Cannot load cpu <span class="token keyword">or</span> cuda kernel<span class="token punctuation">,</span> quantization failed<span class="token punctuation">:</span>
Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>
  File <span class="token string">"cli_demo.py"</span><span class="token punctuation">,</span> line <span class="token number">8</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>
    model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"THUDM\ChatGLM-6B"</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>half<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\models\auto\auto_factory.py"</span><span class="token punctuation">,</span> line <span class="token number">467</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    pretrained_model_name_or_path<span class="token punctuation">,</span> <span class="token operator">*</span>model_args<span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">,</span> <span class="token operator">**</span>hub_kwargs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs
  File <span class="token string">"Q:\IDE\Python\vitrual_enviroment\ai\lib\site-packages\transformers\modeling_utils.py"</span><span class="token punctuation">,</span> line <span class="token number">2629</span><span class="token punctuation">,</span> <span class="token keyword">in</span> from_pretrained
    model <span class="token operator">=</span> cls<span class="token punctuation">(</span>config<span class="token punctuation">,</span> <span class="token operator">*</span>model_args<span class="token punctuation">,</span> <span class="token operator">**</span>model_kwargs<span class="token punctuation">)</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\modeling_chatglm.py"</span><span class="token punctuation">,</span> line <span class="token number">1061</span><span class="token punctuation">,</span> <span class="token keyword">in</span> __init__
    self<span class="token punctuation">.</span>quantize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>quantization_bit<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>quantization_embeddings<span class="token punctuation">,</span> use_quantization_cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> empty_init<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\modeling_chatglm.py"</span><span class="token punctuation">,</span> line <span class="token number">1439</span><span class="token punctuation">,</span> <span class="token keyword">in</span> quantize
    self<span class="token punctuation">.</span>transformer <span class="token operator">=</span> quantize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>transformer<span class="token punctuation">,</span> bits<span class="token punctuation">,</span> use_quantization_cache<span class="token operator">=</span>use_quantization_cache<span class="token punctuation">,</span> empty_init<span class="token operator">=</span>empty_init<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
  File <span class="token string">"C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\quantization.py"</span><span class="token punctuation">,</span> line <span class="token number">464</span><span class="token punctuation">,</span> <span class="token keyword">in</span> quantize
    <span class="token keyword">assert</span> kernels <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
AssertionError

</code></pre> 
<h4><a id="_118"></a>问题原因：配置内容没有修改、依赖包不完整</h4> 
<h4><a id="_120"></a>解决方法</h4> 
<p>这里有多个问题需要解决</p> 
<ol><li> <p>gcc编译器未安装</p> 
  <ul><li>项目的readme有写(位于使用方式/环境安装部分)，如果安装时需要用cpu运行，必须安装gcc与openmp</li><li><img src="https://images2.imgbox.com/41/3a/g3pSYOi9_o.png" alt="在这里插入图片描述"></li><li>下载的地址位于 （https://jmeubank.github.io/tdm-gcc/） 点进去以后因为推荐的是TDM-GCC 10.3.0，因此单击TDM-GCC 10.3.0 release，进去之后再点击（tdm64-gcc-10.3.0-2.exe）下载。</li><li>下载完成后点击运行文件，点create，然后点下一步，遇到能选openmp的时候记得选上就行</li></ul> </li><li> <p>配置内容未修改</p> 
  <ul><li>这里首先，要修改模型文件中的（即THUDM\ChatGLM-6B下的，或是model中的）THUDM/ChatGLM-6B/quantization.py这一文件</li><li><code>from cpm_kernels.kernels.base import LazyKernelCModule, KernelFunction, round_up</code>这行注释掉，后面会飘红也没关系，不用改</li><li>把kernels = Kernel(…）注释掉，替换为kernels =CPUKernel() # 说实话这一步是否有用我不是很确定，后续重新运行时依然提示<code>NameError: name 'CPUKernel' is not defined</code>，但是不影响程序运行</li><li>再<strong>把已缓存的.cache目录下文件删掉！！！</strong> ，这里看报错的地方，我的缓存文件在 File “C:\Users\user/.cache\huggingface\modules\transformers_modules\ChatGLM-6B\quantization.py”</li><li>把.cache后面的huggingface文件夹直接删除</li><li>最后要记得修改cli_demo.py中的内容 
    <ul><li><code>model = AutoModel.from_pretrained("THUDM\ChatGLM-6B", trust_remote_code=True).half().cuda()</code></li><li>改成：<code>model = AutoModel.from_pretrained("THUDM\ChatGLM-6B", trust_remote_code=True).float()</code></li></ul> </li></ul> </li></ol> 
<p>以上修改完成后，我的程序就已经可以运行了<br> <img src="https://images2.imgbox.com/15/f3/hUqVhFfW_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="web_demo2py_143"></a>想要运行web_demo2.py时遇到</h2> 
<h3><a id="No_matching_distribution_found_for_streamlitchat_145"></a>No matching distribution found for streamlit-chat</h3> 
<pre><code class="prism language-shell"><span class="token punctuation">(</span>ai<span class="token punctuation">)</span> Q:<span class="token punctuation">\</span>Python<span class="token punctuation">\</span>project<span class="token punctuation">\</span>ChatGLM<span class="token punctuation">\</span>ChatGLM-6B-main<span class="token operator">&gt;</span>pip <span class="token function">install</span> streamlit-chat
ERROR: Could not <span class="token function">find</span> a version that satisfies the requirement streamlit-chat <span class="token punctuation">(</span>from versions: <span class="token number">0.0</span>.1<span class="token punctuation">)</span>
ERROR: No matching distribution found <span class="token keyword">for</span> streamlit-chat

</code></pre> 
<h3><a id="python38_155"></a>问题原因：组件必须要在python&gt;3.8的环境才能运行！！！！</h3> 
<p>哇这个问题真的是没把我弄死，streamlit很容易就用pip install 下载完成了，后面的streamlit-chat怎么也下载不了，经历了查资料、换源等一系列操作之后，我决定从PYPI官网下载，如愿以偿让我找到了就在我用如下命令进行下载时</p> 
<pre><code class="prism language-python"><span class="token punctuation">(</span>ai<span class="token punctuation">)</span> Q<span class="token punctuation">:</span>\Python\project\ChatGLM\ChatGLM<span class="token operator">-</span>6B<span class="token operator">-</span>main<span class="token operator">&gt;</span>pip <span class="token operator">-</span><span class="token operator">-</span>default<span class="token operator">-</span>timeout<span class="token operator">=</span><span class="token number">100</span> install streamlit_chat<span class="token operator">-</span><span class="token number">0.0</span><span class="token number">.2</span><span class="token number">.2</span><span class="token operator">-</span>py3<span class="token operator">-</span>none<span class="token operator">-</span><span class="token builtin">any</span><span class="token punctuation">.</span>whl
Processing q<span class="token punctuation">:</span>\python\project\chatglm\chatglm<span class="token operator">-</span>6b<span class="token operator">-</span>main\streamlit_chat<span class="token operator">-</span><span class="token number">0.0</span><span class="token number">.2</span><span class="token number">.2</span><span class="token operator">-</span>py3<span class="token operator">-</span>none<span class="token operator">-</span><span class="token builtin">any</span><span class="token punctuation">.</span>whl
Requirement already satisfied<span class="token punctuation">:</span> streamlit<span class="token operator">&gt;=</span><span class="token number">0.63</span> <span class="token keyword">in</span> q<span class="token punctuation">:</span>\ide\python\vitrual_enviroment\ai\lib\site<span class="token operator">-</span>packages <span class="token punctuation">(</span><span class="token keyword">from</span> streamlit<span class="token operator">-</span>chat<span class="token operator">==</span><span class="token number">0.0</span><span class="token number">.2</span><span class="token number">.2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">1.23</span><span class="token number">.1</span><span class="token punctuation">)</span>
ERROR<span class="token punctuation">:</span> Package <span class="token string">'streamlit-chat'</span> requires a different Python<span class="token punctuation">:</span> <span class="token number">3.7</span><span class="token number">.2</span> <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token string">'&gt;=3.8'</span>
WARNING<span class="token punctuation">:</span> You are using pip version <span class="token number">22.0</span><span class="token number">.3</span><span class="token punctuation">;</span> however<span class="token punctuation">,</span> version <span class="token number">23.1</span><span class="token number">.2</span> <span class="token keyword">is</span> available<span class="token punctuation">.</span>
You should consider upgrading via the <span class="token string">'Q:\IDE\Python\vitrual_enviroment\ai\Scripts\python.exe -m pip install --upgrade pip'</span> command<span class="token punctuation">.</span>

</code></pre> 
<p>看懂了吗xdm，这个组件必须要在python&gt;3.8的环境才能运行。。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/abfdeb82fd8944773484eb4e5f00e901/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">windows10企业版安装西门子博途V15---02安装软件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e8cf51f0967cdaefaad7fefa1a19454a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">XML之解析（知识详解即基本使用）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>