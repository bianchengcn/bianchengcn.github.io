<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>利用BP神经网络 设计一个三层神经网络解决手写数字的识别问题 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="利用BP神经网络 设计一个三层神经网络解决手写数字的识别问题" />
<meta property="og:description" content="文章目录 1. 题目描述2. 求解原理（1）算法模型（2）算法原理 3.编程实现（1）环境说明（2）实验方案（3）Python实现 1. 题目描述 设计一个三层神经网络解决手写数字的识别问题。
要求：
（1）三层神经网络如图：784-15-10结构
（2）使用随机梯度下降算法和MNIST训练数据。
http://yann.lecun.com/exdb/mnist/
2. 求解原理 （1）算法模型 利用BP神经网络，这里有输入层、隐藏层、输出层共三层，包括两个阶段，
第一阶段是输入信息的正向传播，其中隐藏层节点的输出为：
输出层节点的输出：
第二阶段是误差反向传播阶段
第p个样本的误差：
p个样本的总误差：
（2）算法原理 BP算法可以描述如下：
（1）工作信号正向传播：输入信号从输入层经隐藏层，传向输出层，在输出端产生输出信号，这是工作信号的正向传播。在信号的向前传递过程中网络的权值是固定不变的，每一层神经元的状态只影响下一层神经元的状态。如果在输出层不能得到期望的输出，则转入误差信号反向传播。正向传播的数学模型为：
其中n为样本数，w为权值，θ为偏置，
为激活函数，这里选择sigmoid函数为激活函数。
（2）误差信号反向传播：网络的实际输出与期望输出之间差值即为误差信号，误差信号由输出端开始逐层向前传播，这是误差信号的反向传播。在误差信号反向传播的过程中，网络的权值由误差反馈进行调节。通过权值的不断修正使网络的实际输出更接近期望输出。
在反向传播中，第p个样本的误差为：
p个样本的总误差：
梯度为：
其中：
3.编程实现 （1）环境说明 python3.7
tensorflow2.1.0
（2）实验方案 数据来源：
手写数字图片数据集MNIST，它包含了0-9共10种数字的手写图片，每种数字一共7000张图片，采样自不同书写风格的真实手写图片，一共70000张图片，其中60000张图片作为训练集，用来训练模型，剩下的10000图片作为测试集，用来预测或者测试，训练集和测试集共同组成了MNIST数据集。
考虑到手写数字图片包含的信息比较简单，每张图片均被缩放到28 × 28的大小，同时
只保留了灰度信息。这些图片由真人书写，包含了如字体大小、书写风格、粗细等丰富的样式，确保这些图片的分布与真实的手写数字图片的分布尽可能的接近，从而保证了模型的泛化能力。
实验计划和流程：
（1）网络搭建。搭建784-15-10结构的神经网络，激活函数类型为 ReLU。
（2）模型训练。使用交叉熵作为损失函数。
验证和测试：
手写数字图片 MNIST 数据集的训练误差曲线如图所示，由于 3 层的神经网络表达能力较强，手写数字图片识别任务相对简单，误差值可以较快速、稳定地下降。其中，把对数据集的所有样本迭代一遍叫作一个Epoch，我们可以在间隔数个 Epoch 后测试模型的准确率等指标，方便监控模型的训练效果。
通过简单的 3 层神经网络，训练固定的 200 个 Epoch 后，我们在测试集上获得了91.59%的准确率。模型的训练误差曲线如图一所示，误差函数为交叉熵，其值越小，模型预测效果就越好。测试准确率曲线如图二所示。
如果使用复杂的神经网络模型，增加数据增强环节，精调网络超参数等技巧，可以获得更高的模型性能。
图一 训练误差 图二 准确率 （3）Python实现 import tensorflow as tf # 导入TF库 from tensorflow import keras # 导入TF子库keras from tensorflow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d3a20eb169f32e4c799d90934e11280c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-20T10:35:28+08:00" />
<meta property="article:modified_time" content="2020-05-20T10:35:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">利用BP神经网络 设计一个三层神经网络解决手写数字的识别问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1__1" rel="nofollow">1. 题目描述</a></li><li><a href="#2__8" rel="nofollow">2. 求解原理</a></li><li><ul><li><a href="#1_9" rel="nofollow">（1）算法模型</a></li><li><a href="#2_20" rel="nofollow">（2）算法原理</a></li></ul> 
  </li><li><a href="#3_39" rel="nofollow">3.编程实现</a></li><li><ul><li><a href="#1_40" rel="nofollow">（1）环境说明</a></li><li><a href="#2_43" rel="nofollow">（2）实验方案</a></li><li><a href="#3Python_61" rel="nofollow">（3）Python实现</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1__1"></a>1. 题目描述</h2> 
<p>设计一个三层神经网络解决手写数字的识别问题。<br> 要求：<br> （1）三层神经网络如图：784-15-10结构<br> （2）使用随机梯度下降算法和MNIST训练数据。<br> http://yann.lecun.com/exdb/mnist/<br> <img src="https://images2.imgbox.com/52/5e/GWWslBAC_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2__8"></a>2. 求解原理</h2> 
<h3><a id="1_9"></a>（1）算法模型</h3> 
<p>利用BP神经网络，这里有输入层、隐藏层、输出层共三层，包括两个阶段，</p> 
<ol><li>第一阶段是输入信息的正向传播，其中隐藏层节点的输出为：<br> <img src="https://images2.imgbox.com/80/1a/zgvN7rex_o.png" alt="在这里插入图片描述"><br> 输出层节点的输出：<br> <img src="https://images2.imgbox.com/60/a6/6IjCKr04_o.png" alt="在这里插入图片描述"></li><li>第二阶段是误差反向传播阶段<br> 第p个样本的误差：<br> <img src="https://images2.imgbox.com/fc/04/AjGxjUYR_o.png" alt="在这里插入图片描述"><br> p个样本的总误差：<br> <img src="https://images2.imgbox.com/1f/0b/95Oxb4gU_o.png" alt="在这里插入图片描述"></li></ol> 
<h3><a id="2_20"></a>（2）算法原理</h3> 
<p>BP算法可以描述如下：<br> （1）工作信号正向传播：输入信号从输入层经隐藏层，传向输出层，在输出端产生输出信号，这是工作信号的正向传播。在信号的向前传递过程中网络的权值是固定不变的，每一层神经元的状态只影响下一层神经元的状态。如果在输出层不能得到期望的输出，则转入误差信号反向传播。正向传播的数学模型为：<br> <img src="https://images2.imgbox.com/e3/60/qeJ7OGPX_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a8/f5/QL3ZbJXa_o.png" alt="在这里插入图片描述"><br> 其中n为样本数，w为权值，θ为偏置，<br> <img src="https://images2.imgbox.com/ef/21/Qug5pOeZ_o.png" alt="在这里插入图片描述"><br> 为激活函数，这里选择sigmoid函数为激活函数。<br> （2）误差信号反向传播：网络的实际输出与期望输出之间差值即为误差信号，误差信号由输出端开始逐层向前传播，这是误差信号的反向传播。在误差信号反向传播的过程中，网络的权值由误差反馈进行调节。通过权值的不断修正使网络的实际输出更接近期望输出。<br> 在反向传播中，第p个样本的误差为：<br> <img src="https://images2.imgbox.com/4a/a5/kcC41mVO_o.png" alt="在这里插入图片描述"><br> p个样本的总误差：<br> <img src="https://images2.imgbox.com/d2/92/aEo0vlpJ_o.png" alt="在这里插入图片描述"><br> 梯度为：<br> <img src="https://images2.imgbox.com/8b/8e/E7daCwaV_o.png" alt="在这里插入图片描述"><br> 其中：<br> <img src="https://images2.imgbox.com/cd/fb/2LMELl6U_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e9/27/Y9ZyBnH1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b8/f4/LoYAte1M_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/62/29/hjSs5LT9_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_39"></a>3.编程实现</h2> 
<h3><a id="1_40"></a>（1）环境说明</h3> 
<p>python3.7<br> tensorflow2.1.0</p> 
<h3><a id="2_43"></a>（2）实验方案</h3> 
<p>数据来源：<br> 手写数字图片数据集MNIST，它包含了0-9共10种数字的手写图片，每种数字一共7000张图片，采样自不同书写风格的真实手写图片，一共70000张图片，其中60000张图片作为训练集，用来训练模型，剩下的10000图片作为测试集，用来预测或者测试，训练集和测试集共同组成了MNIST数据集。<br> 考虑到手写数字图片包含的信息比较简单，每张图片均被缩放到28 × 28的大小，同时<br> 只保留了灰度信息。这些图片由真人书写，包含了如字体大小、书写风格、粗细等丰富的样式，确保这些图片的分布与真实的手写数字图片的分布尽可能的接近，从而保证了模型的泛化能力。<br> 实验计划和流程：<br> （1）网络搭建。搭建784-15-10结构的神经网络，激活函数类型为 ReLU。<br> （2）模型训练。使用交叉熵作为损失函数。<br> 验证和测试：<br> 手写数字图片 MNIST 数据集的训练误差曲线如图所示，由于 3 层的神经网络表达能力较强，手写数字图片识别任务相对简单，误差值可以较快速、稳定地下降。其中，把对数据集的所有样本迭代一遍叫作一个Epoch，我们可以在间隔数个 Epoch 后测试模型的准确率等指标，方便监控模型的训练效果。<br> 通过简单的 3 层神经网络，训练固定的 200 个 Epoch 后，我们在测试集上获得了91.59%的准确率。模型的训练误差曲线如图一所示，误差函数为交叉熵，其值越小，模型预测效果就越好。测试准确率曲线如图二所示。<br> 如果使用复杂的神经网络模型，增加数据增强环节，精调网络超参数等技巧，可以获得更高的模型性能。<br> <img src="https://images2.imgbox.com/0b/74/MakE7sYp_o.png" alt="在这里插入图片描述"></p> 
<center>
  图一 训练误差 
</center> 
<p><img src="https://images2.imgbox.com/f8/ea/tJxUmdYl_o.png" alt="在这里插入图片描述"></p> 
<center>
  图二 准确率 
</center> 
<h3><a id="3Python_61"></a>（3）Python实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf  <span class="token comment"># 导入TF库</span>
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras  <span class="token comment"># 导入TF子库keras</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> datasets  <span class="token comment"># 导入Tf子库</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


<span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""数据处理函数"""</span>
    x <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">.</span> <span class="token operator">-</span> <span class="token number">1</span>  <span class="token comment"># tf.cast函数可以完成精度转换</span>
    y <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y

<span class="token comment"># load_data()函数返回两个元组（tuple）对象，第一个是训练集，第二个是测试集</span>
<span class="token comment"># 每个tuple的第一个元素是多个训练图片数据的X,第二个元素是训练图片对应的类别数字Y</span>
<span class="token comment"># 其中X的大小为（60000，28，28），代表了60000个样本，每个样本由28行、28列构成</span>
<span class="token comment"># 由于是灰度图片，故没有RGB通道；训练集Y的大小为（60000），代表了这60000个样本的标签数字</span>
<span class="token comment"># 每个样本标签用一个范围为0~9的数字表示。测试集X的大小为（10000，28，28）</span>
<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> datasets<span class="token punctuation">.</span>mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 加载MNIST数据集</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment"># TensorFlow中加载的MNIST数据图片，数值的范围为[0,255]。在机器学习中间，一般希望数据的范围</span>
<span class="token comment"># 在0周围的小范围内分布。通过预处理步骤，我们把[0,255]像素范围归一化到[0,1.]区间,在缩放到</span>
<span class="token comment"># [-1,1]区间，从而有利于模型的训练</span>
<span class="token comment"># x = 2*tf.convert_to_tensor(x, dtype=tf.float32)/255.-1  # 转换为浮点张量，并缩放到-1~1</span>
<span class="token comment"># y = tf.convert_to_tensor(y, dtype=tf.int32)  # 转换为整型张量</span>

<span class="token comment"># 处理训练数据</span>
batch_size <span class="token operator">=</span> <span class="token number">512</span>
train_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 构建数据集对象</span>
train_dataset <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>  <span class="token comment"># 随机打散，批量训练</span>

<span class="token comment"># 处理测试数据</span>
test_dataset <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> test_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">)</span><span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>


<span class="token comment"># 使用TensorFlow的Sequential容器可以非常方便地搭建多层网络</span>
<span class="token comment"># 利用Sequential容器封装3个网络层，前网络层的输出默认作为下一层的输入</span>
model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token comment"># 2个非线性层的嵌套模型</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 隐藏层1 ，15</span>
    layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 输出层，输出节点为10</span>
<span class="token comment"># w' = w - lr * grad, 更新网络参数</span>
optimizer <span class="token operator">=</span> optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>  <span class="token comment"># 优化器，加快训练速度</span>
total_epoch <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment"># 迭代次数</span>

<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss_ce <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 模型训练</span>
            <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>  <span class="token comment"># 构建梯度记录环境</span>
                <span class="token comment"># 打平操作，[b,28,28] =&gt; [b,784]</span>
                x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># step1. 得到模型输出output [b, 784] =&gt; [b, 10]</span>
                out <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
                <span class="token comment"># [b] =&gt; [b, 10]</span>
                y_onehot <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># one-hot编码</span>
                <span class="token comment"># 计算交叉熵 [b, 10]</span>
                loss_ce <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>categorical_crossentropy<span class="token punctuation">(</span>y_onehot<span class="token punctuation">,</span> out<span class="token punctuation">,</span> from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># step3. 自动计算参数的梯度w1, w2, w3, b1, b2, b3</span>
            grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss_ce<span class="token punctuation">,</span> model<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>grads<span class="token punctuation">,</span> model<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> step<span class="token punctuation">,</span> f<span class="token string">'loss_ce: {float(loss_ce)}'</span><span class="token punctuation">)</span>
        <span class="token comment"># test</span>
        total_correct <span class="token operator">=</span> <span class="token number">0</span>
        total_num <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_dataset<span class="token punctuation">:</span>
            <span class="token comment"># x:[b,28,28] --&gt; [b,784]</span>
            <span class="token comment"># y:[b]</span>
            x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment"># [b,10]</span>
            out <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token comment"># out --&gt; prob [b,10]</span>
            prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment"># [b,10] --&gt; [b], int32</span>
            pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
            <span class="token comment"># pred:[b]</span>
            <span class="token comment"># y:[b]</span>
            <span class="token comment"># correct: [b], True: equal; False: not equal</span>
            correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
            correct <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>correct<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">)</span>

            total_correct <span class="token operator">+=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
            total_num <span class="token operator">+=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_num
        <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> f<span class="token string">'test acc: {acc}'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            epoch_plt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
            ce_plt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss_ce<span class="token punctuation">)</span>
            acc_plt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>

    <span class="token keyword">return</span> epoch_plt<span class="token punctuation">,</span> ce_plt<span class="token punctuation">,</span> acc_plt


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    epoch_plt<span class="token punctuation">,</span> ce_plt<span class="token punctuation">,</span> acc_plt <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    epoch_plt<span class="token punctuation">,</span> ce_plt<span class="token punctuation">,</span> acc_plt <span class="token operator">=</span> main<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_plt<span class="token punctuation">,</span> ce_plt<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"yellow"</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'s'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'CrossEntropy'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 显示中文标签</span>
    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'训练误差'</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_plt<span class="token punctuation">,</span> acc_plt<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"red"</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'s'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 显示中文标签</span>
    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'准确率'</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1bb0bbc0a74e4739454b879c61fa8518/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">初步了解“树”</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d7b4846a966347c080f9c1261c30c5e4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于AutoJs的抖音短视频养号Apk文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>