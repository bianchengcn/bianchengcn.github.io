<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLO_v1讲解 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLO_v1讲解" />
<meta property="og:description" content="文章目录 一：YOLO_v1的出现二：网络模型三：训练阶段step1：训练数据的制作step2：损失函数 四：测试阶段step1：输入原图step2：计算每个bbox的类别得分 五：YOLO_v1的不足 一：YOLO_v1的出现 YOLO_v1的出现，打破了Faster R-CNN的一统图像检测江山的格局，首次提出了one-stage的图像检测模型，真正实现了end-to-end，其具体优势如下：
快，非常的快，基础版YOLO每秒可以处理45帧；快速版能达到155帧每秒，绝对是开挂的速度准确率高，map达到63.4 map易优化，整体上是一个单阶段网络，很容易进行端到端的优化 二：网络模型 通过上面结构图，我们可以很直接的看出yolov1的网络结构，用了一系列的卷积层、最大池化下载样层以及全连接层，在这里说明一下全连接层。
通过第一个Conn.Layer时，需要进行三个处理：①transpose处理。不一定要进行②flateen。因为要和全连接层连接，所以要进行展平处理。③fc(4096)。通过一个节点个数为4096的全连接层进行连接。此时得到一个4096维的向量。
通过第二个Conn.Layer时，需要进行两个处理：①通过一个节点个数为1470的全连接层。因为要得到一个7×7×30的特征矩阵，所以需要1470。②进行reshape处理。把向量调整为7×7×30的矩阵。
可见，YOLOv1的网络结构还是比较简单的，因为它的关键部分在于它的逻辑，就是它的输入输出的映射和损失函数设计，下面我将从训练阶段和测试阶段进行剖析：
三：训练阶段 step1：训练数据的制作 标签为007732.jpg 341 217 487 375 8 114 209 183 298 8 237 110 320 176 19，其中8表示chair，19表示tvmonitor。
下面演示如何将这些坐标和类别信息转化为YOLO的target张量（7×7×30）：
首先，7×7好理解，就是对一张图片，切成了49个cell，我们对其中一个cell的30个元素进行分析，如下图：
如果该cell中有物体（可能有多个物体），那么x1,y1,w1,h1=x2,y2,w2,h2=cell中程序遍历到的最后一个物体的坐标和长宽，confidence1=confidence2=1，类别就是独热编码。
如果该cell中没有物体，那么30个元素都是0。
def encode(self, boxes, labels): &#34;&#34;&#34; Encode box coordinates and class labels as one target tensor. Args: boxes: (tensor) [[x1, y1, x2, y2]_obj1, ...], normalized from 0.0 to 1.0 w.r.t. image width/height. labels: (tensor) [c_obj1, c_obj2, ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/2ed4aa12fed76b4797b677dfbdd1daa4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-08T10:37:17+08:00" />
<meta property="article:modified_time" content="2022-09-08T10:37:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLO_v1讲解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#YOLO_v1_1" rel="nofollow">一：YOLO_v1的出现</a></li><li><a href="#_7" rel="nofollow">二：网络模型</a></li><li><a href="#_18" rel="nofollow">三：训练阶段</a></li><li><ul><li><a href="#step1_19" rel="nofollow">step1：训练数据的制作</a></li><li><a href="#step2_103" rel="nofollow">step2：损失函数</a></li></ul> 
  </li><li><a href="#_185" rel="nofollow">四：测试阶段</a></li><li><ul><li><a href="#step1_186" rel="nofollow">step1：输入原图</a></li><li><a href="#step2bbox_188" rel="nofollow">step2：计算每个bbox的类别得分</a></li></ul> 
  </li><li><a href="#YOLO_v1_195" rel="nofollow">五：YOLO_v1的不足</a></li></ul> 
</div> 
<p></p> 
<h2><a id="YOLO_v1_1"></a>一：YOLO_v1的出现</h2> 
<p><mark>YOLO_v1的出现，打破了Faster R-CNN的一统图像检测江山的格局</mark>，首次提出了one-stage的图像检测模型，真正实现了end-to-end，其具体优势如下：</p> 
<ul><li><strong>快，非常的快</strong>，基础版YOLO每秒可以处理45帧；快速版能达到155帧每秒，绝对是开挂的速度</li><li><strong>准确率高</strong>，map达到63.4 map</li><li><strong>易优化</strong>，整体上是一个单阶段网络，很容易进行端到端的优化</li></ul> 
<h2><a id="_7"></a>二：网络模型</h2> 
<p><img src="https://images2.imgbox.com/ed/e9/5RXJaNj6_o.png" alt="在这里插入图片描述"><br> 通过上面结构图，我们可以很直接的看出<code>yolov1</code>的网络结构，用了一系列的<mark>卷积层、最大池化下载样层以及全连接层</mark>，在这里说明一下全连接层。</p> 
<p><strong>通过第一个Conn.Layer时</strong>，需要进行三个处理：①transpose处理。不一定要进行②flateen。因为要和全连接层连接，所以要进行展平处理。③fc(<code>4096</code>)。通过一个节点个数为4096的全连接层进行连接。此时得到一个<code>4096维</code>的向量。</p> 
<p><strong>通过第二个Conn.Layer时</strong>，需要进行两个处理：①通过一个节点个数为<code>1470</code>的全连接层。因为要得到一个<code>7×7×30</code>的特征矩阵，所以需要<code>1470</code>。②进行reshape处理。把向量调整为<code>7×7×30</code>的矩阵。</p> 
<p>可见，YOLOv1的网络结构还是比较简单的，<strong>因为它的关键部分在于它的逻辑，就是它的输入输出的映射和损失函数设计，下面我将从训练阶段和测试阶段进行剖析</strong>：</p> 
<h2><a id="_18"></a>三：训练阶段</h2> 
<h3><a id="step1_19"></a>step1：训练数据的制作</h3> 
<p><img src="https://images2.imgbox.com/53/19/1fq6dWaY_o.png" alt="在这里插入图片描述"><br> 标签为<code>007732.jpg 341 217 487 375 8 114 209 183 298 8 237 110 320 176 19</code>，其中8表示chair，19表示tvmonitor。</p> 
<p>下面演示如何将这些坐标和类别信息转化为YOLO的target张量<code>（7×7×30）</code>：</p> 
<p>首先，7×7好理解，就是对一张图片，切成了49个cell，我们对其中一个cell的30个元素进行分析，如下图：<br> <img src="https://images2.imgbox.com/28/4b/Ai9zH9y8_o.png" alt="在这里插入图片描述"><br> 如果该cell中有物体（可能有多个物体），那么x1,y1,w1,h1=x2,y2,w2,h2=cell中程序遍历到的最后一个物体的坐标和长宽，<mark>confidence1=confidence2=1</mark>，类别就是独热编码。</p> 
<p>如果该cell中没有物体，那么30个元素都是0。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> boxes<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" Encode box coordinates and class labels as one target tensor.
        Args:
            boxes: (tensor) [[x1, y1, x2, y2]_obj1, ...], normalized from 0.0 to 1.0 w.r.t. image width/height.
            labels: (tensor) [c_obj1, c_obj2, ...]
        Returns:
            An encoded tensor sized [S, S, 5 x B + C], 5=(x, y, w, h, conf)
        """</span>

        S<span class="token punctuation">,</span> B<span class="token punctuation">,</span> C <span class="token operator">=</span> self<span class="token punctuation">.</span>S<span class="token punctuation">,</span> self<span class="token punctuation">.</span>B<span class="token punctuation">,</span> self<span class="token punctuation">.</span>C
        N <span class="token operator">=</span> <span class="token number">5</span> <span class="token operator">*</span> B <span class="token operator">+</span> C

        target <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>S<span class="token punctuation">,</span> S<span class="token punctuation">,</span> N<span class="token punctuation">)</span>
        cell_size <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>S<span class="token punctuation">)</span>
        boxes_wh <span class="token operator">=</span> boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># width and height for each box, [n, 2]</span>
        boxes_xy <span class="token operator">=</span> <span class="token punctuation">(</span>boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span> <span class="token comment"># center x &amp; y for each box, [n, 2]</span>
        <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>boxes<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            xy<span class="token punctuation">,</span> wh<span class="token punctuation">,</span> label <span class="token operator">=</span> boxes_xy<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span> boxes_wh<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>labels<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span>

            ij <span class="token operator">=</span> <span class="token punctuation">(</span>xy <span class="token operator">/</span> cell_size<span class="token punctuation">)</span><span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1.0</span>
            i<span class="token punctuation">,</span> j <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>ij<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>ij<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># y &amp; x index which represents its location on the grid.</span>
            x0y0 <span class="token operator">=</span> ij <span class="token operator">*</span> cell_size <span class="token comment"># x &amp; y of the cell left-top corner.</span>
            xy_normalized <span class="token operator">=</span> <span class="token punctuation">(</span>xy <span class="token operator">-</span> x0y0<span class="token punctuation">)</span> <span class="token operator">/</span> cell_size <span class="token comment"># x &amp; y of the box on the cell, normalized from 0.0 to 1.0.</span>

            <span class="token comment"># TBM, remove redundant dimensions from target tensor.</span>
            <span class="token comment"># To remove these, loss implementation also has to be modified.</span>
            <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>
                s <span class="token operator">=</span> <span class="token number">5</span> <span class="token operator">*</span> k
                target<span class="token punctuation">[</span>j<span class="token punctuation">,</span> i<span class="token punctuation">,</span> s  <span class="token punctuation">:</span>s<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> xy_normalized
                target<span class="token punctuation">[</span>j<span class="token punctuation">,</span> i<span class="token punctuation">,</span> s<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">:</span>s<span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> wh
                target<span class="token punctuation">[</span>j<span class="token punctuation">,</span> i<span class="token punctuation">,</span> s<span class="token operator">+</span><span class="token number">4</span>    <span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>
            target<span class="token punctuation">[</span>j<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token number">5</span><span class="token operator">*</span>B <span class="token operator">+</span> label<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>

        <span class="token keyword">return</span> target
</code></pre> 
<p>target = torch.zeros(S, S, N) #就是YOLO的输出格式；其中<code>S=7，N=5 * B + C=30</code></p> 
<p>以前面的那张007732.jpg为例，其中右下角的白色椅子的编码结果（target[5, 5]）为：</p> 
<p>tensor([0.7960, 0.5253, 0.2920, 0.4213, 1.0000, 0.7960, 0.5253, 0.2920, 0.4213,</p> 
<p>1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>0.0000, 0.0000, 0.0000])</p> 
<p>其中黑色小椅子的编码结果（target[4, 2]）为：</p> 
<p>tensor([0.0790, 0.7320, 0.1380, 0.2373, 1.0000, 0.0790, 0.7320, 0.1380, 0.2373,</p> 
<p>1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>0.0000, 0.0000, 0.0000])</p> 
<p>其中tvmonitor的编码结果（target[2, 3]）为：</p> 
<p>tensor([0.8990, 0.6693, 0.1660, 0.1760, 1.0000, 0.8990, 0.6693, 0.1660, 0.1760,</p> 
<p>1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,</p> 
<p>0.0000, 0.0000, 1.0000])<br> <img src="https://images2.imgbox.com/ae/a6/jqilxt8A_o.png" alt="在这里插入图片描述"><br> 从这个for循环可以看出，两个<code>x、y、w、h</code>和置信度都是一样的，就是我们前面说的，即，如果训练图像的某个cell含有多个物体的中心点的话，只保留程序遍历到的最后一个物体。</p> 
<p>到此，训练数据的已经处理成YOLO需要的格式<code>（7×7×30）</code>。</p> 
<h3><a id="step2_103"></a>step2：损失函数</h3> 
<p>将原图resize成<code>448×448</code>后输入网络中，最后输出<code>（7×7×30）</code>的张量。下面来讲解如何根据标注好的训练样本，计算损失。</p> 
<p>根据标签数据，计算出含有物体中心点的cell的掩码 coord_mask[0,:,:].numpy()<br> <img src="https://images2.imgbox.com/d6/a3/m5hfUNE7_o.png" alt="在这里插入图片描述"><br> 取反，得到不含有物体中心点的cell的掩码 noobj_mask[0,:,:].numpy()<br> <img src="https://images2.imgbox.com/ec/d0/rijL0buY_o.png" alt="在这里插入图片描述"><br> 下面对损失函数的五个部分进行分析：<br> <img src="https://images2.imgbox.com/b2/d0/NCar6lSz_o.png" alt="在这里插入图片描述"><br> 先简介一下<mark>这个五个部分</mark>：</p> 
<p>①：含有物体中心点的cell里，负责预测的bounding box预测出的xy的MSE</p> 
<p>②：含有物体中心点的cell里，负责预测的bounding box预测出的wh的MSE</p> 
<p>③：含有物体中心点的cell里，负责预测的bounding box预测出的存在物体的置信度的误差。Ci是真实值，用预测出的框体与GT的IOU表示，Ci_hat是yolo的预测值，然后累加MSE。预测置信度对后续非极大值抑制有用。</p> 
<p>④：不含有物体中心点的cell里，每一个bounding box都要参与到loss的计算，Ci一直=0；Ci_hat=bounding box的预测值，然后累加MSE。</p> 
<p>⑤：含有物体中心点的cell里，预测出的物体类别向量和GT对应的向量的MSE。</p> 
<p>先看④——所有不含物体中心点的cell的预测分数与全零向量的MSE：<br> <img src="https://images2.imgbox.com/77/02/ZdhI3idR_o.png" alt="在这里插入图片描述"><br> <strong>A步骤</strong>：上面是Yolo对某张图像前向传播的输出张量，下面是该图的目标张量。</p> 
<p><strong>B步骤</strong>：乘以 不含物体中心点的cell的掩码。</p> 
<p><strong>C步骤</strong>：挖去了三个洞（去除了3个含有物体中心点的cell的数据）。</p> 
<p><strong>D步骤</strong>：一共49个格子，挖去3个=46，B=2，因此拉直的向量长度为92。</p> 
<p><strong>E步骤</strong>：计算MSE——对应论文中的④。</p> 
<p>总结④：如果某个cell中不包含物体的中心点，那这个cell的bounding box预测出物体的置信度就要趋近于0。</p> 
<p>再看①②③⑤：<br> <img src="https://images2.imgbox.com/92/08/bU2upfoA_o.png" alt="在这里插入图片描述"></p> 
<p><strong>A步骤</strong>：上一行图是Yolo对某张图像前向传播的输出张量，下一行图是该图的目标张量。</p> 
<p><strong>B步骤</strong>：乘以含物体中心点的cell的掩码。</p> 
<p><strong>C步骤</strong>：只留下三个向量（3个含有物体中心点的cell的数据）。</p> 
<p><strong>D步骤</strong>：向量合并</p> 
<p><strong>E步骤</strong>：提取出类别的向量。</p> 
<p><strong>F步骤</strong>：计算MSE——对应论文中的⑤</p> 
<p>总结⑤：如果有物体，预测正确类别误差就=0。</p> 
<p><strong>G步骤</strong>：提取出xywh和置信度的向量，向量合并</p> 
<p><mark>H步骤：每一个cell会有2个bounding box，每个bounding box与ground truth的IOU，然后，得到索引矩阵（可以用来确定哪个bounding box对于这个cell来说是responsible for that prediction的）</mark></p> 
<p><strong>I步骤</strong>：提取出有责任的bounding box的向量。</p> 
<p><strong>J步骤</strong>：bounding box预测出的xy与GT算MSE——对应论文中的①；bounding box预测出的wh与GT算MSE——对应论文中的②；</p> 
<p>总结①②：bounding box预测出的xywh和真实的越接近，误差越小。</p> 
<p><strong>K步骤</strong>：bounding box预测出的置信度与GT算MSE——对应论文中的③。</p> 
<p><strong>（ 这里有个tips</strong>，就是计算置信度的时候使用了公式：</p> 
<p><img src="https://images2.imgbox.com/74/a1/msnVHYoy_o.png" alt="在这里插入图片描述"></p> 
<p>对于label计算这个公式，<code>Pr(Object)=1</code>,最终使用的是iou_predict_truth来作为置信度目标，这样有更深层的含义，就是希望学习到的是如何计算当前预测的box与ground_truth的iou来作为置信度，这个真的好厉害啊，但是也好复杂，他想要学习到这个信息，是不是最起码得对目标位置有个准确的认识，然后还要学习到iou计算公式，最终才会计算到这个iou。<strong>）</strong></p> 
<p>总结③：yolo预测出的置信度和真实的置信度（预测出来的框体和GT的IOU）越接近误差越小。</p> 
<p>最后再将这些误差带权叠加，作为最终的损失函数。再讲一下损失函数前面的权重参数：</p> 
<ul><li> <p>位置相关误差（坐标、IOU）与分类误差对网络loss的贡献值是不同的，因此YOLO在计算loss时，使用<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
          
          
            λ 
           
           
           
             c 
            
           
             o 
            
           
             o 
            
           
             r 
            
           
             d 
            
           
          
         
           = 
          
         
           5 
          
         
        
          λ_{coord} = 5 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span style="margin-right: 0.0278em;" class="mord mathnormal mtight">coor</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">5</span></span></span></span></span> 修正 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           c 
          
         
           o 
          
         
           o 
          
         
           r 
          
         
           d 
          
         
           E 
          
         
           r 
          
         
           r 
          
         
           o 
          
         
           r 
          
         
        
          coordError 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span style="margin-right: 0.0278em;" class="mord mathnormal">coor</span><span class="mord mathnormal">d</span><span style="margin-right: 0.0576em;" class="mord mathnormal">E</span><span style="margin-right: 0.0278em;" class="mord mathnormal">rror</span></span></span></span></span>。</p> </li><li> <p>在计算IOU误差时，包含物体的格子与不包含物体的格子，二者的IOU误差对网络loss的贡献值是不同的。若采用相同的权值，那么<strong>不包含物体的格子的confidence值近似为0，变相放大了不包含物体的格子的confidence误差在计算网络参数梯度时的影响</strong>。为解决这个问题，YOLO 使用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
          
          
            λ 
           
           
           
             n 
            
           
             o 
            
           
             o 
            
           
             b 
            
           
             j 
            
           
          
         
           = 
          
         
           0.5 
          
         
        
          λ_{noobj} = 0.5 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">oo</span><span style="margin-right: 0.0572em;" class="mord mathnormal mtight">bj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.5</span></span></span></span></span> 修正 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           i 
          
         
           o 
          
         
           u 
          
         
           E 
          
         
           r 
          
         
           r 
          
         
           o 
          
         
           r 
          
         
        
          iouError 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span style="margin-right: 0.0576em;" class="mord mathnormal">E</span><span style="margin-right: 0.0278em;" class="mord mathnormal">rror</span></span></span></span></span>。（注此处的‘包含’是指存在一个物体，它的中心坐标落入到格子内）。</p> </li></ul> 
<h2><a id="_185"></a>四：测试阶段</h2> 
<h3><a id="step1_186"></a>step1：输入原图</h3> 
<p>经过YOLO_v1网络后，输出<code>7×7×(2×5+20)</code>的张量</p> 
<h3><a id="step2bbox_188"></a>step2：计算每个bbox的类别得分</h3> 
<p><img src="https://images2.imgbox.com/e4/34/akrk1T3z_o.png" alt="在这里插入图片描述"></p> 
<ul><li>从每一个cell中找出20个类别score中最大的类别，作为cell中两box预测出的类别</li><li>针对每一个cell中的两个bbox，选择置信度大的box来代表这个cell，并按上面的公式计算出该box的类别得分</li><li>这样只剩下49个bbox，最后进行NMS</li></ul> 
<h2><a id="YOLO_v1_195"></a>五：YOLO_v1的不足</h2> 
<p><strong>首先</strong>，相比RCNN系列物体检测方法，YOLO具有以下缺点：</p> 
<ul><li>识别物体位置精准性差。</li><li>召回率低。</li></ul> 
<p><strong>再者</strong>，针对于YOLO的v1系列的短板，也有以下几个缺陷：</p> 
<ul><li>由于感受野太大，只分了 7×7个cell，对一些群体性的小目标检测效果很差。</li><li>如果一个cell中有多个类别，也检测不出</li><li>定位不准确，毕竟没有RP，光想一步到位了</li></ul> 
<hr> 
<p>  至此我对YOLO_v1的全部流程与细节，进行了深度讲解，希望对大家有所帮助，有不懂的地方或者建议，欢迎大家在下方留言评论。（码字不易，各位看官<mark>点个赞，手留余香</mark>~谢谢！）</p> 
<p>我是努力在CV泥潭中摸爬滚打的江南咸鱼，我们一起努力，不留遗憾！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/87c8435e1b7728a03cfa5efb6b6b8c6c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">路由跳转的两种方式及动态创建路由</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b646fa560171eb72e0dd9592a2130812/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">两个单链表求和</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>