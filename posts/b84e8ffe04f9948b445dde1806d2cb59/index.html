<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>抓取猫眼电影排行上 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="抓取猫眼电影排行上" />
<meta property="og:description" content="经过一系列基础知识的铺垫，我们将学习利用requests库和正则表达式来抓取猫眼TOP100的相关内容。
一、抓取首页 首先抓取第一页的内容。我们实现了get__one__page()方法，并给它传入url参数。然后将抓取的页面结果返回，再通过main()方法调用。初步代码实现如下：
import requests def get_one_page(url): headers={ &#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.03.3325.162 Safari/537.36&#39; } response=requests.get(url, headers=headers) if response.status_code==200: return response.text return None def main(): url=&#39;http://maoyan.com/board/4&#39; html=get_one_page(url) print(html) main() 这样运行后，就可以成功获取首页的源代码了。然后就需要解析页面，提取出我们想要的信息。
二、正则提取 可以看到一部电影对应的源代码是一个dd节点，我们用正则表达式来提取这里面的一些电影信息。首先，需要提取它的排名信息。而它的排名信息是在class为board-index的i节点内，这里利用非贪婪匹配来提取i节点内的信息，正则表达式为：&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;
随后需要提取电影的图片。可以看到，后面有a节点，其内部有两个img节点。经过检查后发现，第二个img节点的data-src属性是图片链接。提取正则表达式为：
&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&#34;(.*?)&#34;
再往后，需要提取电影的名称，它在后面的p节点内，class为name。所以，可以用name做一个标致位，然后进一步提取到其内a节点的正文内容，此时正则表达式为：
&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&#34;(.*?)&#34;.*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;
同理，提取主演、发布时间、评分等，总正则表达式为：
&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&#34;(.*?)&#34;.*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;
def parse_one_page(html): pattern=re.compile( &#39;&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&#34;(.*?)&#34;.*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;&#39;, re.S) items = re.findall(pattern, html) print(items) 这样就可以成功地将一页的10个信息都提取出来，这时一个列表形式。
但数据比较杂乱，我们再将匹配结果处理一下，遍历提取结果并生成字典，此时方法改写如下：
def parse_one_page(html): pattern=re.compile( &#39;&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&#34;(.*?)&#34;.*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;&#39;, re.S) items = re.findall(pattern, html) print(items) for item in items: yield{ &#39;index&#39;:item[0], &#39;image&#39;: item[1], &#39;title&#39;: item[2]." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/b84e8ffe04f9948b445dde1806d2cb59/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-02T23:03:52+08:00" />
<meta property="article:modified_time" content="2023-07-02T23:03:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">抓取猫眼电影排行上</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>经过一系列基础知识的铺垫，我们将学习利用requests库和正则表达式来抓取猫眼TOP100的相关内容。</p> 
<h2>一、抓取首页</h2> 
<p>首先抓取第一页的内容。我们实现了get__one__page()方法，并给它传入url参数。然后将抓取的页面结果返回，再通过main()方法调用。初步代码实现如下：</p> 
<pre><code class="language-python">import requests
def get_one_page(url):
    headers={
        'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.03.3325.162 Safari/537.36'
    }
    response=requests.get(url, headers=headers)
    if response.status_code==200:
        return response.text
    return None
def main():
    url='http://maoyan.com/board/4'
    html=get_one_page(url)
    print(html)
main()</code></pre> 
<p>这样运行后，就可以成功获取首页的源代码了。然后就需要解析页面，提取出我们想要的信息。</p> 
<h2>二、正则提取</h2> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/58/86/qyZWnb4r_o.jpg"></p> 
<p> 可以看到一部电影对应的源代码是一个dd节点，我们用正则表达式来提取这里面的一些电影信息。首先，需要提取它的排名信息。而它的排名信息是在class为board-index的i节点内，这里利用非贪婪匹配来提取i节点内的信息，正则表达式为：&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;</p> 
<p>随后需要提取电影的图片。可以看到，后面有a节点，其内部有两个img节点。经过检查后发现，第二个img节点的data-src属性是图片链接。提取正则表达式为：</p> 
<p>&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)"</p> 
<p>再往后，需要提取电影的名称，它在后面的p节点内，class为name。所以，可以用name做一个标致位，然后进一步提取到其内a节点的正文内容，此时正则表达式为：<br> &lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;</p> 
<p>同理，提取主演、发布时间、评分等，总正则表达式为：</p> 
<p>&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;</p> 
<pre><code class="language-python">def parse_one_page(html):

    pattern=re.compile(
        '&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;',
        re.S)
    items = re.findall(pattern, html)
    print(items)</code></pre> 
<p>这样就可以成功地将一页的10个信息都提取出来，这时一个列表形式。</p> 
<p>但数据比较杂乱，我们再将匹配结果处理一下，遍历提取结果并生成字典，此时方法改写如下：</p> 
<pre><code class="language-python">def parse_one_page(html):

    pattern=re.compile(
        '&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;',
        re.S)
    items = re.findall(pattern, html)
    print(items)
    for item in items:
        yield{
            'index':item[0],
            'image': item[1],
            'title': item[2].strip(),
            'actor': item[3].strip()[3:] if len(item[3])&gt;3 else '',
            'time': item[4].strip()[5:] if len(item[4])&gt;5 else '',
            'score':item[5].strip() + item[6].strip()
        }</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4609130902568fd69e34714065e897e5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用新版FLIR (FLIR_ADAS_v2) 红外数据集训练基于pytorch的YOLOv7模型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0db7cde0bd8b1d98309a8f72ace6492b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">抓取猫眼电影排行下</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>