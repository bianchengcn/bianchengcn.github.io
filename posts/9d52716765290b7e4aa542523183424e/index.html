<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch 转 onnx - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch 转 onnx" />
<meta property="og:description" content="ONNX 是目前模型部署中最重要的中间表示之一，在把 PyTorch 模型转换成 ONNX 模型时，使用的 torch 接口是 torch.onnx.export
这里记录了 pytorch 模型转 onnx 时的原理和注意事项，还包括部分 PyTorch 与 ONNX 的算子对应关系。
1 torch.onnx.export原理 1.1 导出计算图 TorchScript 是一种序列化和优化 PyTorch 模型的格式，在优化过程中，一个torch.nn.Module模型会被转换成 TorchScript 的 torch.jit.ScriptModule 模型。通常 TorchScript 也被当成一种中间表示来使用。
torch.onnx.export中需要的模型实际上是一个torch.jit.ScriptModule。而要把普通 PyTorch 模型转一个这样的 TorchScript 模型，有跟踪（trace）和记录（script）两种导出计算图的方法。
如果给torch.onnx.export传入了一个普通 PyTorch 模型（torch.nn.Module），那么这个模型会默认使用 trace 的方法导出：
t o r c h . n n . M o d u l e → t o r c h . o n n x . e x p o r t （默认使用 t o r c h ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/9d52716765290b7e4aa542523183424e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-02T20:23:36+08:00" />
<meta property="article:modified_time" content="2024-01-02T20:23:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch 转 onnx</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>ONNX 是目前模型部署中最重要的中间表示之一，在把 PyTorch 模型转换成 ONNX 模型时，使用的 torch 接口是 <code>torch.onnx.export</code><br> 这里记录了 pytorch 模型转 onnx 时的原理和注意事项，还包括部分 PyTorch 与 ONNX 的算子对应关系。</p> 
<h4><a id="1_torchonnxexport_4"></a>1 <code>torch.onnx.export</code>原理</h4> 
<h5><a id="11__5"></a>1.1 导出计算图</h5> 
<p>TorchScript 是一种序列化和优化 PyTorch 模型的格式，在优化过程中，一个torch.nn.Module模型会被转换成 TorchScript 的 torch.jit.ScriptModule 模型。通常 TorchScript 也被当成一种中间表示来使用。</p> 
<p>torch.onnx.export中需要的模型实际上是一个torch.jit.ScriptModule。而要把普通 PyTorch 模型转一个这样的 TorchScript 模型，有跟踪（trace）和记录（script）两种导出计算图的方法。</p> 
<p>如果给torch.onnx.export传入了一个普通 PyTorch 模型（torch.nn.Module），那么这个模型会默认使用 trace 的方法导出：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
           
            
             
             
               t 
              
             
               o 
              
             
               r 
              
             
               c 
              
             
               h 
              
             
               . 
              
             
               n 
              
             
               n 
              
             
               . 
              
             
               M 
              
             
               o 
              
             
               d 
              
             
               u 
              
             
               l 
              
             
               e 
              
             
            
           
          
         
         
         
           → 
          
          
           
           
             t 
            
           
             o 
            
           
             r 
            
           
             c 
            
           
             h 
            
           
             . 
            
           
             o 
            
           
             n 
            
           
             n 
            
           
             x 
            
           
             . 
            
           
             e 
            
           
             x 
            
           
             p 
            
           
             o 
            
           
             r 
            
           
             t 
            
           
             （默认使用 
            
           
             t 
            
           
             o 
            
           
             r 
            
           
             c 
            
           
             h 
            
           
             . 
            
           
             j 
            
           
             i 
            
           
             t 
            
           
             . 
            
           
             t 
            
           
             r 
            
           
             a 
            
           
             c 
            
           
             e 
            
           
             ） 
            
           
          
         
         
          
           
            
             
             
               o 
              
             
               n 
              
             
               n 
              
             
               x 
              
             
               模型 
              
             
            
           
          
         
        
       
         \boxed{torch.nn.Module} \xrightarrow{torch.onnx.export（默认使用 torch.jit.trace）} \boxed{onnx模型} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4481em; vertical-align: -0.34em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0344em;"><span class="" style="top: -3.3744em;"><span class="pstrut" style="height: 3.3744em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mord mathnormal">t</span><span class="mord mathnormal">orc</span><span class="mord mathnormal">h</span><span class="mord">.</span><span class="mord mathnormal">nn</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">e</span></span></span></span></span><span class="" style="top: -3.0344em;"><span class="pstrut" style="height: 3.3744em;"></span><span class="stretchy fbox" style="height: 1.3744em; border-style: solid; border-width: 0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.34em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel x-arrow"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.1081em;"><span class="" style="top: -3.322em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight x-arrow-pad"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">orc</span><span class="mord mathnormal mtight">h</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">nn</span><span class="mord mathnormal mtight">x</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">or</span><span class="mord mathnormal mtight">t</span><span class="mord cjk_fallback mtight">（默认使用</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">orc</span><span class="mord mathnormal mtight">h</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">ji</span><span class="mord mathnormal mtight">t</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ce</span><span class="mord cjk_fallback mtight">）</span></span></span></span><span class="svg-align" style="top: -2.689em;"><span class="pstrut" style="height: 2.7em;"></span><span class="hide-tail" style="height: 0.522em; min-width: 1.469em;"> 
            <svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"> 
             <path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"></path> 
            </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.011em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.3633em; vertical-align: -0.34em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0233em;"><span class="" style="top: -3.3633em;"><span class="pstrut" style="height: 3.3633em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mord mathnormal">o</span><span class="mord mathnormal">nn</span><span class="mord mathnormal">x</span><span class="mord cjk_fallback">模型</span></span></span></span></span><span class="" style="top: -3.0233em;"><span class="pstrut" style="height: 3.3633em;"></span><span class="stretchy fbox" style="height: 1.3633em; border-style: solid; border-width: 0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.34em;"><span class=""></span></span></span></span></span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
           
            
             
             
               t 
              
             
               o 
              
             
               r 
              
             
               c 
              
             
               h 
              
             
               . 
              
             
               n 
              
             
               n 
              
             
               . 
              
             
               M 
              
             
               o 
              
             
               d 
              
             
               u 
              
             
               l 
              
             
               e 
              
             
            
           
          
         
         
         
           → 
          
          
           
           
             t 
            
           
             o 
            
           
             r 
            
           
             c 
            
           
             h 
            
           
             . 
            
           
             j 
            
           
             i 
            
           
             t 
            
           
             . 
            
           
             s 
            
           
             c 
            
           
             r 
            
           
             i 
            
           
             p 
            
           
             t 
            
           
             s 
            
           
          
          
           
           
             t 
            
           
             o 
            
           
             r 
            
           
             c 
            
           
             h 
            
           
             . 
            
           
             j 
            
           
             i 
            
           
             t 
            
           
             . 
            
           
             t 
            
           
             r 
            
           
             a 
            
           
             c 
            
           
             e 
            
           
          
         
         
          
           
            
             
             
               t 
              
             
               o 
              
             
               r 
              
             
               c 
              
             
               h 
              
             
               . 
              
             
               j 
              
             
               i 
              
             
               t 
              
             
               . 
              
             
               S 
              
             
               c 
              
             
               r 
              
             
               i 
              
             
               p 
              
             
               t 
              
             
               M 
              
             
               o 
              
             
               d 
              
             
               u 
              
             
               l 
              
             
               e 
              
             
            
           
          
         
         
         
           → 
          
          
           
           
             t 
            
           
             o 
            
           
             r 
            
           
             c 
            
           
             h 
            
           
             . 
            
           
             o 
            
           
             n 
            
           
             n 
            
           
             x 
            
           
             . 
            
           
             e 
            
           
             x 
            
           
             p 
            
           
             o 
            
           
             r 
            
           
             t 
            
           
          
         
         
          
           
            
             
             
               o 
              
             
               n 
              
             
               n 
              
             
               x 
              
             
               模型 
              
             
            
           
          
         
        
       
         \boxed{torch.nn.Module} \xrightarrow[torch.jit.scripts]{torch.jit.trace} \boxed{torch.jit.ScriptModule} \xrightarrow{torch.onnx.export} \boxed{onnx模型} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.8523em; vertical-align: -0.7442em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0344em;"><span class="" style="top: -3.3744em;"><span class="pstrut" style="height: 3.3744em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mord mathnormal">t</span><span class="mord mathnormal">orc</span><span class="mord mathnormal">h</span><span class="mord">.</span><span class="mord mathnormal">nn</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">e</span></span></span></span></span><span class="" style="top: -3.0344em;"><span class="pstrut" style="height: 3.3744em;"></span><span class="stretchy fbox" style="height: 1.3744em; border-style: solid; border-width: 0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.34em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel x-arrow"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.1081em;"><span class="" style="top: -3.322em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight x-arrow-pad"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">orc</span><span class="mord mathnormal mtight">h</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">ji</span><span class="mord mathnormal mtight">t</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ce</span></span></span></span><span class="svg-align" style="top: -2.689em;"><span class="pstrut" style="height: 2.7em;"></span><span class="hide-tail" style="height: 0.522em; min-width: 1.469em;"> 
            <svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"> 
             <path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"></path> 
            </svg></span></span><span class="" style="top: -2.0919em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight x-arrow-pad"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">orc</span><span class="mord mathnormal mtight">h</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">ji</span><span class="mord mathnormal mtight">t</span><span class="mord mtight">.</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">scr</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">pt</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7442em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.6425em; vertical-align: -0.5344em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0344em;"><span class="" style="top: -3.5689em;"><span class="pstrut" style="height: 3.5689em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mord mathnormal">t</span><span class="mord mathnormal">orc</span><span class="mord mathnormal">h</span><span class="mord">.</span><span class="mord mathnormal">ji</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mord mathnormal" style="margin-right: 0.0278em;">cr</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.109em;">ptM</span><span class="mord mathnormal">o</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">e</span></span></span></span></span><span class="" style="top: -3.0344em;"><span class="pstrut" style="height: 3.5689em;"></span><span class="stretchy fbox" style="height: 1.5689em; border-style: solid; border-width: 0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.5344em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel x-arrow"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.1081em;"><span class="" style="top: -3.322em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight x-arrow-pad"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">orc</span><span class="mord mathnormal mtight">h</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">nn</span><span class="mord mathnormal mtight">x</span><span class="mord mtight">.</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">or</span><span class="mord mathnormal mtight">t</span></span></span></span><span class="svg-align" style="top: -2.689em;"><span class="pstrut" style="height: 2.7em;"></span><span class="hide-tail" style="height: 0.522em; min-width: 1.469em;"> 
            <svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"> 
             <path d="M0 241v40h399891c-47.3 35.3-84 78-110 128
-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20
 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7
 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85
-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5
-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67
 151.7 139 205zm0 0v40h399900v-40z"></path> 
            </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.011em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.3633em; vertical-align: -0.34em;"></span><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0233em;"><span class="" style="top: -3.3633em;"><span class="pstrut" style="height: 3.3633em;"></span><span class="boxpad"><span class="mord"><span class="mord"><span class="mord mathnormal">o</span><span class="mord mathnormal">nn</span><span class="mord mathnormal">x</span><span class="mord cjk_fallback">模型</span></span></span></span></span><span class="" style="top: -3.0233em;"><span class="pstrut" style="height: 3.3633em;"></span><span class="stretchy fbox" style="height: 1.3633em; border-style: solid; border-width: 0.04em;"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.34em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<p>trace 方法只能通过实际运行一遍模型的方法导出模型的静态图，即无法识别出模型中的控制流（如循环）；script 方法则能通过解析模型来正确记录所有的控制流</p> 
<p>下面的代码段额可以用来对比 trace 和 script 两种方法获取 graph 的区别</p> 
<pre><code class="prism language-python">    <span class="token keyword">import</span> torch 
 
    <span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> 
            self<span class="token punctuation">.</span>n <span class="token operator">=</span> n 
            self<span class="token punctuation">.</span>conv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> 
    
        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span> 
                x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
            <span class="token keyword">return</span> x 
    
    
    models <span class="token operator">=</span> <span class="token punctuation">[</span>Model<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Model<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span> 
    model_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'model_2'</span><span class="token punctuation">,</span> <span class="token string">'model_3'</span><span class="token punctuation">]</span> 
    
    <span class="token keyword">for</span> model<span class="token punctuation">,</span> model_name <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>models<span class="token punctuation">,</span> model_names<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        dummy_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> 
        dummy_output <span class="token operator">=</span> model<span class="token punctuation">(</span>dummy_input<span class="token punctuation">)</span> 
        model_trace <span class="token operator">=</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>trace<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dummy_input<span class="token punctuation">)</span> 
        model_script <span class="token operator">=</span> torch<span class="token punctuation">.</span>jit<span class="token punctuation">.</span>script<span class="token punctuation">(</span>model<span class="token punctuation">)</span> 
    
        <span class="token comment"># 跟踪法与直接 torch.onnx.export(model, ...)等价 </span>
        torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model_trace<span class="token punctuation">,</span> dummy_input<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>model_name<span class="token punctuation">}</span></span><span class="token string">_trace.onnx'</span></span><span class="token punctuation">,</span> example_outputs<span class="token operator">=</span>dummy_output<span class="token punctuation">)</span> 
        <span class="token comment"># 记录法必须先调用 torch.jit.sciprt </span>
        torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model_script<span class="token punctuation">,</span> dummy_input<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>model_name<span class="token punctuation">}</span></span><span class="token string">_script.onnx'</span></span><span class="token punctuation">,</span> example_outputs<span class="token operator">=</span>dummy_output<span class="token punctuation">)</span> 
</code></pre> 
<p>在这段代码里，定义了一个带循环的模型，模型通过参数n来控制输入张量被卷积的次数。之后，各创建了一个n=2和n=3的模型。把这两个模型分别用跟踪和记录的方法进行导出。</p> 
<p>值得一提的是，由于这里的两个模型（model_trace, model_script）是 TorchScript 模型，export函数已经不需要再运行一遍模型了。（如果模型是用跟踪法得到的，那么在执行torch.jit.trace的时候就运行过一遍了；而用记录法导出时，模型不需要实际运行）参数中的dummy_input和dummy_output`仅仅是为了获取输入和输出张量的类型和形状。</p> 
<p>trace 方法得到的 ONNX 模型结构，会把 for 循环展开，这样不同的 n，得到的 ONNX 模型 graph 是不一样的；而 scripts 方法得到的 ONNX 模型，用 Loop 节点来表示循环，这样对于不同的 n，得到的 ONNX 模型结构是一样的</p> 
<p>实际上，推理引擎对静态图的支持更好，通常在模型部署时不需要显式地把 PyTorch 模型转成 TorchScript 模型，直接把 PyTorch 模型用 torch.onnx.export 借助 trace 方法导出即可。</p> 
<h5><a id="12_torchonnxexport__54"></a>1.2 <code>torch.onnx.export</code> 参数注解</h5> 
<p>这里主要记录对于模型部署比较重要的几个参数在模型部署中还如何设置，该函数的 API 文档：https://pytorch.org/docs/stable/onnx.html#functions</p> 
<p><code>torch.onnx.export</code> 在 <code>torch.onnx.__init__.py</code> 文件中的定义如下:</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">export</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> args<span class="token punctuation">,</span> f<span class="token punctuation">,</span> export_params<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> training<span class="token operator">=</span>TrainingMode<span class="token punctuation">.</span>EVAL<span class="token punctuation">,</span> 
                input_names<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> output_names<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> aten<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> export_raw_ir<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> 
                operator_export_type<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> opset_version<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> _retain_param_name<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
                do_constant_folding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> example_outputs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> strip_doc_string<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
                dynamic_axes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> keep_initializers_as_inputs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> custom_opsets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
                enable_onnx_checker<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> use_external_data_format<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
</code></pre> 
<p>前三个必选参数分别为 torch 模型、模型输入（转 ONNX 的时候的 dummy input）、ONNX 模型的保存路径。</p> 
<ul><li> <p>export_params<br> 模型中是否存储模型权重。IR 中一般包含两类信息，模型结构和模型权重，这两类信息可以在同一个文件里存储，也可以分文件存储。<br> 一般来说，如果转 onnx 是用来部署的，那么选择设置为 true，存放在同一个文件中；如果是用来在在不同框架间传递模型，则设为 false，分开存放</p> </li><li> <p>input_names, output_names<br> 设置输入输出张量的名称。如果不设置，会默认使用 tensor ID（数字） 作为 张量名称。ONNX 的张量名称一般都需要设置，因为大部分推理引擎在设置模型输入和获取输出数据的时候，都是以字典的形式进行访问处理，其中张量名称作为 key，数据作为 value</p> </li><li> <p>opset_version<br> 转换时参考哪个 ONNX 算子集版本，默认为 9</p> </li><li> <p>dynamic_axes<br> 指定 onnx 动态 shape 的动态维度。<br> 为了追求效率，ONNX 默认所有参与运算的张量都是静态的（张量的形状不发生改变）。但在实际应用中，我们又希望模型的输入张量是动态的，尤其是本来就没有形状限制的全卷积模型。因此，我们需要显式地指明输入输出张量的哪几个维度的大小是可变的。</p> <pre><code class="prism language-python">  <span class="token keyword">import</span> torch 

  <span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
          <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> 
          self<span class="token punctuation">.</span>conv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> 
   
      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
          x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
          <span class="token keyword">return</span> x 
   
   
  model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span> 
  dummy_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> 
  model_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'model_static.onnx'</span><span class="token punctuation">,</span>  
  <span class="token string">'model_dynamic_0.onnx'</span><span class="token punctuation">,</span>  
  <span class="token string">'model_dynamic_23.onnx'</span><span class="token punctuation">]</span> 
   
  dynamic_axes_0 <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span> 
      <span class="token string">'in'</span> <span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span>， <span class="token string">'batch'</span><span class="token punctuation">}</span>， 
      <span class="token string">'out'</span> <span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'batch'</span><span class="token punctuation">}</span> 
  <span class="token punctuation">}</span> 
   
  torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>
      model<span class="token punctuation">,</span> 
      dummy_input<span class="token punctuation">,</span> 
      model_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
      input_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'in'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
      output_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span>
  <span class="token punctuation">)</span> 

  torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>
      model<span class="token punctuation">,</span> dummy_input<span class="token punctuation">,</span> 
      model_names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
      input_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'in'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
      output_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
      dynamic_axes<span class="token operator">=</span>dynamic_axes_0
  <span class="token punctuation">)</span> 
</code></pre> <p>导出 2 个 ONNX 模型，分别为没有动态维度、第 0 维动态的模型。<br> 这里使用字典的方式来表示动态维度，因为 ONNX 要求每个动态维度都有一个名字，否则会有一堆 warning</p> </li></ul> 
<h4><a id="2_torch__onnx__125"></a>2 torch 转 onnx 时候的额外操作</h4> 
<h5><a id="21__onnx__126"></a>2.1 添加额外处理逻辑到 onnx 中</h5> 
<p>可以把一些后处理的逻辑放在模型里，来简化除运行模型之外的其他代码。<code>torch.onnx.is_in_onnx_export()</code> 可以达到这样的效果，这个函数只会在执行<code>torch.onnx.export()</code>的时候返回 true</p> 
<pre><code class="prism language-python">    <span class="token keyword">import</span> torch 
 
    <span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> 
            self<span class="token punctuation">.</span>conv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> 
     
        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
            <span class="token keyword">if</span> torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>is_in_onnx_export<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
                x <span class="token operator">=</span> torch<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> 
            <span class="token keyword">return</span> x 
</code></pre> 
<p>这里，仅在模型导出 onnx 时把输出张量的数值限制在[0, 1]之间。使用 <code>is_in_onnx_export</code>确让我们方便地在代码中添加和模型部署相关的逻辑。但是，这些突兀的部署逻辑会降低代码整体的可读性。另外，<code>is_in_onnx_export</code>只能在每个需要添加部署逻辑的地方都“打补丁”，不方便进行统一的管理。</p> 
<h5><a id="22__trace_144"></a>2.2 中断张量 trace</h5> 
<p>如果在 pytorch 的模型脚本中有一些比较离谱的操作，会把某些取决于输入的中间结果变成常量，从而使导出的 ONNX 模型和原来的模型不等价。<br> 如下是一个 trace 中断的例子：</p> 
<pre><code class="prism language-python">    <span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> 
     
        <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
            x <span class="token operator">=</span> x <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
            <span class="token keyword">return</span> x<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> x<span class="token punctuation">]</span><span class="token punctuation">)</span> 
     
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>       
    dummy_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> 
    torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dummy_input<span class="token punctuation">,</span> <span class="token string">'a.onnx'</span><span class="token punctuation">)</span> 
</code></pre> 
<p>在导出 ONNX 的时候，会有很多的 warning，并且提示转出来的 onnx 很可能不正确。<br> 在这个模型里使用了.item()把 torch 中的张量转换成了普通的 Python 变量，还尝试遍历 torch 张量，并用一个列表新建一个 torch 张量。这些涉及张量与普通变量转换的逻辑都会导致最终的 ONNX 模型不太正确。<br> 另一方面，也可以利用这个性质，在保证正确性的前提下令模型的中间结果变成常量。这个技巧常常用于模型的静态化上。</p> 
<h4><a id="3_pytorch__onnx__164"></a>3 pytorch 对 onnx 算子的支持了解</h4> 
<p>在做 pytorch model 转换成 onnx model 的时候，PyTorch 一方面会用跟踪法执行前向推理，把遇到的算子整合成计算图；另一方面，PyTorch 还会把遇到的每个算子翻译成 ONNX 中定义的算子。 PyTorch 算子是向 ONNX 对齐的，这个过程中，可能会有这样的情况：</p> 
<ul><li>该算子可以一对一地翻译成一个 ONNX 算子。</li><li>该算子在 ONNX 中没有直接对应的算子，会翻译成一至多个 ONNX 算子。</li><li>该算子没有定义翻译成 ONNX 的规则，报错。</li></ul> 
<h5><a id="31_onnx__170"></a>3.1 onnx 算子文档</h5> 
<p>在<a href="https://github.com/onnx/onnx/blob/main/docs/Operators.md">onnx 官方算子文档</a>中可以查看 onnx 算子的定义情况。<br> 在算子文档中，第一列是算子名，第二列是该算子发生变动的算子集版本号，也就是前面在torch.onnx.export中提到的opset_version表示的算子集版本号。通过查看算子第一次发生变动的版本号，可以知道某个算子是从哪个版本开始支持的；通过查看某算子小于等于opset_version的第一个改动记录，可以知道当前算子集版本中该算子的定义规则。</p> 
<h5><a id="32_pytorch__onnx__174"></a>3.2 pytorch 对 onnx 算子的映射</h5> 
<p>在 PyTorch 中，和 ONNX 有关的定义全部放在<code>torch.onnx</code>目录中。<code>symbolic_opset{n}.py</code>（符号表文件）即表示 PyTorch 在支持第 n 版 ONNX 算子集时新加入的内容。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b9fc338be7b11bc2d6d28a464f5922cc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SQL数据库死锁语句查询结果</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/49010e64e6f190627307f3dc99ca72cf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">redis之分布式锁(四)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>