<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>卷积神经网络：LeNet网络手写数字识别代码实践 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="卷积神经网络：LeNet网络手写数字识别代码实践" />
<meta property="og:description" content="文章目录 LeNet-5详解及代码实现LeNet模型Lenet的pytorch实现搭建LeNet-5网络加载数据集训练网络自己手写的数字处理测试自己手写的数字完整代码 LeNet-5详解及代码实现 LeNet是在1998年LeCuu等人提出来的，用于解决手写数字识别的视觉任务，被认为是卷积神经网络的开创性工作，是卷积神经网络的祖师爷，是深度学习领域的里程碑，自那时起，CNN的最基本的架构就定下来了：卷积层、池化层、全连接层。论文地址：Gradient-Based Learning Applied to Document Recognition
LeNet模型 LeNet5网络包含了深度学习的基本模块：卷积层，池化层，全连接层。
LeNet5共有7层，不包含输入，每层都包含可训练参数；每个层有多个Feature Map，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有多个神经元。
论文中用的数据集输入大小为单通道，32×32大小的图片。
本次实践采用MNIST 数据集，可在 http://yann.lecun.com/exdb/mnist/ 获取，也可以通过pytorch代码。MNIST数据集输入大小为单通道，28×28大小的图片。因此实践中的LeNet，特征图大小与论文不一致，如下表所示。
操作论文的输出尺寸实践的输出尺寸input1, 32, 321, 28, 28）conv16, 28, 286, 24, 24）pool16, 14, 146, 12, 12）con16, 10, 1016, 8, 8）pool216, 5, 516, 4, 4fc1120120fc28484fc31010 Lenet的pytorch实现 实践加载的库
# 加载库 import torch import torch.nn as nn import torch.optim as optim import torchvision.datasets as datasets import torchvision.transforms as transforms import matplotlib.pyplot as plt from torchsummary import summary from PIL import Image 搭建LeNet-5网络 class LeNet5(nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/2f5dbc0abefc5c49582154f78e8f4c9c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-11T14:24:50+08:00" />
<meta property="article:modified_time" content="2023-07-11T14:24:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">卷积神经网络：LeNet网络手写数字识别代码实践</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#LeNet5_5" rel="nofollow">LeNet-5详解及代码实现</a></li><li><ul><li><a href="#LeNet_9" rel="nofollow">LeNet模型</a></li><li><a href="#Lenetpytorch_31" rel="nofollow">Lenet的pytorch实现</a></li><li><ul><li><a href="#LeNet5_47" rel="nofollow">搭建LeNet-5网络</a></li><li><a href="#_129" rel="nofollow">加载数据集</a></li><li><a href="#_139" rel="nofollow">训练网络</a></li><li><a href="#_199" rel="nofollow">自己手写的数字处理</a></li><li><a href="#_235" rel="nofollow">测试自己手写的数字</a></li><li><a href="#_298" rel="nofollow">完整代码</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="LeNet5_5"></a>LeNet-5详解及代码实现</h2> 
<p>LeNet是在<strong>1998年</strong>LeCuu等人提出来的，用于解决手写数字识别的视觉任务，被认为是卷积神经网络的开创性工作，是卷积神经网络的祖师爷，是深度学习领域的里程碑，自那时起，CNN的最基本的架构就定下来了：卷积层、池化层、全连接层。论文地址：<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=726791" rel="nofollow">Gradient-Based Learning Applied to Document Recognition</a></p> 
<h3><a id="LeNet_9"></a>LeNet模型</h3> 
<p>LeNet5网络包含了深度学习的基本模块：<strong>卷积层</strong>，<strong>池化层</strong>，<strong>全连接层</strong>。</p> 
<p>LeNet5共有7层，不包含输入，每层都包含可训练参数；每个层有多个Feature Map，每个FeatureMap通过一种卷积滤波器提取输入的一种特征，然后每个FeatureMap有多个神经元。<br> <img src="https://images2.imgbox.com/fd/96/iYllogWL_o.jpg" alt="在这里插入图片描述"></p> 
<p>论文中用的数据集输入大小为单通道，32×32大小的图片。</p> 
<p>本次实践采用MNIST 数据集，可在 <a href="https://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/mnist/" rel="nofollow">http://yann.lecun.com/exdb/mnist/</a> 获取，也可以通过pytorch代码。MNIST数据集输入大小为单通道，28×28大小的图片。因此实践中的LeNet，特征图大小与论文不一致，如下表所示。</p> 
<table><thead><tr><th align="left">操作</th><th align="left">论文的输出尺寸</th><th align="left">实践的输出尺寸</th></tr></thead><tbody><tr><td align="left">input</td><td align="left">1, 32, 32</td><td align="left">1, 28, 28）</td></tr><tr><td align="left">conv1</td><td align="left">6, 28, 28</td><td align="left">6, 24, 24）</td></tr><tr><td align="left">pool1</td><td align="left">6, 14, 14</td><td align="left">6, 12, 12）</td></tr><tr><td align="left">con</td><td align="left">16, 10, 10</td><td align="left">16, 8, 8）</td></tr><tr><td align="left">pool2</td><td align="left">16, 5, 5</td><td align="left">16, 4, 4</td></tr><tr><td align="left">fc1</td><td align="left">120</td><td align="left">120</td></tr><tr><td align="left">fc2</td><td align="left">84</td><td align="left">84</td></tr><tr><td align="left">fc3</td><td align="left">10</td><td align="left">10</td></tr></tbody></table> 
<h3><a id="Lenetpytorch_31"></a>Lenet的pytorch实现</h3> 
<p>实践加载的库</p> 
<pre><code class="prism language-python"><span class="token comment"># 加载库</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torchsummary <span class="token keyword">import</span> summary
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
</code></pre> 
<h4><a id="LeNet5_47"></a>搭建LeNet-5网络</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">LeNet5</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet5<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 卷积神经网络 # n.Sequential():一个序列容器，用于搭建神经网络的模块</span>
        <span class="token comment"># 调用forward()方法进行前向传播时，for循环按照顺序遍历nn.Sequential()中存储的网络模块</span>
        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># sigmoid()是论文中的激活函数，由于十几年后的计算机运算速度的加快，出现了更深的网络,</span>
            <span class="token comment"># sigmoid()激活函数引发了梯度消失和梯度爆炸，以及不同激活函数的优缺点与适用场景，出现了ReLu(),Leaky ReLU(),Tanh()等等激活函数</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 分类器</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># x = x.view(-1, 16 * 5 * 5)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre> 
<p><strong>展示网络</strong></p> 
<pre><code class="prism language-python">mol <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 没安装cuda报错,删除.cuda() 也错？ 是因为torchsummary.summary()的默认参数device='cuda'，删除后要改为device='cpu'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>mol<span class="token punctuation">)</span> <span class="token comment"># 打印网络</span>
summary<span class="token punctuation">(</span>mol<span class="token punctuation">,</span> input_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 默认参数device='cuda'。 device='cpu'</span>
</code></pre> 
<pre><code>LeNet5(
  (features): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
    (1): Sigmoid()
    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (4): Sigmoid()
    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)
  )
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=120, bias=True)
    (1): Linear(in_features=120, out_features=84, bias=True)
    (2): Linear(in_features=84, out_features=10, bias=True)
  )
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 24, 24]             156
           Sigmoid-2            [-1, 6, 24, 24]               0
         AvgPool2d-3            [-1, 6, 12, 12]               0
            Conv2d-4             [-1, 16, 8, 8]           2,416
           Sigmoid-5             [-1, 16, 8, 8]               0
         AvgPool2d-6             [-1, 16, 4, 4]               0
            Linear-7                  [-1, 120]          30,840
            Linear-8                   [-1, 84]          10,164
            Linear-9                   [-1, 10]             850
================================================================
Total params: 44,426
Trainable params: 44,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.08
Params size (MB): 0.17
Estimated Total Size (MB): 0.25
----------------------------------------------------------------
</code></pre> 
<h4><a id="_129"></a>加载数据集</h4> 
<p>使用pytorch进行学习时，可以使用pytorch的处理图像视频的torchvision工具集直接下载MNIST的训练和测试图片，torchvision包含了一些常用的数据集、模型和转换函数等等，比如图片分类、语义切分、目标识别、实例分割、关键点检测、视频分类等工具。<code>train=True</code>就是训练集，<code>train=False</code>不是训练集，即是测试集。若没下载设 <code>download=True</code></p> 
<pre><code class="prism language-python"><span class="token comment"># 加载MNIST数据集</span>
train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_139"></a>训练网络</h4> 
<pre><code class="prism language-python"><span class="token comment"># 定义模型、损失函数和优化器</span>
model <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9) # 其他优化器</span>
<span class="token comment"># 训练模型</span>
loss_<span class="token punctuation">,</span> accuracy_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch:[{}/{}]'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    total_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data  <span class="token comment"># 一个batch的数据</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零，初始化</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>  <span class="token comment"># 前向传播</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>  <span class="token comment"># 计算误差</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 权重更新</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 损失累加</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment"># 每100次迭代查看一次结果</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Iteration:[{}/{}], Loss: {:.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_loss<span class="token punctuation">)</span>
    <span class="token comment"># 测试模型</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        total <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy: {:.2f}%'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>
        accuracy_<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span>
  
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model.pth'</span><span class="token punctuation">)</span>  <span class="token comment"># 仅保存权重参数</span>

<span class="token comment"># 打印损失值 精度变化曲线</span>
fig<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax1<span class="token punctuation">,</span> ax2<span class="token punctuation">)</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss_<span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'total loss'</span><span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>accuracy_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accuracy_<span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'accuracy(%)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>10次epoch训练结果如下</p> 
<pre><code>Test Accuracy: 98.26%
</code></pre> 
<p><img src="https://images2.imgbox.com/ac/60/tLFkuH3o_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_199"></a>自己手写的数字处理</h4> 
<p><img src="https://images2.imgbox.com/cf/7e/7tzMgBaO_o.jpg" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c0/cb/X4KOckLs_o.jpg" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3e/3f/S6mnEXNI_o.jpg" alt="在这里插入图片描述"></p> 
<p>为什么”4“那么粗，因为前两个测试均错误，让我怀疑难道是写的太细了？后来加了个<code>transforms.Normalize(0.5, 0.5)</code>做数据归一化，细的数字才识别成功。我用微信拍照上传电脑，如上图，虽然裁剪了到图像依旧很大，几百×几百的像素，且是彩图，要依次做以下处理</p> 
<pre><code class="prism language-python"><span class="token comment"># 测试自己的手写数字</span>
five <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'7.jpg'</span><span class="token punctuation">)</span>
img_gray <span class="token operator">=</span> five<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>      <span class="token comment"># 容器 会按照顺序依次处理</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     <span class="token comment"># 手机拍的尺寸太大，无法放进网络，要缩放到28×28</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token comment"># 会把数据压缩，归一化到(0,1)</span>
    transforms<span class="token punctuation">.</span>RandomInvert<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># 训练集是黑底，白字，需要反相，把自己写的也变成黑底白数字，概率设为p=1</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 数据已经是(0,1),使用公式"(x-mean=0.5)/(std=0.5)"，将每个元素分布到(-1,1)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

img <span class="token operator">=</span> transform<span class="token punctuation">(</span>img_gray<span class="token punctuation">)</span>  <span class="token comment"># 数据处理，此时图片为[C, H, W]   </span>
img <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 在0位置展开一个维度为批次(batch)N，[N, C, H, W]</span>

<span class="token comment"># 看一看结果</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img_gray<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'before'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>  <span class="token comment"># imshow()只能显示二维的，此时img是四维的</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'after'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/c4/80/xwRF7USw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/23/d6/KvlOjd6Q_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e0/70/fh40rLgF_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_235"></a>测试自己手写的数字</h4> 
<p>没有设置随机种子，训练的结果，网络参数各不一样</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span>
weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span>   <span class="token comment"># 加载保存的参数</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  <span class="token comment"># 给网络模型按照文件weight，设置权重参数</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    re <span class="token operator">=</span> outputs<span class="token punctuation">.</span>data
    <span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">)</span>  <span class="token comment"># 输出结果</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    _<span class="token punctuation">,</span> predict <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 找到最大值的位置，即是识别结果</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'识别结果：'</span><span class="token punctuation">,</span> predict<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>最终结果</strong></p> 
<p><strong>7 输出</strong></p> 
<pre><code>tensor([[-14.5138,  14.1604,  10.1955,  -4.1804,   4.6772,  -1.3008, -16.3280,
          16.3169, -17.2751,   0.0612]])
torch.return_types.max(
values=tensor([16.3169]),
indices=tensor([7]))
tensor([7])
识别结果： 7
</code></pre> 
<p>tensor([7]) 是7 识别正确</p> 
<p><strong>5 输出</strong></p> 
<pre><code>tensor([[ -8.7777,   4.6533,  11.0276,  -2.3891,  -1.6845,   2.8539, -11.4988,
          10.2582, -11.5190,   0.3073]])
torch.return_types.max(
values=tensor([11.0276]),
indices=tensor([2]))
tensor([2])
识别结果： 2 
</code></pre> 
<p>tensor([2]) 是2 识别错误</p> 
<p><strong>4 输出</strong></p> 
<pre><code>tensor([[-10.5092,   0.3667,   2.4670,  -8.9335,  23.4923,  -8.2030,  -0.8113,
           8.0965, -12.7255,   2.3728]])
torch.return_types.max(
values=tensor([23.4923]),
indices=tensor([4]))
tensor([4])
识别结果： 4
</code></pre> 
<p>tensor([4]) 是4 识别正确</p> 
<h4><a id="_298"></a>完整代码</h4> 
<pre><code class="prism language-python"><span class="token comment"># 加载库</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> torchsummary <span class="token keyword">import</span> summary
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image


<span class="token comment"># 定义LeNet-5模型</span>
<span class="token keyword">class</span> <span class="token class-name">LeNet5</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LeNet5<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 卷积神经网络 # n.Sequential():一个序列容器，用于搭建神经网络的模块</span>
        <span class="token comment"># 调用forward()方法进行前向传播时，for循环按照顺序遍历nn.Sequential()中存储的网络模块</span>
        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># sigmoid()是论文中的激活函数，由于十几年后的计算机运算速度的加快，出现了更深的网络,</span>
            <span class="token comment"># sigmoid()激活函数引发了梯度消失和梯度爆炸，以及不同激活函数的优缺点与适用场景，出现了ReLu(),Leaky ReLU(),Tanh()等等激活函数</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 分类器</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># x = x.view(-1, 16 * 5 * 5)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


mol <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 没安装cuda报错,删除.cuda() 也错？ 是因为torchsummary.summary()的默认参数device='cuda'，删除后要改为device='cpu'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>mol<span class="token punctuation">)</span> <span class="token comment"># 打印网络</span>
summary<span class="token punctuation">(</span>mol<span class="token punctuation">,</span> input_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 默认参数device='cuda'。 device='cpu'</span>

<span class="token comment"># 加载MNIST数据集</span>
train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义数据加载器</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型、损失函数和优化器</span>
model <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_function <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9) # 其他优化器</span>
<span class="token comment"># 训练模型</span>
loss_<span class="token punctuation">,</span> accuracy_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch:[{}/{}]'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    total_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data  <span class="token comment"># 一个batch的数据</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零，初始化</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>  <span class="token comment"># 前向传播</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>  <span class="token comment"># 计算误差</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 权重更新</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 损失累加</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment"># 每100次迭代查看一次结果</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Iteration:[{}/{}], Loss: {:.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_loss<span class="token punctuation">)</span>
    <span class="token comment"># 测试模型</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        correct <span class="token operator">=</span> <span class="token number">0</span>
        total <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy: {:.2f}%'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>
        accuracy_<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span>

torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model.pth'</span><span class="token punctuation">)</span>  <span class="token comment"># 仅保存权重参数</span>

<span class="token comment"># 打印损失值 精度变化曲线</span>
fig<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax1<span class="token punctuation">,</span> ax2<span class="token punctuation">)</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loss_<span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'total loss'</span><span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>accuracy_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> accuracy_<span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
ax2<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'accuracy(%)'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token punctuation">)</span>
weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span>  <span class="token comment"># 加载保存的参数</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  <span class="token comment"># 给网络模型按照文件weight，设置权重参数</span>

<span class="token comment"># 测试自己的手写数字</span>
five <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'4.jpg'</span><span class="token punctuation">)</span>
img_gray <span class="token operator">=</span> five<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span>

transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token comment"># 容器 会按照顺序依次处理</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 手机拍的尺寸太大，无法放进网络，要缩放到28×28</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 会把数据压缩，归一化到(0,1)</span>
    transforms<span class="token punctuation">.</span>RandomInvert<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 训练集是黑底，白字，需要反相，把自己写的也变成黑底白数字，概率设为p=1</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 数据已经是(0,1),使用公式"(x-mean=0.5)/(std=0.5)"，将每个元素分布到(-1,1)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

img <span class="token operator">=</span> transform<span class="token punctuation">(</span>img_gray<span class="token punctuation">)</span>  <span class="token comment"># 数据处理，此时图片为[C, H, W]</span>
img <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 在0位置展开一个维度为批次(batch)N，[N, C, H, W]</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img_gray<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'before'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span>  <span class="token comment"># imshow()只能显示二维的，此时img是四维的</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'after'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    re <span class="token operator">=</span> outputs<span class="token punctuation">.</span>data
    <span class="token keyword">print</span><span class="token punctuation">(</span>re<span class="token punctuation">)</span>  <span class="token comment"># 输出结果</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    _<span class="token punctuation">,</span> predict <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 找到最大值的位置，即是识别结果</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>predict<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'识别结果：'</span><span class="token punctuation">,</span> predict<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4562d825adca5d930d9aa4a0f1840fb9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【leetcode刷题之路】剑指Offer（3）——搜索与回溯算法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eb87b3c4bd9461e2617cd6de41233e61/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">微信小程序背景渐变写法加占比以及微信小程序开发过程中长使用的代码段</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>