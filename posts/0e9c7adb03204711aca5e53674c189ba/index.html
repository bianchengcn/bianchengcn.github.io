<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>细讲sklearn决策树后剪枝(带例子) - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="细讲sklearn决策树后剪枝(带例子)" />
<meta property="og:description" content="《老饼讲解机器学习》https://www.bbbdata.com/ml/text/38
目录
一.CCP后剪枝简介
二.剪枝操作过程
(1) 查看CCP路径
(2)根据CCP路径剪树
为预防模型过拟合，我们可以采用预剪枝和后剪枝方法
1. 预剪枝:树构建过程，达到一定条件就停止生长
2. 后剪枝是等树完全构建后，再剪掉一些节点。
本文讲述后剪枝，预剪枝请参考《sklearn决策树预剪枝》
一.CCP后剪枝简介 后剪枝一般指的是CCP代价复杂度剪枝法（Cost Complexity Pruning），
即在树构建完成后，对树进行剪枝简化，使以下损失函数最小化:
：叶子节点个数
：所有样本个数
：第 i 个叶子节点上的样本数 ：第i个叶子节点的损失函数
α ：待定系数，用于惩罚节点个数，引导模型用更少的节点。
损失函数既考虑了代价，又考虑了树的复杂度，所以叫代价复杂度剪枝法，实质就是在树的复杂度与准确性之间取得一个平衡点。
备注：在sklearn中，如果criterion设为GINI,则是​﻿每个叶子节点的GINI系数，如果设为entropy，则是熵。
二.剪枝操作过程 具体操作过程如下：
(1) 查看CCP路径 ﻿计算CCP路径，查看alpha与树质量的关系：
构建好树后，我们可以通过clf.cost_complexity_pruning_path(X, y) 查看树的CCP路径：
# -*- coding: utf-8 -*- from sklearn.datasets import load_iris from sklearn import tree import numpy as np #----------------数据准备---------------------------- iris = load_iris() # 加载数据 X = iris.data y = iris.target #---------------模型训练--------------------------------- clf = tree.DecisionTreeClassifier(min_samples_split=10,ccp_alpha=0) clf = clf." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/0e9c7adb03204711aca5e53674c189ba/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-21T20:40:21+08:00" />
<meta property="article:modified_time" content="2024-01-21T20:40:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">细讲sklearn决策树后剪枝(带例子)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><a class="has-card" href="https://www.bbbdata.com/ml/text/38" rel="nofollow" title="《老饼讲解机器学习》"><span class="link-card-box"><span class="link-title">《老饼讲解机器学习》</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/0a/da/RzfPKuY2_o.png" alt="icon-default.png?t=N7T8">https://www.bbbdata.com/ml/text/38</span></span></a></p> 
<hr> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80.CCP%E5%90%8E%E5%89%AA%E6%9E%9D%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#%E4%B8%80.CCP%E5%90%8E%E5%89%AA%E6%9E%9D%E7%AE%80%E4%BB%8B" rel="nofollow">一.CCP后剪枝简介</a></p> 
<p id="%E4%BA%8C.%E5%89%AA%E6%9E%9D%E6%93%8D%E4%BD%9C%E8%BF%87%E7%A8%8B-toc" style="margin-left:0px;"><a href="#%E4%BA%8C.%E5%89%AA%E6%9E%9D%E6%93%8D%E4%BD%9C%E8%BF%87%E7%A8%8B" rel="nofollow">二.剪枝操作过程</a></p> 
<p id="(1)%C2%A0%E6%9F%A5%E7%9C%8BCCP%E8%B7%AF%E5%BE%84-toc" style="margin-left:40px;"><a href="#%281%29%C2%A0%E6%9F%A5%E7%9C%8BCCP%E8%B7%AF%E5%BE%84" rel="nofollow">(1) 查看CCP路径</a></p> 
<p id="(2)%E6%A0%B9%E6%8D%AECCP%E8%B7%AF%E5%BE%84%E5%89%AA%E6%A0%91-toc" style="margin-left:40px;"><a href="#%282%29%E6%A0%B9%E6%8D%AECCP%E8%B7%AF%E5%BE%84%E5%89%AA%E6%A0%91" rel="nofollow">(2)根据CCP路径剪树</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p><strong>为预防模型过拟合，我们可以采用预剪枝和后剪枝方法</strong><br> 1. 预剪枝:树构建过程，达到一定条件就停止生长<br> 2. 后剪枝是等树完全构建后，再剪掉一些节点。</p> 
<p><strong>本文讲述后剪枝</strong><strong>，预剪枝请参考《</strong><a href="https://www.bbbdata.com/ml/text/37" rel="nofollow" title="sklearn决策树预剪枝">sklearn决策树预剪枝</a><strong>》</strong></p> 
<h2 id="%E4%B8%80.CCP%E5%90%8E%E5%89%AA%E6%9E%9D%E7%AE%80%E4%BB%8B"><strong>一.CCP后剪枝简介</strong></h2> 
<p><strong>后剪枝一般指的是CCP代价复杂度剪枝法（Cost Complexity Pruning），<br> 即在树构建完成后，对树进行剪枝简化，使以下损失函数最小化:</strong></p> 
<p style="text-align:center;">  <img alt="L=\displaystyle \sum \limits _{i=1}^{T} \frac{N_i}{N} L_i +\alpha T" class="mathcode" src="https://images2.imgbox.com/eb/cf/xMMyxLQJ_o.png"></p> 
<p><img alt="T" class="mathcode" src="https://images2.imgbox.com/2d/29/8U14AqEr_o.png">  ：叶子节点个数<br><img alt="N" class="mathcode" src="https://images2.imgbox.com/40/38/1erxGnAq_o.png"> ：所有样本个数<br><img alt="N_{i}" class="mathcode" src="https://images2.imgbox.com/5b/0e/eBcSjMJ5_o.png"> ：第 i 个叶子节点上的样本数 <br><img alt="L_{i}" class="mathcode" src="https://images2.imgbox.com/5a/f5/j6EMRwUm_o.png"> ：第i个叶子节点的损失函数<br> α   ：待定系数，用于惩罚节点个数，引导模型用更少的节点。</p> 
<p>损失函数既考虑了代价，又考虑了树的复杂度，所以叫代价复杂度剪枝法，实质就是在树的复杂度与准确性之间取得一个平衡点。</p> 
<p><strong>备注：在sklearn中，如果criterion设为GINI,则是<img alt="L_i" class="mathcode" src="https://images2.imgbox.com/76/2c/Ql3yuW39_o.png">​﻿每个叶子节点的GINI系数，如果设为entropy，则是熵。</strong></p> 
<p></p> 
<h2 id="%E4%BA%8C.%E5%89%AA%E6%9E%9D%E6%93%8D%E4%BD%9C%E8%BF%87%E7%A8%8B"><strong>二.剪枝操作过程</strong></h2> 
<p>具体操作过程如下：</p> 
<h3 id="(1)%C2%A0%E6%9F%A5%E7%9C%8BCCP%E8%B7%AF%E5%BE%84"><strong>(1) 查看CCP路径</strong></h3> 
<p><strong>﻿计算CCP路径，查看alpha与树质量的关系：</strong><br> 构建好树后，我们可以通过clf.cost_complexity_pruning_path(X, y) 查看树的CCP路径：</p> 
<pre><code># -*- coding: utf-8 -*-
from sklearn.datasets import load_iris
from sklearn import tree
import numpy as np
#----------------数据准备----------------------------
iris = load_iris()                          # 加载数据
X = iris.data
y = iris.target
#---------------模型训练---------------------------------
clf = tree.DecisionTreeClassifier(min_samples_split=10,ccp_alpha=0)        
clf = clf.fit(X, y)     
#-------计算ccp路径-----------------------
pruning_path = clf.cost_complexity_pruning_path(X, y)
#-------打印结果---------------------------    
print("\n====CCP路径=================")
print("ccp_alphas:",pruning_path['ccp_alphas'])
print("impurities:",pruning_path['impurities'])</code></pre> 
<p><strong>运行结果：</strong></p> 
<pre><code>====sklearn的CCP路径=================
ccp_alphas: [0.      0.00415459 0.01305556 0.02966049 0.25979603 0.33333333]
impurities: [0.02666667 0.03082126 0.04387681 0.07353731 0.33333333 0.66666667]</code></pre> 
<p><strong>它的意思是:</strong><br> 0&lt;﻿\alphaα﻿ &lt;0.00415时，树的不纯度为 0.02666，<br> 0.00415&lt;﻿\alphaα﻿ &lt;0.01305时，树的不纯度为 0.03082，<br> 0.01305&lt;﻿\alphaα﻿ &lt;0.02966时，树的不纯度为 0.04387，<br> ........<br> 小贴士：ccp_path只提供树的不纯度，如果还需要alpha对应的其它信息，则可以将alpha代入模型中训练，从训练好的模型中获取。</p> 
<p>备注：树的不纯度指的是损失函数的前部分<img alt="L=\displaystyle \sum \limits _{i=1}^{T} \frac{N_i}{N} L_i" class="mathcode" src="https://images2.imgbox.com/b3/fe/96r19Ncc_o.png">， 也即所有叶子的不纯度（gini或者熵）加权和。</p> 
<h3 id="(2)%E6%A0%B9%E6%8D%AECCP%E8%B7%AF%E5%BE%84%E5%89%AA%E6%A0%91"><strong>(2)根据CCP路径剪树 </strong></h3> 
<p><strong>根据树的质量，选定alpha进行剪树</strong><br> 我们选择一个可以接受的树不纯度，找到对应的alpha,例如，我们可接受的树不纯度为0.0735，则alpha可设为0.1(在0.02966与0.25979之间）<br> 对模型重新以参数ccp_alpha=0.1进行训练，即可得到剪枝后的决策树。</p> 
<p><strong>完整代码如下：</strong></p> 
<pre><code> # -*- coding: utf-8 -*-
from sklearn.datasets import load_iris
from sklearn import tree
import numpy as np

#--------数据准备-----------------------------------
iris = load_iris()                          # 加载数据
X = iris.data
y = iris.target
#-------模型训练---------------------------------
clf = tree.DecisionTreeClassifier(min_samples_split=10,random_state=0,ccp_alpha=0)        
clf = clf.fit(X, y)     
#-------计算ccp路径------------------------------
pruning_path = clf.cost_complexity_pruning_path(X, y)

#-------打印结果---------------------------------   
print("\n====CCP路径=================")
print("ccp_alphas:",pruning_path['ccp_alphas'])
print("impurities:",pruning_path['impurities'])    

#------设置alpha对树后剪枝-----------------------
clf = tree.DecisionTreeClassifier(min_samples_split=10,random_state=0,ccp_alpha=0.1)        
clf = clf.fit(X, y) 
#------自行计算树纯度以验证-----------------------
is_leaf =clf.tree_.children_left ==-1
tree_impurities = (clf.tree_.impurity[is_leaf]* clf.tree_.n_node_samples[is_leaf]/len(y)).sum()
#-------打印结果--------------------------- 
print("\n==设置alpha=0.1剪枝后的树纯度：=========\n",tree_impurities)</code></pre> 
<p><strong>运行结果：</strong></p> 
<pre><code>====CCP路径=================
ccp_alphas: [0.      0.00415459 0.01305556 0.02966049 0.25979603 0.33333333]
impurities: [0.02666667 0.03082126 0.04387681 0.07353731 0.33333333 0.66666667]

==设置alpha=0.1剪枝后的树纯度：=========
 0.0735373054213634</code></pre> 
<p>对于CCP路径的计算过程，可参考：</p> 
<p>1.《<a href="https://www.bbbdata.com/ml/text/87" rel="nofollow" title="决策树后剪枝原理：CCP剪枝法">决策树后剪枝原理：CCP剪枝法</a>》</p> 
<p id="%E4%B8%89.%E6%8C%81%E4%B9%85%E5%8C%96%E8%B0%83%E7%94%A8"><span style="color:#fe2c24;"><strong>相关文章</strong></span></p> 
<p>《<a href="https://www.bbbdata.com/ml/text/32" rel="nofollow" title="一个简单的决策树分类例子">一个简单的决策树分类例子</a>》</p> 
<p>《<a href="https://www.bbbdata.com/ml/text/33" rel="nofollow" title="sklearn决策树结果可视化">sklearn决策树结果可视化</a>》</p> 
<p>《<a href="https://www.bbbdata.com/ml/text/34" rel="nofollow" title="sklearn决策树参数详解">sklearn决策树参数详解</a>》</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2f0b071fb3f4bb6bf480d980a5e05f5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">一文讲清神经网络、BP神经网络、深度学习的关系</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/23a5a011a6012944999f17fdfb533860/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">决策树建模完整流程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>