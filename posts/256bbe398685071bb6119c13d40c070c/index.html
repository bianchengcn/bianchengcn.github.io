<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Tortoise-tts Better speech synthesis through scaling——TTS论文阅读 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Tortoise-tts Better speech synthesis through scaling——TTS论文阅读" />
<meta property="og:description" content="笔记地址：https://flowus.cn/share/a79f6286-b48f-42be-8425-2b5d0880c648
【FlowUs 息流】tortoise
论文地址：
Better speech synthesis through scaling
Abstract: 自回归变换器和DDPM：自回归变换器（autoregressive transformers）是一种基于变换器架构的模型，能够处理序列数据，例如图像的像素。DDPM（深度概率模型，Deep Diffusion Probabilistic Models）是一种基于深度学习的概率模型，用于生成高质量的图像。 自回归变换器和DDPM被广泛应用于图像生成，它们利用大量的计算资源和数据来学习图像的分布，这意味着模型通过分析和学习大量图像数据来理解和复现图像的概率分布。
技术迁移：该方法论不仅限于图像生成，还可以应用于其他领域，如语音合成。
TorToise系统：这篇论文描述了一种将图像生成领域的进步应用于语音合成的方法。其结果是TorToise，这是一个富有表现力的多声音文本到语音合成系统。
所有的模型代码和训练好的权重都已在GitHub上开源，网址为：
GitHub - neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality
1.Background 1.1Text-to-speech 文本到语音研究领域主要集中于开发高效的模型，这些模型通常基于相对较小的数据集进行训练。这种选择主要受以下因素的驱动：
高效模型的需求：为了能够大规模部署，需要构建高效的语音生成模型，这些模型必须具有高采样率。
大型转录语音数据集的缺乏：很难获得大型、经过转录的语音数据集。
扩展传统TTS中使用的编解码器模型架构的挑战：传统的TTS技术在扩展时面临许多挑战。
1.1.1Neural MEL Invertes 神经MEL反转器，就是vocoder，声码器
MEL频谱编码：大多数现代文本到语音系统操作的是编码为MEL频谱的语音数据。MEL编码的一个主要优点是它高度空间压缩，意味着它可以在保留大部分信息的同时大幅度减小数据大小。例如，Tacotron使用的MEL配置相对于以22kHz采样的原始音频波形数据实现了256倍的压缩。
MEL频谱解码研究：由于MEL频谱的这些特性，一个专门的研究领域致力于找到高质量的方法，将MEL频谱再转换回音频波形。执行这一任务的合成器通常称为“声码器”，但在这篇论文中，作者更普遍地将其称为“MEL反转器”。
基于神经网络的MEL反转器：现代基于神经网络的MEL反转器非常复杂，它们产生的波形几乎与人类耳朵听到的录音波形无法区分，并且在训练集之外具有很高的泛化能力。作者利用这些研究成果，使用了Univnet(Kim, 2021)的实现作为其文本到语音系统的最终阶段。
1.2Image generation 与TTS系统主要关注延迟不同，图像生成领域更多地关注于训练能生成高质量结果的模型，而不太关心采样时间的长短。
1.2.1DALL-E 自回归解码器在图像生成中的应用：DALL-E（Ramesh等人，2021年）展示了如何将自回归解码器应用于文本到图像的生成。这一点特别吸引人，因为在NLP领域，已经有大量研究专注于扩展仅解码器模型。
DALL-E的问题：首先，DALL-E依赖于全序列自注意力，这带来了O(N²)的计算和存储成本，其中N是序列长度。其次，传统的自回归方法需要在离散域中操作。DALL-E使用量化自编码器将图像编码成离散的标记序列，然后使用自回归先验模型来模拟这些标记序列。这在表现力方面是DALL-E的一个优势，但它需要一个解码器将这些图像标记转换回实际组成图像的像素值。
1.2.2DDPMs 解决模糊性和模式崩溃问题：DDPM（Ho等人，2020年）最近作为一种能够产生清晰、连贯和多样化图像的生成模型而出现。这些模型非常有效地使用低质量的引导信号来重建这些信号来源的高维空间。换句话说，它们在超分辨率方面表现出色。
DDPM的局限性：传统的DDPM方法依赖于在采样开始前已知的固定输出形状。此外，DDPM的采样过程需要多次迭代，并且消耗大量计算资源，意味着总是会有显著的延迟成本。
1.2.3Re-ranking 自回归模型的输出过程：DALL-E引入了“重新排序”自回归模型输出的过程。这一过程从自回归模型中随机采样，并从k个输出中挑选最高质量的输出用于下游应用。
强大的鉴别器的需求：这种方法需要一个强大的鉴别器，即能够区分好的和不好的文本/图像配对的模型。DALL-E使用了CLIP（Radford等人，2021年），这是一个以对比文本和图像配对目标进行训练的模型。
2.Method 2.1Joining Autoregressive Decoders and DDPMs 将自回归解码器和DDPM结合起来
首先回顾一下二者的优势：
自回归模型的优势：
自回归模型擅长在视觉、文本和语音等未对齐的领域之间进行转换。它们通过将输入数据（如文本）转换成一系列的输出标记（如图像或语音的代表性标记）来工作。 DDPM的优势：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/256bbe398685071bb6119c13d40c070c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-26T15:40:25+08:00" />
<meta property="article:modified_time" content="2024-01-26T15:40:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Tortoise-tts Better speech synthesis through scaling——TTS论文阅读</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong><a name="Xae9004ccb5d3155c82d1a4c54dc2ae1b354e1bc"></a><strong><strong>笔记地址：https://flowus.cn/share/a79f6286-b48f-42be-8425-2b5d0880c648<br> 【FlowUs 息流】tortoise</strong></strong></strong></p> 
<p>论文地址：</p> 
<p><a href="https://arxiv.org/abs/2305.07243" rel="nofollow" title="Better speech synthesis through scaling">Better speech synthesis through scaling</a></p> 
<h3><span style="color:#4f81bd;"><strong><a name="abstract"></a><strong><span style="color:#4f81bd;"><strong>Abstract:</strong></span></strong></strong></span></h3> 
<p><strong><strong>自回归变换器和DDPM</strong></strong>：自回归变换器（autoregressive transformers）是一种基于变换器架构的模型，能够处理序列数据，例如图像的像素。DDPM（深度概率模型，Deep Diffusion Probabilistic Models）是一种基于深度学习的概率模型，用于生成高质量的图像。 自回归变换器和DDPM被广泛应用于图像生成，它们利用大量的计算资源和数据来学习图像的分布，这意味着模型通过分析和学习大量图像数据来理解和复现图像的概率分布。</p> 
<p><strong><strong>技术迁移</strong></strong>：该方法论不仅限于图像生成，还可以应用于其他领域，如语音合成。</p> 
<p><strong><strong>TorToise系统</strong></strong>：这篇论文描述了一种将图像生成领域的进步应用于语音合成的方法。其结果是TorToise，这是一个富有表现力的多声音文本到语音合成系统。</p> 
<p>所有的模型代码和训练好的权重都已在GitHub上开源，网址为：</p> 
<p><a href="https://github.com/neonbjb/tortoise-tts" title="GitHub - neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality">GitHub - neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality</a></p> 
<h3><span style="color:#4f81bd;"><strong><a name="background"></a><strong><span style="color:#4f81bd;"><strong>1.Background</strong></span></strong></strong></span></h3> 
<h4><span style="color:#4f81bd;"><strong><a name="text-to-speech"></a><strong><span style="color:#4f81bd;"><strong>1.1Text-to-speech</strong></span></strong></strong></span></h4> 
<p>文本到语音研究领域主要集中于开发高效的模型，这些模型通常基于相对较小的数据集进行训练。这种选择主要受以下因素的驱动：</p> 
<p><strong><strong>高效模型的需求</strong></strong>：为了能够大规模部署，需要构建高效的语音生成模型，这些模型必须具有高采样率。</p> 
<p><strong><strong>大型转录语音数据集的缺乏</strong></strong>：很难获得大型、经过转录的语音数据集。</p> 
<p><strong><strong>扩展传统TTS中使用的编解码器模型架构的挑战</strong></strong>：传统的TTS技术在扩展时面临许多挑战。</p> 
<h5><span style="color:#4f81bd;"><a name="neural-mel-invertes"></a><em><span style="color:#4f81bd;">1.1.1Neural MEL Invertes</span></em></span></h5> 
<p>神经MEL反转器，就是vocoder，声码器</p> 
<p><strong><strong>MEL频谱编码</strong></strong>：大多数现代文本到语音系统操作的是编码为MEL频谱的语音数据。MEL编码的一个主要优点是它高度空间压缩，意味着它可以在保留大部分信息的同时大幅度减小数据大小。例如，Tacotron使用的MEL配置相对于以22kHz采样的原始音频波形数据实现了256倍的压缩。</p> 
<p><strong><strong>MEL频谱解码研究</strong></strong>：由于MEL频谱的这些特性，一个专门的研究领域致力于找到高质量的方法，将MEL频谱再转换回音频波形。执行这一任务的合成器通常称为“声码器”，但在这篇论文中，作者更普遍地将其称为“MEL反转器”。</p> 
<p><strong><strong>基于神经网络的MEL反转器</strong></strong>：现代基于神经网络的MEL反转器非常复杂，它们产生的波形几乎与人类耳朵听到的录音波形无法区分，并且在训练集之外具有很高的泛化能力。作者利用这些研究成果，使用了Univnet(Kim, 2021)的实现作为其文本到语音系统的最终阶段。</p> 
<h4><span style="color:#4f81bd;"><strong><a name="image-generation"></a><strong><span style="color:#4f81bd;"><strong>1.2Image generation</strong></span></strong></strong></span></h4> 
<p>与TTS系统主要关注延迟不同，图像生成领域更多地关注于训练能生成高质量结果的模型，而不太关心采样时间的长短。</p> 
<h5><span style="color:#4f81bd;"><a name="dall-e"></a><em><span style="color:#4f81bd;">1.2.1DALL-E</span></em></span></h5> 
<p><strong><strong>自回归解码器在图像生成中的应用</strong></strong>：DALL-E（Ramesh等人，2021年）展示了如何将自回归解码器应用于文本到图像的生成。这一点特别吸引人，因为在NLP领域，已经有大量研究专注于扩展仅解码器模型。</p> 
<p><strong><strong>DALL-E的问题</strong></strong>：首先，DALL-E依赖于全序列自注意力，这带来了O(N²)的计算和存储成本，其中N是序列长度。其次，传统的自回归方法需要在离散域中操作。DALL-E使用量化自编码器将图像编码成离散的标记序列，然后使用自回归先验模型来模拟这些标记序列。这在表现力方面是DALL-E的一个优势，但它需要一个解码器将这些图像标记转换回实际组成图像的像素值。</p> 
<h5><span style="color:#4f81bd;"><a name="ddpms"></a><em><span style="color:#4f81bd;">1.2.2DDPMs</span></em></span></h5> 
<p><strong><strong>解决模糊性和模式崩溃问题</strong></strong>：DDPM（Ho等人，2020年）最近作为一种能够产生清晰、连贯和多样化图像的生成模型而出现。这些模型非常有效地使用低质量的引导信号来重建这些信号来源的高维空间。换句话说，它们在超分辨率方面表现出色。</p> 
<p><strong><strong>DDPM的局限性</strong></strong>：传统的DDPM方法依赖于在采样开始前已知的固定输出形状。此外，DDPM的采样过程需要多次迭代，并且消耗大量计算资源，意味着总是会有显著的延迟成本。</p> 
<h5><span style="color:#4f81bd;"><a name="re-ranking"></a><em><span style="color:#4f81bd;">1.2.3Re-ranking</span></em></span></h5> 
<p><strong><strong>自回归模型的输出过程</strong></strong>：DALL-E引入了“重新排序”自回归模型输出的过程。这一过程从自回归模型中随机采样，并从k个输出中挑选最高质量的输出用于下游应用。</p> 
<p><strong><strong>强大的鉴别器的需求</strong></strong>：这种方法需要一个强大的鉴别器，即能够区分好的和不好的文本/图像配对的模型。DALL-E使用了CLIP（Radford等人，2021年），这是一个以对比文本和图像配对目标进行训练的模型。</p> 
<h3><span style="color:#4f81bd;"><strong><a name="method"></a><strong><span style="color:#4f81bd;"><strong>2.Method</strong></span></strong></strong></span></h3> 
<h4><span style="color:#4f81bd;"><strong><a name="X12e58798cc07d8a0c6b019cd5369c6592aed809"></a><strong><span style="color:#4f81bd;"><strong>2.1Joining Autoregressive Decoders and DDPMs</strong></span></strong></strong></span></h4> 
<p><img alt="" height="373" src="https://images2.imgbox.com/e1/23/REhTUN4r_o.png" width="700"></p> 
<p>将自回归解码器和DDPM结合起来</p> 
<p>首先回顾一下二者的优势：</p> 
<p>自回归模型的优势：</p> 
<ul><li>自回归模型擅长在视觉、文本和语音等未<strong><strong>对齐的领域之间进行转换</strong></strong>。</li><li>它们通过将输入数据（如文本）转换成一系列的输出标记（如图像或语音的代表性标记）来工作。</li></ul> 
<p>DDPM的优势：</p> 
<ul><li>DDPM在连续域中操作，使它们能够模拟表达性模态，如图像或语音的细微变化。</li><li>DDPMs<strong><strong>通过处理这些输出标记，将它们转换成高质量的连续数据表示</strong></strong>，例如语音谱图或图像。</li></ul> 
<p>结合二者优两种模型类型都已经展示了随着计算和数据的增加而提升性能的能力。当面对像生成语音谱图或图像这样的连续数据问题时，结合这两种方法可能会带来独特的优势。</p> 
<ul><li>在推理过程中，首先使用自回归模型将一系列文本标记转换成代表输出空间的一系列标记（在这个案例中是语音标记）。</li><li>然后，使用DDPM将这些标记解码成高质量的语音表示。</li></ul> 
<h4><span style="color:#4f81bd;"><strong><a name="applying-autoregressionddpms-to-tts"></a><strong><span style="color:#4f81bd;"><strong>2.2Applying Autoregression+DDPMs to TTS</strong></span></strong></strong></span></h4> 
<p>为了构建之前提出的系统，需要训练以下几种神经网络：</p> 
<p><strong><strong>自回归解码器</strong></strong>：</p> 
<ul><li>预测基于文本的语音标记的概率分布。</li><li>这个解码器将文本转换成一系列代表语音的标记。</li></ul> 
<p><strong><strong>对比模型（类似于CLIP）</strong></strong>：</p> 
<ul><li>用于对自回归解码器的输出进行排序。</li><li>类似于CLIP的模型，用于评估和选择最佳的生成输出。</li></ul> 
<p><strong><strong>DDPM</strong></strong>：</p> 
<ul><li>将语音标记转换回语音谱图。</li><li>这一步骤负责将标记转化为可以听到的语音。</li></ul> 
<h5><span style="color:#4f81bd;"><a name="conditinoing-input"></a><em><span style="color:#4f81bd;">2.2.1Conditinoing Input</span></em></span></h5> 
<ul><li><strong><strong>TorToise的独特设计选择</strong></strong>：一个额外的输入被提供给自回归生成器和DDPM，被称为语音条件输入。</li><li><strong><strong>语音条件输入的处理</strong></strong>：从一个或多个与目标相同说话者的音频剪辑开始，这些剪辑被转换为MEL谱图，并通过一个由自注意力层组成的编码器进行处理。</li><li><strong><strong>编码器的输出</strong></strong>：这些层的输出被平均以产生单个向量。所有编码的条件剪辑的向量然后再次被平均，然后作为输入传递给自回归或条件网络。</li></ul> 
<h5><span style="color:#4f81bd;"><a name="the-tortoise-trick"></a><em><span style="color:#4f81bd;">2.2.2 The “TorToise Trick”</span></em></span></h5> 
<ul><li><strong><strong>训练过程</strong></strong>：在大部分训练过程中，DDPM被训练为将离散的语音代码转换成MEL谱图。在这一过程收敛后，对DDPM进行微调，使其基于从自回归模型输出中提取的潜在空间，而不是语音代码。</li><li><strong><strong>逻辑</strong></strong>：自回归潜在空间比离散标记在语义上更丰富。通过在这个潜在空间上进行微调，可以提高下游扩散模型的效率。这种微调是提高模型输出质量的最大贡献者之一。</li></ul> 
<h4><span style="color:#4f81bd;"><strong><a name="clvp"></a><strong><span style="color:#4f81bd;"><strong>2.3CLVP</strong></span></strong></strong></span></h4> 
<ul><li><strong><strong>重新排序的策略</strong></strong>：正如之前提到的，从生成模型中获取表达性输出的一个好策略是使用定性鉴别器重新排序多个输出，然后只选择最佳的。DALL-E使用CLIP来实现这一点。</li><li><strong><strong>CLVP的应用</strong></strong>：用于CLIP的这种方法同样可以应用于语音：大多数TTS数据集只是音频剪辑和文本的配对。通过在对比设置中对这些配对进行模型训练，模型成为了语音的有效鉴别器。</li><li><strong><strong>TorToise中的CLVP</strong></strong>：训练了Contrastive Language-Voice Pretrained Transformer（CLVP）。它具有CLIP的许多相同属性，但显著地用作在重新排序TTS输出中的评分模型。</li><li><strong><strong>高效推理</strong></strong>：为了在推理中高效运作，CLVP被训练为将离散的语音标记与文本标记配对，这样CLVP可以在不调用昂贵的扩散模型的情况下重新排序多个自回归输出。</li></ul> 
<h3><span style="color:#4f81bd;"><strong><a name="training"></a><strong><span style="color:#4f81bd;"><strong>3.Training</strong></span></strong></strong></span></h3> 
<ul><li><strong><strong>训练环境</strong></strong>：这些模型在8台NVIDIA RTX-3090显卡组成的小型集群上训练了一年时间。（一年...突然理解了为什么叫tortoise）<img alt="" height="248" src="https://images2.imgbox.com/86/41/5b7FTYuF_o.png" width="1078"></li><li><strong><strong>训练细节</strong></strong>：关于这些模型的具体训练方法可以在论文文档的附录B中找到。</li></ul> 
<h3><span style="color:#4f81bd;"><strong><a name="inference-process"></a><strong><span style="color:#4f81bd;"><strong>4.Inference Process</strong></span></strong></strong></span></h3> 
<p>一旦框架的四个模型全部训练完成，推理过程如下：</p> 
<p><strong><strong>输入条件和文本</strong></strong>：将条件输入和文本输入到自回归模型，并解码出大量的输出候选项。</p> 
<p><strong><strong>使用CLVP评分</strong></strong>：使用CLVP为每个语音候选项和文本之间的相关性打分。</p> 
<p><strong><strong>选择顶级候选项</strong></strong>：选择排名最高的k个语音候选项，然后对每个候选项：</p> 
<p><strong><strong>使用DDPM解码</strong></strong>：使用DDPM解码成MEL谱图。</p> 
<p><strong><strong>转换为波形</strong></strong>：使用传统的声码器将其转换为波形。</p> 
<p><strong><strong>自回归模型解码设置</strong></strong>：在解码自回归模型时，使用核采样（nucleus sampling），设置P=0.8，重复惩罚=2，Softmax温度=0.8。</p> 
<ul><li><strong><strong>DDPMs采样</strong></strong>：采样自DDPMs是一个高度研究且快速变化的领域。在TorToise设计时，发现最佳平衡质量和推理速度的采样配置如下：</li></ul> 
<p>算法：DDIM（Song等人，2022年）</p> 
<p>调度：线性</p> 
<p>采样步骤：64</p> 
<p>无条件引导常数：2</p> 
<h3><span style="color:#4f81bd;"><strong><a name="the-dataset"></a><strong><span style="color:#4f81bd;"><strong>5.The Dataset</strong></span></strong></strong></span></h3> 
<ul><li><strong><strong>数据需求</strong></strong>：由于目标是训练一个大型语言模型，因此需要大量数据。</li><li><strong><strong>初始数据集</strong></strong>：开始使用的是LibriTTS（Zen等人，2019年）和HiFiTTS（Bakhturina等人，2021年）数据集，这两个数据集合计包含896小时的转录语音。</li><li><strong><strong>扩展数据集</strong></strong>：构建了一个额外的“扩展”数据集，包含从互联网上抓取的有声书和播客的49,000小时语音音频。关于这个数据集是如何构建的细节在附录I中。</li><li><strong><strong>验证用数据集</strong></strong>：使用官方的LibriTTS测试分割作为验证目的。</li></ul> 
<h3><span style="color:#4f81bd;"><strong><a name="experiments"></a><strong><span style="color:#4f81bd;"><strong>6.Experiments</strong></span></strong></strong></span></h3> 
<ul><li><strong><strong>TTS系统的比较挑战</strong></strong>：由于许多最先进的TTS系统是闭源的，且可比较样本较少，因此实验性比较TTS系统具有挑战性。</li><li><strong><strong>评估套件</strong></strong>：为此，作者构建了自己的评估套件，使用CLVP生成实际样本和生成样本之间的距离度量，类似于用于图像的FID分数。</li><li><strong><strong>“可理解性”度量</strong></strong>：此外，还使用开源的wav2vec模型来表征语音片段的“可理解性”。</li><li><strong><strong>开源工作</strong></strong>：作者已将这些工作开源。</li><li><strong><strong>TorToise样本与其他论文样本的比较</strong></strong>：可以在提供的链接中找到TorToise生成的样本与其他论文生成的样本之间的比较。</li></ul> 
<h3><span style="color:#4f81bd;"><strong><a name="conclusion"></a><strong><span style="color:#4f81bd;"><strong>7.Conclusion</strong></span></strong></strong></span></h3> 
<ul><li><strong><strong>TorToise的地位</strong></strong>：TorToise是最近使用通用模型架构的一系列最新突破性成果中的最新成果之一。</li><li><strong><strong>对音频处理的应用</strong></strong>：尽管TorToise几乎没有专门为音频处理设计的部分，但它在真实感方面超越了所有以前的TTS模型。</li><li><strong><strong>成功因素</strong></strong>：TorToise的成功归因于以下几点：</li></ul> 
<p><strong><strong>采用通用架构</strong></strong>：比如变换器层堆栈。</p> 
<p><strong><strong>利用大型高质量数据集</strong></strong>。</p> 
<p><strong><strong>在较大规模和高批量大小下训练</strong></strong>。</p> 
<ul><li><strong><strong>项目的主要启示</strong></strong>：作者从这个项目中主要认识到，遵循上述三点可以获得非常强大的结果。作者认为，任何数字化的模态都可能适用于使用这个框架的生成建模。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/90082fcbf9d721477194be16ce2a540c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">解决el-steps切换时el-form的动态表单报错Error: please transfer a valid prop path to form item</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/042d4ec9c3d8d0f14d83f1b3731f5cb2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Git】Git配置 — 首次clone失败，出现报错：authenticity can‘t be established</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>