<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>海思 YOLOv5 pytorch 转 onnx 转 Caffe 再转 wk 的转化详解 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="海思 YOLOv5 pytorch 转 onnx 转 Caffe 再转 wk 的转化详解" />
<meta property="og:description" content="目录： 前沿 YOLOv5模型的选取与修改 YOLOv5 pytorch 转 onnx 转 Caffe YOLOv5 Caffe转wk文件 总结 参考 前沿 作者在将YOLOv5 pytorch版本转成wk文件中碰到了很多的坑，但在研究中也收获了很多知识，针对转化过程，作者进行了详细的解读来给大家避坑，如果在转化过程中有什么问题也可以联系作者，我们可以一起进行分析和讨论。
YOLOv5模型的选取与修改 现如今，官方最新版本的YOLOv5是6.0以上的版本，而6.0版本相比于6.0以下版本（不包含6.0）发生了不少的变化，其中最为突出的改动是将force层修改为成步长为2，卷积为 2 x 2的Conv层 （GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite）。
YOLOv5 5.0和6.0以YOLOv5s.yaml为例
# yolov5s.yaml YOLOv5 5.0版本 # parameters nc: 10 # number of classes depth_multiple: 0.33 # model depth multiple width_multiple: 0.50 # layer channel multiple # anchors anchors: - [10,13, 16,30, 33,23] # P3/8 - [30,61, 62,45, 59,119] # P4/16 - [116,90, 156,198, 373,326] # P5/32 # YOLOv5 backbone backbone: # [from, number, module, args] [[-1, 1, Focus, [64, 3]], # 这块部分 0-P1/2 [-1, 1, Conv, [128, 3, 2]], # 1-P2/4 [-1, 3, C3, [128]], [-1, 1, Conv, [256, 3, 2]], # 3-P3/8 [-1, 9, C3, [256]], [-1, 1, Conv, [512, 3, 2]], # 5-P4/16 [-1, 9, C3, [512]], [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32 [-1, 1, SPP, [1024, [5, 9, 13]]], [-1, 3, C3, [1024, False]], # 9 ] # YOLOv5 head head: [[-1, 1, Conv, [512, 1, 1]], [-1, 1, nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/f3b4e502a81641c9cd19b9db15696b75/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-14T15:50:50+08:00" />
<meta property="article:modified_time" content="2022-07-14T15:50:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">海思 YOLOv5 pytorch 转 onnx 转 Caffe 再转 wk 的转化详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E7%9B%AE%E5%BD%95%EF%BC%9A"></h2> 
<h2 id="main-toc"><strong>目录</strong>：</h2> 
<h3 id="%E5%89%8D%E6%B2%BF-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E6%B2%BF" rel="nofollow">        </a><a href="#%E5%89%8D%E6%B2%BF" rel="nofollow">前沿</a></h3> 
<h3 id="YOLOv5%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E5%8F%96%E4%B8%8E%E4%BF%AE%E6%94%B9-toc" style="margin-left:0px;"><a href="#YOLOv5%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E5%8F%96%E4%B8%8E%E4%BF%AE%E6%94%B9" rel="nofollow">        </a><a href="#YOLOv5%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E5%8F%96%E4%B8%8E%E4%BF%AE%E6%94%B9" rel="nofollow">YOLOv5模型的选取与修改</a></h3> 
<h3 id="YOLOv5%20pytorch%20%E8%BD%AC%20onnx%20%E8%BD%AC%20Caffe-toc" style="margin-left:0px;"><a href="#YOLOv5%20pytorch%20%E8%BD%AC%20onnx%20%E8%BD%AC%20Caffe" rel="nofollow">        </a><a href="#YOLOv5%20pytorch%20%E8%BD%AC%20onnx%20%E8%BD%AC%20Caffe" rel="nofollow">YOLOv5 pytorch 转 onnx 转 Caffe</a></h3> 
<h3 id="YOLOv5%20Caffe%E8%BD%ACwk%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><a href="#YOLOv5%20Caffe%E8%BD%ACwk%E6%96%87%E4%BB%B6" rel="nofollow">        </a><a href="#YOLOv5%20Caffe%E8%BD%ACwk%E6%96%87%E4%BB%B6" rel="nofollow">YOLOv5 Caffe转wk文件</a></h3> 
<h3 id="%E6%80%BB%E7%BB%93%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93%EF%BC%9A" rel="nofollow">        </a><a href="#%E6%80%BB%E7%BB%93%EF%BC%9A" rel="nofollow">总结</a></h3> 
<h3 id="%E5%8F%82%E8%80%83%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83%EF%BC%9A" rel="nofollow">        </a><a href="#%E5%8F%82%E8%80%83%EF%BC%9A" rel="nofollow">参考</a></h3> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E5%89%8D%E6%B2%BF">前沿</h2> 
<p>        作者在将YOLOv5 pytorch版本转成wk文件中碰到了很多的坑，但在研究中也收获了很多知识，针对转化过程，作者进行了详细的解读来给大家避坑，如果在转化过程中有什么问题也可以联系作者，我们可以一起进行分析和讨论。</p> 
<p></p> 
<h2 id="YOLOv5%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E5%8F%96%E4%B8%8E%E4%BF%AE%E6%94%B9"><a href="#YOLOv5%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E5%8F%96%E4%B8%8E%E4%BF%AE%E6%94%B9" rel="nofollow"><span style="color:#0d0016;">YOLOv5模型的选取与修改</span></a></h2> 
<p>        现如今，官方最新版本的YOLOv5是6.0以上的版本，而6.0版本相比于6.0以下版本（不包含6.0）发生了不少的变化，其中最为突出的改动是将force层修改为成步长为2，卷积为 2 x 2的Conv层 （<a href="https://github.com/ultralytics/yolov5" title="GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite">GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite</a>）。</p> 
<p>YOLOv5  5.0和6.0以YOLOv5s.yaml为例</p> 
<pre><code class="language-python"># yolov5s.yaml       YOLOv5 5.0版本
# parameters
nc: 10  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 这块部分   0-P1/2  
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]</code></pre> 
<p></p> 
<pre><code class="language-python"># YOLOv5s.yaml    YOLOv5 6.0版本

# Parameters
nc: 10  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 这块部分 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">        而wk（nnie）并不支持的Focus层，因此，如果用YOLOv5 6.0以下版本，需要将Focus层进行替换，替换成YOLOv5 6.0版本的Conv层，写法保持一致。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        经查阅其他博客发现，上采样nn.Upsample在海思的运用会影响检测速度，因而文档作者将nn.Upsample用上采样的另一种表现形式nn.ConvTranspose2d来替换，替换后的结果如下：</p> 
<pre><code class="language-python"># YOLOv5 6.0    yolov5s.yaml

# Parameters
nc: 10  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   #[-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [-1, -1, nn.ConvTranspose2d,[256, 256, 2, 2]],

   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
#   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [-1, -1, nn.ConvTranspose2d,[128, 128, 2, 2]],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
</code></pre> 
<p>        模型修改后需要<span style="color:#fe2c24;">重新进行训练</span>，之后的模型转化均是基于训练后的 <strong>.pt </strong>或 <strong>.pth </strong>文件进行的。</p> 
<p></p> 
<h2 id="YOLOv5%20pytorch%20%E8%BD%AC%20onnx%20%E8%BD%AC%20Caffe">YOLOv5 pytorch 转 onnx 转 Caffe</h2> 
<p style="margin-left:.0001pt;text-align:justify;">        YOLOv5官方代码文件中自带 <strong><span style="color:#ff0000;"><strong>pt (pth) 转 onnx</strong></span></strong> 代码文件<strong><span style="color:#ff0000;"><strong>export.py</strong></span></strong>，6.0版本的export.py文件位置放置在主目录下。6.0版本以下的export.py文件一般放置在models文件夹下。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        模型转化所需要的python库为 onnx 和 onnx-simplifier，版本号可根据YOLOv5官方代码文件中的 requirements.txt 来确定。</p> 
<p style="margin-left:.0001pt;text-align:justify;">运行export.py文件如下：</p> 
<pre><code class="language-python">python export.py --data mydata.yaml --weights yolov5s.pt --batch 1 --img 640 640 --train --simplify --include onnx --opset 10</code></pre> 
<p>        其中，--img，--data和 --weights 参数是基于读者自己输入模型尺寸的大小，训练集的yaml文件地址以及生成的<strong> .pt (.pth) </strong>文件地址而定，剩余参数可依据情况而定（6.0版本的export.py文件进行的模型转化尽量都加上，要不容易产生错误，具体原因还没有查清）。</p> 
<p>将生成的onnx文件进行进一步的简化，运行如下：</p> 
<pre><code class="language-python">python -m onnxsim yolov5s.onnx yolov5s-sim.onnx</code></pre> 
<p>        其中，onnxsim后的两个参数分别是上一步生成的onnx的地址以及生成简化后onnx的地址。</p> 
<p>        <span style="color:#fe2c24;">注：如果发生报错，请查看网络层是否发生了更改，参数是否正确等问题。</span></p> 
<p>        作者将onnx模型转化为Caffe模型是在linux的Ubuntu 18.04版本下进行的，这里需要搭建一下Caffe环境，采用的转化代码为Wulingtian老师的代码。</p> 
<p>（<a href="https://github.com/Wulingtian/yolov5_caffe" title="GitHub - Wulingtian/yolov5_caffe: yolov5 onnx caffe">GitHub - Wulingtian/yolov5_caffe: yolov5 onnx caffe</a>）</p> 
<p>        将上一步生成的 yolov5s-sim.onnx 文件放入代码文件中，并打开convertCaffe.py文件，根据模型网络层的情况与simple_onnx文件地址修改main函数下面的内容。</p> 
<p>例如：</p> 
<p><img alt="" height="221" src="https://images2.imgbox.com/cc/9c/dty8FBXb_o.png" width="952"></p> 
<p>         其中，convertToCaffe函数选用最后一个即可，主要原因是Focus网络层在训练的时候已经被改为了Conv层，所以，无需再用其他函数。</p> 
<p>如果转化成功，会出现以下信息：</p> 
<p class="img-center"><img alt="" height="115" src="https://images2.imgbox.com/9d/9c/9CuWJkCb_o.png" width="426"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="color:#ff0000;"><strong>        注意：如果转化成功，便会出现类似以下的信息，如果转化失败，代码会报错。转化失败的原因可能是因为前面生成的simple_onnx不满足转化条件，存在Caffe中无法解析的网络层，或是在生成simple_onnx前修改了yolo.py、common.py等源码，或是onnx的版本号可能不符合需求，或是无法生成节点。因此在转化模型前，先用netron（https://netron.app/）（只需将onnx文件导入即可）来看一下神经网络结构。</strong></span></strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="YOLOv5%20Caffe%E8%BD%ACwk%E6%96%87%E4%BB%B6" style="margin-left:.0001pt;text-align:justify;">YOLOv5 Caffe转wk文件</h2> 
<p style="margin-left:.0001pt;text-align:justify;">        安装并下载mingw64和RuyiStudio，RuyiStudio的版本为2.0.38。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        打开RuyiStudio.exe，并创建NNIE Studio Project，然后赋予项目名称，设置相应的配置信息。在NNIE Studio Project中创建models和images文件夹（名称可以自己定），models中放入上一步转成Caffe的 xxx.caffemodel和 xxx.prototxt文件，images中放入20-30张模型测试的图片。</p> 
<p class="img-center"><img alt="" height="376" src="https://images2.imgbox.com/a5/4d/o5eZKhOi_o.png" width="310"></p> 
<p>         打开文件最下方的 xxx.cfg，导入caffe模型文件，并设置模型转化的对应参数。</p> 
<p><img alt="" height="675" src="https://images2.imgbox.com/47/e4/ZMvyU4Cf_o.png" width="1044"></p> 
<p style="margin-left:.0001pt;text-align:justify;">参数说明： prototxt  ------------------------------- 导入caffe模型的prototxt文件</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    caffemodel  --------------------------- 导入caffe模型的caffemodel文件</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    net_type  ------------------------------ 模型类别（图像都是CNN）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    is_simulation  ------------------------ 是否进行仿真（默认即可）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    marked_prototxt  -------------------- 预生成wk文件的prototxt文件   （需要进行修改）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    output_wk_name  -------------------- 导出的wk文件的命名</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    complie_model  ---------------------- 导出模型的精度</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    log_level  ------------------------------ 是否开启日志文件</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    align_bytes  ---------------------------- 模型组对齐方式（默认）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    batch_num  ----------------------------- 处理图片的批次</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    sparse_rate  ----------------------------  FC参数稀疏化操作（默认）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    image_type  ----------------------------  输入模型的图像类型（与后处  理有关）</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    RGB_order  ----------------------------  输入模型图像的通道顺序</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    image_list  -----------------------------  参考图片</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    norm_type  -----------------------------  模型输入数据初始化</p> 
<p style="margin-left:.0001pt;text-align:justify;">                    mean_file  ------------------------------  均值文件（一般不用加）</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><span style="color:#ff0000;"><strong>        注意：所有参数均可在《</strong></span></strong><strong><u><span style="color:#ff0000;"><strong><u>HiSVP开发指南</u></strong></span></u></strong><strong><span style="color:#ff0000;"><strong>》102-106页进行查看，里面有更加详尽的参数说明。</strong></span></strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">        打开mark_prototxt文件夹下的xxx.prototxt，删除xxx.prototxt最后几行中的Reshape和Transpose层（<strong>即model_hand中3个output区域的Reshape和Transpose层</strong>），然后保存修改后的xxx.prototxt，利用marked_prototxt中的Mark来查看修改后的xxx.prototxt（以其中一组<strong>Reshape和Transpose层</strong>为例子）。</p> 
<p style="margin-left:.0001pt;text-align:justify;">修改前：<img alt="" height="511" src="https://images2.imgbox.com/a1/16/RGuzQEUF_o.png" width="152">                            修改后：<img alt="" height="464" src="https://images2.imgbox.com/81/b5/0BE22A6I_o.png" width="177"></p> 
<p>         因为YOLOv5模型采用onnx输出后的神经网络为5维（可以用<span style="color:#0d0016;">netron开查看YOLOv5模型的网络结果，netron网页查看地址：<strong><strong>https://netron.app/</strong></strong></span>），而RuyiStudio只支持4维输出结构，输出形式与YOLOv5后处理方式有关。</p> 
<p> 如果wk生成成功，则会显示wk生成成功的提示，例如：</p> 
<p class="img-center"><img alt="" height="50" src="https://images2.imgbox.com/5b/82/eKXslWqK_o.png" width="432"></p> 
<p><span style="color:#fe2c24;">        注意：如果转化失败，请查看xxx.prototxt中的网络层结构是否符合RuyiStudio所支持的网络层结构。</span></p> 
<p></p> 
<h2 id="%E6%80%BB%E7%BB%93%EF%BC%9A">总结</h2> 
<p>        总的来说，模型转化并没有困难的知识点，只需要注意一些小的细节。后处理部分需要根据模型的格式进行一定的修改，这里不对后处理部分进行说明。希望大家都能顺利的转成wk文件，尽量避免一些不必要的坑。</p> 
<p></p> 
<h2 id="%E5%8F%82%E8%80%83%EF%BC%9A">参考</h2> 
<p style="margin-left:.0001pt;text-align:justify;">                <a href="https://github.com/Wulingtian/yolov5_caffe" title="GitHub - Wulingtian/yolov5_caffe: yolov5 onnx caffe"></a></p> 
<p>                <a href="https://github.com/ultralytics/yolov5" title="GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite"></a></p> 
<p><a href="https://blog.csdn.net/tangshopping/article/details/111150493?spm=1001.2101.3001.6650.11&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-11-111150493-blog-110038605.pc_relevant_multi_platform_whitelistv1&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-11-111150493-blog-110038605.pc_relevant_multi_platform_whitelistv1&amp;utm_relevant_index=15" title="                海思开发：yolo v5的 focus层 移植到海思上的方法_tang-shopping的博客-CSDN博客_caffe focus层">                海思开发：yolo v5的 focus层 移植到海思上的方法_tang-shopping的博客-CSDN博客_caffe focus层</a></p> 
<p><a href="https://blog.csdn.net/tangshopping/article/details/110038605" title="                海思开发：yolo v5s ：pytorch-＞onnx-＞caffe-＞nnie_tang-shopping的博客-CSDN博客_yolov5 海思">                海思开发：yolo v5s ：pytorch-＞onnx-＞caffe-＞nnie_tang-shopping的博客-CSDN博客_yolov5 海思</a></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0ccc088c2fdf7434d5a9bcaa7dc08255/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">javaEE进阶 - Spring 更简单的读取和存储对象 - 细节狂魔</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7ffd10be35cab7a1942271ed3f3d3075/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">日志审计Graylog审计华为交换机用户登录日志</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>