<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GAN系列之普通GAN - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GAN系列之普通GAN" />
<meta property="og:description" content="基础GAN详解 1.原理解析 在深度学习的大家庭中，可以将所有的模型粗略地分成两个派系，即生成式模型以及判别式模型，所谓的生成式模型，即是你输入一个sample，模型就会生成另外一个东西，比如最近大火的ChatGPT,Stable Diffusion，以及今天我们要讲的GAN等，都是生成式模型。
而所谓的判别式模型，就是你输入一个sample,模型会给你一个预测概率，表示该sample是某个label的可能性。
那么今天的重点内容，就是讲解GAN的原理。
简而言之，GAN是由两个部分组成的，一个部分叫做生成器，专门生成假的数据，而另外一个是判别器，专门来识别你给的数据是来自真实样本还是生成器的假样本。
他们两者相互博弈，直到达到所谓的纳什均衡。
注： 什么是纳什均衡？
定义：博弈的所有参与人都为了满足自己的个人利益而选择牺牲集体利益而导致的全体参与人都吃亏的均衡状态。
在GAN中的意思就是，判别器既不能发现生成器生成的假数据是真数据还是假数据，而生成器也不能奈何判别器。
2. 算法流程 讲解完了原理，相信很多人还是一头雾水，那么我们再来过一遍算法流程。
请明确一点：生成器和判别器本质上是深度神经网络，所以不用关注它的模型架构，后面会有涉及，现在只需要知道它是神经网络
首先随机采样噪声z，输入到生成器G生成器获得采样的噪声，然后就会生成一张图片生成器为了愚弄判别器，要求判别器判断该张生成出的图片与真实图像的误差越大越好。越大，那么我就能够越成功愚弄判别器了。判别器判断该张图片是真图片还是假图片，如果是真图片，就输出1，否则输出0判别器为了不被愚弄，要判别生成器生成出的图片是假图片，真实的样本输出是真图片，让真实的误差越小越好。直到判别器无法判别生成器生成的图片是真图片还是假图片为止，就达到了所谓的纳什均衡 公式如下:
3. 代码解释 首先给出的是生成器的代码和判别器的代码：
#生成器代码 class Generator(nn.Module): def __init__(self): super(Generator, self).__init__() def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(opt.latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *img_shape) return img 而判别器的代码是:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d262f2272bca7ce2bbfc6a4d98070df5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-03T22:46:44+08:00" />
<meta property="article:modified_time" content="2023-08-03T22:46:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GAN系列之普通GAN</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="GAN_0"></a>基础GAN详解</h3> 
<h4><a id="1_1"></a>1.原理解析</h4> 
<p>在深度学习的大家庭中，可以将所有的模型粗略地分成两个派系，即<strong>生成式模型</strong>以及<strong>判别式模型</strong>，所谓的生成式模型，即是你输入一个sample，模型就会<strong>生成另外一个东西</strong>，比如最近大火的ChatGPT,Stable Diffusion，以及今天我们要讲的GAN等，都是生成式模型。<br> 而所谓的<strong>判别式模型</strong>，就是你输入一个sample,模型会给你一个预测概率，表示该sample是某个label的可能性。</p> 
<p>那么今天的重点内容，就是讲解GAN的原理。<br> 简而言之，GAN是由两个部分组成的，一个部分叫做<strong>生成器</strong>，专门生成<strong>假的数据</strong>，而另外一个是<strong>判别器</strong>，专门来识别你给的数据是来自真实样本还是生成器的假样本。</p> 
<p>他们两者相互博弈，直到达到所谓的<strong>纳什均衡</strong>。</p> 
<blockquote> 
 <p>注： 什么是纳什均衡？<br> 定义：博弈的所有参与人都为了满足自己的个人利益而选择牺牲集体利益而导致的全体参与人都吃亏的均衡状态。<br> 在GAN中的意思就是，判别器既不能发现生成器生成的假数据是真数据还是假数据，而生成器也不能奈何判别器。</p> 
</blockquote> 
<h4><a id="2__12"></a>2. 算法流程</h4> 
<p>讲解完了原理，相信很多人还是一头雾水，那么我们再来过一遍算法流程。<br> <em>请明确一点：生成器和判别器本质上是深度神经网络，所以不用关注它的模型架构，后面会有涉及，现在只需要知道它是神经网络</em></p> 
<blockquote> 
 <ol><li>首先随机采样噪声z，输入到生成器G</li><li>生成器获得采样的噪声，然后就会生成一张图片</li><li>生成器为了愚弄判别器，要求判别器判断该张生成出的图片与真实图像的误差越大越好。越大，那么我就能够越成功愚弄判别器了。</li><li>判别器判断该张图片是真图片还是假图片，如果是真图片，就输出1，否则输出0</li><li>判别器为了不被愚弄，要判别生成器生成出的图片是假图片，真实的样本输出是真图片，让真实的误差越小越好。</li><li>直到判别器无法判别生成器生成的图片是真图片还是假图片为止，就达到了所谓的纳什均衡</li></ol> 
</blockquote> 
<p>公式如下:<br> <img src="https://images2.imgbox.com/fd/99/SxslAT8t_o.png" alt="GAN的误差函数"></p> 
<h4><a id="3__26"></a>3. 代码解释</h4> 
<p>首先给出的是生成器的代码和判别器的代码：</p> 
<pre><code class="prism language-python"><span class="token comment">#生成器代码</span>
<span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">block</span><span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers <span class="token operator">=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feat<span class="token punctuation">,</span> out_feat<span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>
                layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>out_feat<span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> layers

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token operator">*</span>block<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">*</span>img_shape<span class="token punctuation">)</span>
        <span class="token keyword">return</span> img
</code></pre> 
<p>而判别器的代码是:</p> 
<pre><code class="prism language-python">  <span class="token comment">#判别器</span>
<span class="token keyword">class</span> <span class="token class-name">Discriminator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Discriminator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_flat <span class="token operator">=</span> img<span class="token punctuation">.</span>view<span class="token punctuation">(</span>img<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        validity <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>img_flat<span class="token punctuation">)</span>

        <span class="token keyword">return</span> validity
</code></pre> 
<p>可以看到，两者都是最普通的神经网络结构，然后我们给出Loss定义,这里使用的是BCELoss。可以回看算法流程第三、第五步！</p> 
<pre><code class="prism language-python">adversarial_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>然后我们来声明一下两个优化器，分别是生成器优化器，负责更新参数，让生成的图片越来越像真实的图像（即让真实图像和生成图像的误差越大越好）</p> 
<pre><code class="prism language-python">optimizer_G <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>generator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>而判别器优化器，负责判别一张图像是生成的图像还是真实的图像，所以需要让判别器判别的结果和真实的标签误差越小越好。</p> 
<pre><code class="prism language-python">optimizer_D <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>discriminator<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>opt<span class="token punctuation">.</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>b1<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>b2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>好了，接下来就到了重头戏了，训练过程！</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># Adversarial ground truths</span>
        <span class="token comment"># 真实的数据标签，我们从真实的dataloader中拿数据，那么肯定都是真实的数据啦！</span>
        <span class="token comment"># [[1],[1],...,[1]]</span>
        valid <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment">#label</span>
        <span class="token comment"># 那么这个是假标签，都是0</span>
        <span class="token comment"># [[0],[0],...,[0]]</span>
        fake <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        <span class="token comment"># Configure input</span>
        <span class="token comment"># 我们获得一个真的图像</span>
        real_imgs <span class="token operator">=</span> Variable<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># -----------------</span>
        <span class="token comment">#  Train Generator</span>
        <span class="token comment"># -----------------</span>
		<span class="token comment"># 梯度置空</span>
        optimizer_G<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># Sample noise as generator input(随机采样)</span>
        z <span class="token operator">=</span> Variable<span class="token punctuation">(</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Generate a batch of images</span>
        <span class="token comment"># 生成器根据采样结果生成一张图像</span>
        gen_imgs <span class="token operator">=</span> generator<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token comment"># Loss measures generator's ability to fool the discriminator</span>
        <span class="token comment"># 我们为了愚弄判别器，要让判别器的结果和0越大越好，也就是说不能让判别器发现我们嘛</span>
        <span class="token comment"># 因此反过来，就是要和1越小越好嘛</span>
        g_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>
		
		<span class="token comment"># 梯度更新</span>
        g_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer_G<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># ---------------------</span>
        <span class="token comment">#  Train Discriminator</span>
        <span class="token comment"># ---------------------</span>

        optimizer_D<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># Measure discriminator's ability to classify real from generated samples</span>
        <span class="token comment"># 这个很简单，判别器就是要发现哪些是真图像，哪些是假图像啦</span>
        <span class="token comment"># 所以，要让真图像和1的loss越小越好，让假图像和0的loss越小越好</span>
        real_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>real_imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> valid<span class="token punctuation">)</span>
        fake_loss <span class="token operator">=</span> adversarial_loss<span class="token punctuation">(</span>discriminator<span class="token punctuation">(</span>gen_imgs<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fake<span class="token punctuation">)</span>
        d_loss <span class="token operator">=</span> <span class="token punctuation">(</span>real_loss <span class="token operator">+</span> fake_loss<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>

        d_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer_D<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><mark>The End</mark></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/88ee1e192584a903e574cbf270b117de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">常见算法及其时间复杂度总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/730705d4aa0207d8962749ae8dc8f110/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">echarts图表渐变色 &#43; 每个柱子不同颜色设置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>