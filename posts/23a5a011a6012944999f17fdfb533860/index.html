<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>决策树建模完整流程 - 编程中国的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="决策树建模完整流程" />
<meta property="og:description" content="《老饼讲解机器学习》https://www.bbbdata.com/ml/text/40
目录
一.数据处理
(一) 数据预处理
(二)训练、测试数据分割
二.试探建模极限
三.参数调优(预剪枝)
1.参数网络扫描
2.参数评估
3.待调优参数列表
四.后剪枝调优
(一) 打印决策树相关信息
(二) 剪枝
五.模型提取
决策树建模完整流程主要有五个：
1.数据处理
2.试探建模极限
3.参数调优
4.后剪枝
5.模型提取
本文只作流程介绍，完整代码见《决策树建模完整代码》
一.数据处理 (一) 数据预处理 1.缺失值填充：我们知道，决策树（CART）是不支持缺失值的，我们要把缺失数据按业务逻辑处理成非缺失值。
备注：也有人说决策树支持缺失值，其实说的是C4.5算法，sklearn用的是CART,不要搞混乱了
2.枚举变量转成数值变量：CART树的每个节点都是判断 变量在阈值的 左边还是右边，因此，它是不支持枚举变量的，需要处理成数值变量，处理方法不在此展开。
(二)训练、测试数据分割 决策树是一个易于过拟合的模型，因此，需要数据分割为两份：训练数据集(80%)、测试数据集(20%)。
train_X, test_X, train_y, test_y = train_test_split(all_X, all_y, test_size=0.2, random_state=0) 二.试探建模极限 我们建模结果并不总是一直顺利如意，模型的结果可能不理想，可能是数据问题，也可能是模型参数问题，
所以，我们要先试探一下用这批数据建模的极限在哪里。如果很差，那就没必要在模型参数上太纠结了，应往数据上找问题。
参数的调整，仅是让我们往这个极限上靠拢。所以，我们先试探一下最优模型，能让我们心里更有底。
决策树试探极限，只需要把参数调到极致（即用默认参数）就可以。
#--------模型极限试探----------------------------------- clf = tree.DecisionTreeClassifier(max_depth=3,min_samples_leaf=8,random_state=20) clf = clf.fit(all_X, all_y) total_socre = clf.score(all_X,all_y) clf = clf.fit(train_X, train_y) train_socre = clf.score(train_X,train_y) print(&#34;\n========模型试探============&#34;) print(&#34;全量数据建模准确率：&#34;,total_socre) print(&#34;训练数据建模准确率：&#34;,train_socre) 三." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/23a5a011a6012944999f17fdfb533860/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-21T20:44:25+08:00" />
<meta property="article:modified_time" content="2024-01-21T20:44:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程中国的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程中国的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">决策树建模完整流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><a class="has-card" href="https://www.bbbdata.com/ml/text/40" rel="nofollow" title="《老饼讲解机器学习》"><span class="link-card-box"><span class="link-title">《老饼讲解机器学习》</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/39/b1/BrZr7zlu_o.png" alt="icon-default.png?t=N7T8">https://www.bbbdata.com/ml/text/40</span></span></a></p> 
<hr> 
<p><strong>目录</strong></p> 
<p id="%E4%B8%80.%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%B8%80.%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86" rel="nofollow">一.数据处理</a></p> 
<p id="(%E4%B8%80)%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#%28%E4%B8%80%29%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" rel="nofollow">(一) 数据预处理</a></p> 
<p id="(%E4%BA%8C)%E8%AE%AD%E7%BB%83%E3%80%81%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2-toc" style="margin-left:40px;"><a href="#%28%E4%BA%8C%29%E8%AE%AD%E7%BB%83%E3%80%81%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2" rel="nofollow">(二)训练、测试数据分割</a></p> 
<p id="%E4%BA%8C.%E8%AF%95%E6%8E%A2%E5%BB%BA%E6%A8%A1%E6%9E%81%E9%99%90-toc" style="margin-left:0px;"><a href="#%E4%BA%8C.%E8%AF%95%E6%8E%A2%E5%BB%BA%E6%A8%A1%E6%9E%81%E9%99%90" rel="nofollow">二.试探建模极限</a></p> 
<p id="%E4%B8%89.%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98(%E9%A2%84%E5%89%AA%E6%9E%9D)-toc" style="margin-left:0px;"><a href="#%E4%B8%89.%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98%28%E9%A2%84%E5%89%AA%E6%9E%9D%29" rel="nofollow">三.参数调优(预剪枝)</a></p> 
<p id="1.%E5%8F%82%E6%95%B0%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F-toc" style="margin-left:40px;"><a href="#1.%E5%8F%82%E6%95%B0%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F" rel="nofollow">1.参数网络扫描</a></p> 
<p id="2.%E5%8F%82%E6%95%B0%E8%AF%84%E4%BC%B0-toc" style="margin-left:40px;"><a href="#2.%E5%8F%82%E6%95%B0%E8%AF%84%E4%BC%B0" rel="nofollow">2.参数评估</a></p> 
<p id="3.%E5%BE%85%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8-toc" style="margin-left:40px;"><a href="#3.%E5%BE%85%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8" rel="nofollow">3.待调优参数列表</a></p> 
<p id="%E5%9B%9B.%E5%90%8E%E5%89%AA%E6%9E%9D%E8%B0%83%E4%BC%98-toc" style="margin-left:0px;"><a href="#%E5%9B%9B.%E5%90%8E%E5%89%AA%E6%9E%9D%E8%B0%83%E4%BC%98" rel="nofollow">四.后剪枝调优</a></p> 
<p id="(%E4%B8%80)%20%E6%89%93%E5%8D%B0%E5%86%B3%E7%AD%96%E6%A0%91%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF-toc" style="margin-left:40px;"><a href="#%28%E4%B8%80%29%20%E6%89%93%E5%8D%B0%E5%86%B3%E7%AD%96%E6%A0%91%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF" rel="nofollow">(一) 打印决策树相关信息</a></p> 
<p id="(%E4%BA%8C)%20%E5%89%AA%E6%9E%9D-toc" style="margin-left:40px;"><a href="#%28%E4%BA%8C%29%20%E5%89%AA%E6%9E%9D" rel="nofollow">(二) 剪枝</a></p> 
<p id="%E4%BA%94.%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96-toc" style="margin-left:0px;"><a href="#%E4%BA%94.%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96" rel="nofollow">五.模型提取</a></p> 
<hr id="hr-toc"> 
<p><strong>决策树建模完整流程主要有五个：</strong><br> 1.数据处理<br> 2.试探建模极限<br> 3.参数调优<br> 4.后剪枝<br> 5.模型提取<br><strong>本文只作流程介绍，完整代码见</strong><strong>《</strong><a href="https://www.bbbdata.com/ml/text/40" rel="nofollow" title="决策树建模完整代码">决策树建模完整代码</a><strong>》</strong></p> 
<h2 id="%E4%B8%80.%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><strong>一.数据处理</strong></h2> 
<h3 id="(%E4%B8%80)%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><strong>(一) 数据预处理</strong></h3> 
<p><strong>1.缺失值填充：</strong>我们知道，决策树（CART）是不支持缺失值的，我们要把缺失数据按业务逻辑处理成非缺失值。<br> 备注：也有人说决策树支持缺失值，其实说的是C4.5算法，sklearn用的是CART,不要搞混乱了<br><strong>2.枚举变量转成数值变量：</strong>CART树的每个节点都是判断 变量在阈值的 左边还是右边，因此，它是不支持枚举变量的，需要处理成数值变量，处理方法不在此展开。</p> 
<h3 id="(%E4%BA%8C)%E8%AE%AD%E7%BB%83%E3%80%81%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E5%88%86%E5%89%B2"><strong>(二)训练、测试数据分割</strong></h3> 
<p>决策树是一个易于过拟合的模型，因此，需要数据分割为两份：训练数据集(80%)、测试数据集(20%)。</p> 
<pre><code>train_X, test_X, train_y, test_y = train_test_split(all_X, all_y, test_size=0.2, random_state=0)</code></pre> 
<h2 id="%E4%BA%8C.%E8%AF%95%E6%8E%A2%E5%BB%BA%E6%A8%A1%E6%9E%81%E9%99%90"><strong>二.试探建模极限</strong></h2> 
<p>我们建模结果并不总是一直顺利如意，模型的结果可能不理想，可能是数据问题，也可能是模型参数问题，<br> 所以，我们要先试探一下用这批数据建模的极限在哪里。如果很差，那就没必要在模型参数上太纠结了，应往数据上找问题。<br> 参数的调整，仅是让我们往这个极限上靠拢。所以，我们<strong>先试探一下最优模型，能让我们心里更有底。</strong></p> 
<p><strong>决策树试探极限，只需要把参数调到极致（即用默认参数）就可以。</strong></p> 
<pre><code>#--------模型极限试探-----------------------------------
clf = tree.DecisionTreeClassifier(max_depth=3,min_samples_leaf=8,random_state=20)
clf         = clf.fit(all_X, all_y)  
total_socre      = clf.score(all_X,all_y)
clf         = clf.fit(train_X, train_y)  
train_socre      = clf.score(train_X,train_y)
print("\n========模型试探============")
print("全量数据建模准确率：",total_socre)
print("训练数据建模准确率：",train_socre)</code></pre> 
<h2 id="%E4%B8%89.%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98(%E9%A2%84%E5%89%AA%E6%9E%9D)"><strong>三.参数调优(预剪枝)</strong></h2> 
<p>建模中，我们需要考虑模型的泛化能力，因此需要设置预剪枝参数。<br> 预剪枝参数怎么设？可以<strong>采用《交叉验证方法》+《参数网格扫描》进行参数确定。</strong></p> 
<h3 id="1.%E5%8F%82%E6%95%B0%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F"><strong>1.参数网络扫描</strong></h3> 
<p>例如，我们要确定参数max_depth和min_samples_leaf，<br> 可预设max_depth的扫描值为 [3,5,7,9,11,13,15]这7个值， <br> min_samples_leaf 的扫描值为[1,3,5,7,9]这5个值，<br> 那它们的组合为5*7=35种，然后对每组参数进行评估，最后选出最优的参数组数。</p> 
<h3 id="2.%E5%8F%82%E6%95%B0%E8%AF%84%E4%BC%B0"><strong>2.参数评估</strong></h3> 
<p><strong>参数评估方法：K折交叉验证评估方法。</strong><br> 例如5折交叉验证，就是把数据分为5份，训练5轮，每轮训练用一份数据验证，其余4份训练。这样最终每个样本都有预测值，最后把预测值的准确率(或其它指标)作为评估指标。<br> 由于评估指标用的都是检验数据，所以评估的是泛化能力。</p> 
<p>通过网络扫描后，即可得到最优的参数组合。</p> 
<h3 id="3.%E5%BE%85%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8"><strong>3.待调优参数列表</strong></h3> 
<p><strong>一般调的参数有：</strong><br> min_samples_leaf  ：叶子节点最小样本数。<br> max_depth             ：树分枝的最大深度<br> random_state         ：随机种子</p> 
<p><strong>其它<br> (1)预剪枝参数：</strong><br> min_samples_leaf            ：叶子节点最小样本数。<br> min_samples_split           ：节点分枝最小样本个数<br> max_depth                       ：树分枝的最大深度<br> min_weight_fraction_leaf ：叶子节点最小权重和<br> min_impurity_decrease   ：节点分枝最小纯度增长量<br> max_leaf_nodes              ：最大叶子节点数</p> 
<p><strong>(2)节点不纯度评估函数：</strong><br> criterion：节点不纯度评估函数（gini,entropy）</p> 
<pre><code>#-------网格扫描最优训练参数---------------------------
clf = tree.DecisionTreeClassifier(random_state=0)
param_test = {
             'max_depth':range(3,15,3) #最大深度
             ,'min_samples_leaf':range(5,20,3)
             ,'random_state':range(0,100,10)
             # ,'min_samples_split':range(5,20,3)
             # ,'splitter':('best','random')  #
             # ,'criterion':('gini','entropy') #基尼  信息熵
}
gsearch= GridSearchCV(estimator=clf,              # 对应模型
                param_grid=param_test,     # 要找最优的参数
                scoring=None,         # 准确度评估标准 
                n_jobs=-1,            # 并行数个数,-1:跟CPU核数一致
                cv = 5,             # 交叉验证 5折
                verbose=0            # 输出训练过程
                )
gsearch.fit(train_X,train_y)
print("\n========最优参数扫描结果============")
print("模型最佳评分:",gsearch.best_score_)
print("模型最佳参数:",gsearch.best_params_)</code></pre> 
<h2 id="%E5%9B%9B.%E5%90%8E%E5%89%AA%E6%9E%9D%E8%B0%83%E4%BC%98"><strong>四.后剪枝调优</strong></h2> 
<p><strong>为了进一步加强模型的泛化能力，和增加模型的合理性，在最后阶段，我们会人工干预，进行后剪枝调优。</strong></p> 
<h3 id="(%E4%B8%80)%20%E6%89%93%E5%8D%B0%E5%86%B3%E7%AD%96%E6%A0%91%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF"><strong>(一) 打印决策树相关信息</strong></h3> 
<p><strong>(1)决策树信息</strong></p> 
<pre><code>====决策树信息=================
叶子个数： 5
树的深度： 3
特征权重： [0.00277564 0.         0.54604969 0.45117467]</code></pre> 
<p><strong>(2) 错误样本在叶子节点的分布情况：</strong></p> 
<pre><code> leaf_node  num  is_err  err_rate
    4       9    1      0.111111</code></pre> 
<p> <strong>(3)决策树可视图</strong></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/14/82/HYkREDK3_o.png"></p> 
<p><strong>(4)打印CCP路径：</strong></p> 
<pre><code>====CCP路径=================
ccp_alphas: [0.         0.00167683 0.01384615 0.25871926 0.32988169]
impurities: [0.06073718      0.06241401 0.07626016 0.33497942 0.66486111]</code></pre> 
<p><strong>它的意思是：</strong><br> 0&lt;﻿α﻿ &lt;0.00167683时，树的不纯度为 0.06073718，<br> 0.001676&lt;﻿\alphaα﻿ &lt;0.013846时，树的不纯度为 0.06241，<br> 0.013846&lt;﻿\alphaα﻿ &lt;0.258719时，树的不纯度为 0.07626，<br> ..... </p> 
<p><strong>详细参考《</strong><a href="https://www.bbbdata.com/ml/text/38" rel="nofollow" title="sklearn决策树后剪枝">sklearn决策树后剪枝</a><strong>》</strong></p> 
<h3 id="(%E4%BA%8C)%20%E5%89%AA%E6%9E%9D"><strong>(二) 剪枝</strong></h3> 
<p><strong>CCP剪枝法： 参考CCP路径，我们选择一个可以接受的树不纯度，找到对应的alpha,对其剪枝。</strong><br> 例如，我们可接受的树不纯度为0.07626，则alpha可设为0.1(在0.01384与0.2587之间）对树进行剪树。</p> 
<p><strong>上面提供了多种信息，剪枝是最后的优化步骤，我们除了以上的信息，还要考虑实际业务的特性，对其灵活进行剪枝。</strong></p> 
<h2 id="%E4%BA%94.%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8F%96"><strong>五.模型提取</strong></h2> 
<p>模型建好后，需要布署到生产，生产环境可能是JAVA环境，PYTHON环境等，</p> 
<p><strong>主要思路是，只提取数据，再在生产环境写出通用预测代码（不是弄成一系列的if else）。</strong></p> 
<p>可以参考《<a href="https://www.bbbdata.com/ml/text/35" rel="nofollow" title="sklearn提取决策树规则代码">sklearn提取决策树规则代码</a>》</p> 
<p id="%E4%B8%89.%E6%8C%81%E4%B9%85%E5%8C%96%E8%B0%83%E7%94%A8"><span style="color:#fe2c24;"><strong>相关文章</strong></span></p> 
<p> 《<a href="https://www.bbbdata.com/ml/text/32" rel="nofollow" title="一个简单的决策树分类例子">一个简单的决策树分类例子</a>》</p> 
<p>《<a href="https://www.bbbdata.com/ml/text/33" rel="nofollow" title="sklearn决策树结果可视化">sklearn决策树结果可视化</a>》</p> 
<p>《<a href="https://www.bbbdata.com/ml/text/34" rel="nofollow" title="sklearn决策树参数详解">sklearn决策树参数详解</a>》</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0e9c7adb03204711aca5e53674c189ba/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">细讲sklearn决策树后剪枝(带例子)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/33282987e1ee7cfe034d5697d090c404/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">评分卡实例：一步一步实现评分卡(详细长文)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程中国的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>